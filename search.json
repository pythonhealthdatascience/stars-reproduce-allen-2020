[
  {
    "objectID": "evaluation/scope.html",
    "href": "evaluation/scope.html",
    "title": "Scope",
    "section": "",
    "text": "This page outlines that parts of the journal article which we will attempt to reproduce."
  },
  {
    "objectID": "evaluation/scope.html#within-scope",
    "href": "evaluation/scope.html#within-scope",
    "title": "Scope",
    "section": "Within scope",
    "text": "Within scope\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\nFigure 2. ‚ÄúPatient state over time by unit. The patient population progresses through infection over three months (with 80% infected). The bold line shows the median results of 30 trials, and the fainter lines show the minimum and maximum from the 30 trials.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\nFigure 3. ‚ÄúProgression of patient population through COVID infection, assuming 80% become infected over three months, with 15% mortality. The figure also shows the number of patients not allocated to a dialysis session at any time. The bold line shows the median results of 30 trials, and the fainter lines show the minimum and maximum from the 30 trials.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\nFigure 4. ‚ÄúPatient displacement. The number of patients displaced from their current unit (left panel) and the additional travel time to the unit of care (right panel) for displaced patients. These results do not include those receiving inpatient care. The patient population progresses through infection over three months (with 80% infected). The bold line shows the median results of 30 trials, and the fainter lines show the minimum and maximum from the 30 trials.‚Äù"
  },
  {
    "objectID": "evaluation/scope.html#outside-scope",
    "href": "evaluation/scope.html#outside-scope",
    "title": "Scope",
    "section": "Outside scope",
    "text": "Outside scope\n\n\n\n\n\n\nTable 1\n\n\n\n\n\nOutside scope as it is a table of model parameters rather than outputs.\n\n\n\nTable 1. ‚ÄúBaseline model parameters.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nOutside scope as it is a flow chart representing the model pathways.\n\n\n\nFigure 1. ‚ÄúSchematic representation of patient pathway.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nOutside scope as it is a result of the Monte Carlo model.\n\n\n\nFigure 5. ‚ÄúOne-way ambulance transport time distributions (1000 model runs). Results compare population COVID-positive and ambulance seating capacity (e.g.¬†2 = 2 seats.) Figures do not include ambulance clean-down/turnaround time.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 6\n\n\n\n\n\nOutside scope as it is a result of the Monte Carlo model.\n\n\n\nFigure 6. ‚ÄúTwo-way ambulance transport time distributions (1000 model runs). Results compare population COVID-positive and ambulance seating capacity (e.g.¬†2 = 2 seats.) Figures do not include ambulance clean-down/turnaround time.‚Äù"
  },
  {
    "objectID": "evaluation/logbook.html",
    "href": "evaluation/logbook.html",
    "title": "Logbook",
    "section": "",
    "text": "These diary entries record daily progress in reproduction of the study, providing a transparent and detailed record of work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2\n\n\n\n\n\n\nread\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nsetup\n\n\nread\n\n\nscope\n\n\n\n\n\n\n\n\n\nMay 22, 2024\n\n\nAmy Heather\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html",
    "href": "evaluation/posts/2024_05_24/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Note\n\n\n\nFixed model so that it is reproducible between runs. Total time used: 5h 45m (14.4%)"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#work-log",
    "href": "evaluation/posts/2024_05_24/index.html#work-log",
    "title": "Day 3",
    "section": "Work log",
    "text": "Work log"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#untimed---revision-on-random-numbers",
    "href": "evaluation/posts/2024_05_24/index.html#untimed---revision-on-random-numbers",
    "title": "Day 3",
    "section": "Untimed - Revision on random numbers",
    "text": "Untimed - Revision on random numbers\nSpent some time revises how number generation works in Python - notes here. I felt this was external to reproducing the model, so did not include it in time.\nIf I would have timed it though, it would‚Äôve been apx. 9.30-11.28."
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#reproduction",
    "href": "evaluation/posts/2024_05_24/index.html#reproduction",
    "title": "Day 3",
    "section": "11.29-12.38 Reproduction",
    "text": "11.29-12.38 Reproduction\nI returned to trying to modify the code so it can reproduce results between runs.\nA simple fix of adding a seed to some of the Uniform() functions that were still using random_seed=None meant that the simulation would now run exactly the same each time.\nRun 1:\n\nRun 2:\n\nThen we needed a seperate seed with each run (else every run will produce identical results) This required changes to: * single_run() within sim_replicate.py so it can accept random number set as an argument, and then when it was called in multiple_replications(), to use the rep number as the starting seed * Scenario, changing it from a frozen dataclass to a class with a function that accepts a random number set, and then prompts generation of distributions from that\nThese changes were based on this model.\nAs can see, this has fixed it, as we have reproducible results between runs, and varying results within runs.\nRun 1:\n\nRun 2:"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#untimed-exploring-methods-for-overlaying-figures",
    "href": "evaluation/posts/2024_05_24/index.html#untimed-exploring-methods-for-overlaying-figures",
    "title": "Day 3",
    "section": "Untimed: Exploring methods for overlaying figures",
    "text": "Untimed: Exploring methods for overlaying figures\nExploring methods for overlaying figures. Not timed as not about reproduction of this study, but about how we are going to do this each time when reproducing.\nDecided that it‚Äôs not helpful to do this - spend more time fiddling around with getting them to resize and overlay correctly - and that the simplest option here would be to compare by eye.\nIf timed, 13.33-13.57.\n\nimport cv2\nimport matplotlib.pyplot as plt\n\noriginal = cv2.imread('../../../original_study/article_fig4.png')\noverlay = cv2.imread('figure_2a.png')\n\n# Resize overlay to match original image dimensions\noverlay_resize = cv2.resize(overlay, (original.shape[1], original.shape[0]))\n\n# View new image\nimg = plt.imshow(overlay_resize)\nplt.axis('off')\nimg\n\n\n\n\n\n\n\n\n\n# Overlay transparenly\ncombined = cv2.addWeighted(original,0.4,overlay_resize,0.1,0)\n\n# View new image\nimg = plt.imshow(combined)\nplt.axis('off')\nimg"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#timings",
    "href": "evaluation/posts/2024_05_24/index.html#timings",
    "title": "Day 3",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 276\n\n# Times from today\ntimes = [\n    ('11.29', '12.38')]\n\n# Print time used and remaining\ncalculate_times(used_to_date, times)\n\nTime spent today: 69m, or 1h 9m\nTotal used to date: 345m, or 5h 45m\nTime remaining: 2055m, or 34h 15m\nUsed 14.4% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_05_24/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 3",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nProtocol:\n\nIncreasing the emphasis on fiddling with the random number generators and seeds as likely being a large part of trying to reproduce the studies\nShould I have timed the revision of random number generators?\nCould it be that time to get it running we are interested in is partly just ‚Äúits working‚Äù and partly ‚Äúi can reproduce between runs‚Äù and then ‚Äúi can get this and that figure‚Äù. In the case of this example, the figure from Krafczyk wouldn‚Äôt make alot of sense, as we all-or-nothing reproduce them. Depending on decision, need to be clear in protocol about what is being timed and what is not."
  },
  {
    "objectID": "evaluation/reporting.html",
    "href": "evaluation/reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "This page evaluates the extent to which Monks et al.¬†2016 meets the criteria from two discrete-event simulation study reporting guidelines:\nif we apply this later down the line, what about if its not discrete-event?"
  },
  {
    "objectID": "evaluation/reporting.html#stress-des",
    "href": "evaluation/reporting.html#stress-des",
    "title": "Reporting",
    "section": "STRESS-DES",
    "text": "STRESS-DES\nexample fill in, not actual\nTotal (out of 5):\n\n‚úÖ Fully - 20% (n=1)\nüü° Partially - 20% (n=1)\n‚ùå Not met - 20% (n=1)\n‚ùî Unclear - 40% (n=2)\n\n\n\n\n\n\n\n\n\n\n\nItem\nRecommendation\nMet by study?\nEvidence\n\n\n\n\nObjectives\n\n\n\n\n\n1.1 Purpose of the model\nExplain the background and objectives for the model\n‚úÖ Fully\n\n\n\n1.2 Model outputs\nDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\nüü° Partially\n\n\n\n1.3 Experimentation aims\nIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis ‚Äì Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments ‚Äì Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation ‚Äì (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n‚ùå Not met\n\n\n\nLogic\n\n\n\n\n\n2.1 Base model overview diagram\nDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n‚ùî Unclear\n\n\n\n2.2 Base model logic\nGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n‚ùî Unclear\n\n\n\n2.3 Scenario logic\nGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\n\n\n\n\n2.4 Algorithms\nProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e.¬†scheduling of arrivals/appointments/operations/maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n\n\n\n\n2.5.1 Components - entities\nGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n\n\n\n\n2.5.2 Components - activities\nDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n\n\n\n\n2.5.3 Components - resources\nList all the resources included within the model and which activities make use of them.\n\n\n\n\n2.5.4 Components - queues\nGive details of the assumed queuing discipline used in the model (e.g.¬†First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\n\n\n\n\n2.5.5 Components - entry/exit points\nGive details of the model boundaries i.e.¬†all arrival and exit points of entities. Detail the arrival mechanism (e.g.¬†‚Äòthinning‚Äô to mimic a non-homogenous Poisson process or balking)\n\n\n\n\nData\n\n\n\n\n\n3.1 Data sources\nList and detail all data sources. Sources may include:‚Ä¢ Interviews with stakeholders,‚Ä¢ Samples of routinely collected data,‚Ä¢ Prospectively collected samples for the purpose of the simulation study,‚Ä¢ Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n\n\n\n\n3.2 Pre-processing\nProvide details of any data manipulation that has taken place before its use in the simulation, e.g.¬†interpolation to account for missing data or the removal of outliers.\n\n\n\n\n3.3 Input parameters\nList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:‚Ä¢ Base case data‚Ä¢ Data use in experimentation, where different from the base case.‚Ä¢ Where optimisation or design of experiments has been used, state the range of values that parameters can take.Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n\n\n\n\n3.4 Assumptions\nWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n\n\n\n\nExperimentation\n\n\n\n\n\n4.1 Initialisation\nReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n\n\n\n\n4.2 Run length\nDetail the run length of the simulation model and time units.\n\n\n\n\n4.3 Estimation approach\nState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\n\n\n\n\nImplementation\n\n\n\n\n\n5.1 Software or programming language\nState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g.¬†Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\n\n\n\n\n5.2 Random sampling\nState the algorithm used to generate random samples in the software/programming language used e.g.¬†Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n\n\n\n\n5.3 Model execution\nState the event processing mechanism used e.g.¬†three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n\n\n\n\n5.4 System specification\nState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\n\n\n\n\nCode access\n\n\n\n\n\n6.1 Computer model sharing statement\nDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these."
  },
  {
    "objectID": "evaluation/reporting.html#ispor-sdm",
    "href": "evaluation/reporting.html#ispor-sdm",
    "title": "Reporting",
    "section": "ISPOR-SDM",
    "text": "ISPOR-SDM\nTotal (out of 4):\n\n‚úÖ Fully - 25% (n=1)\nüü° Partially - 25% (n=1)\n‚ùå Not met - 25% (n=1)\n‚ùî Unclear - 25% (n=1)\n\n\n\n\n\n\n\n\n\n\nItem\nAssessed if‚Ä¶\nMet by study?\nEvidence/location\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?\n‚Ä¶the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\nüü° Partially\n\n\n\n2 Is the modeled healthcare setting/health condition clarified?\n‚Ä¶the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n‚ùå Not met\n\n\n\n3 Is the model structure described?\n‚Ä¶the model‚Äôs conceptual structure was described in the form of either graphical or text presentation.\n‚úÖ Fully\n\n\n\n4 Is the time horizon given?\n‚Ä¶the time period covered by the simulation was reported.\n\n\n\n\n5 Are all simulated strategies/scenarios specified?\n‚Ä¶the comparators under test were described in terms of their components, corresponding variations, etc\n‚ùî Unclear\n\n\n\n6 Is the target population described?\n‚Ä¶the entities simulated and their main attributes were characterized.\n\n\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?\n‚Ä¶the sources of all data used to inform model inputs were reported.\n\n\n\n\n8 Are the parameters used to populate model frameworks specified?\n‚Ä¶all relevant parameters fed into model frameworks were disclosed.\n\n\n\n\n9 Are model uncertainties discussed?\n‚Ä¶the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n\n\n\n\n10 Are sensitivity analyses performed and reported?\n‚Ä¶the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters‚Äô plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n\n\n\n\nValidation\n\n\n\n\n\n11 Is face validity evaluated and reported?\n‚Ä¶it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n\n\n\n\n12 Is cross validation performed and reported\n‚Ä¶comparison across similar modeling studies which deal with the same decision problem was undertaken.\n\n\n\n\n13 Is external validation performed and reported?\n‚Ä¶the modeler(s) examined how well the model‚Äôs results match the empirical data of an actual event modeled.\n\n\n\n\n14 Is predictive validation performed or attempted?\n‚Ä¶the modeler(s) examined the consistency of a model‚Äôs predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\n\n\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n15 Is the model generalizability issue discussed?\n‚Ä¶the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\n\n\n\n\n16 Are decision makers or other stakeholders involved in modeling?\n‚Ä¶the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n\n\n\n\n17 Is the source of funding stated?\n‚Ä¶the sponsorship of the study was indicated.\n\n\n\n\n18 Are model limitations discussed?\n‚Ä¶limitations of the assessed model, especially limitations of interest to decision makers, were discussed."
  },
  {
    "objectID": "evaluation/artefacts.html",
    "href": "evaluation/artefacts.html",
    "title": "Sharing research artefacts",
    "section": "",
    "text": "This page evaluates the extent to which Monks et al.¬†2016 meets the recommendations for the sharing of code and associated materials.\nFirst, it copies information from the best practice audit by Monks and Harper (2023). The items in this audit were based on ADD CITATIONS.\nSecondly, it assesses whether the article meets recommendations from the recently published STARS framework by Monks, Harper, and Mustafee (2024)."
  },
  {
    "objectID": "evaluation/artefacts.html#best-practice-audit-monks-and-harper-2023",
    "href": "evaluation/artefacts.html#best-practice-audit-monks-and-harper-2023",
    "title": "Sharing research artefacts",
    "section": "Best practice audit (Monks and Harper 2023)",
    "text": "Best practice audit (Monks and Harper 2023)\n\n\n\n\n\n\n\n\nItem\nDescription\nMet by study?\n\n\n\n\nDigital Object Identifier\nDoes the model have a DOI and promise of persistence? Can it be cited?\n\n\n\nOpen Researcher and Contributor ID\nIs the model linked to one or more of the authors via an ORCID?\n\n\n\nLicence\nDoes the repository have a recognised open license to control the use of code, liabilty and credit?\n\n\n\nReadme file\nIs there an obvious file that provides an overview of the repository/model and it purpose?\n\n\n\nLink to published paper\nDo models shared externally from journal articles contain a link to the published article?\n\n\n\nSteps to run code\nDoes the readme file or similar describe the steps required to execute the simulation model?\n\n\n\nFormal dependency management\nHas a formal tool, e.g.¬†renv, conda, or poetry been used to manage software dependencies for the simulation model?\n\n\n\nInformal dependency management\nHas an informal list or description of software, or OS dependencies been provided?\n\n\n\nCode Testing\nIs there any evidence of tests that have been applied to the code to check that it functions correctly?\n\n\n\nLocal execution\nCan the simulation model and associated files be downloaded and in theory executed on a local machine\n\n\n\nRemote execution\nCan the simulation model be executed online using free or commercial infrastructure?"
  },
  {
    "objectID": "evaluation/artefacts.html#stars",
    "href": "evaluation/artefacts.html#stars",
    "title": "Sharing research artefacts",
    "section": "STARS",
    "text": "STARS\n\n\n\n\n\n\n\n\nComponent\nMet by study?\nEvidence/location\n\n\n\n\nEssential components\n\n\n\n\nOpen license\n‚úÖ Fully\n\n\n\nDependency management\nüü° Partially\n\n\n\nModel created using free and open-source software (FOSS)\n‚ùå Not met\n\n\n\nMinimum documentation\n‚ùî Unclear\n\n\n\nResearch artefact metadata: Open Researcher and Contributor ID (ORCID) and citation information\n\n\n\n\nRemote code repository\n\n\n\n\nOpen science archive\n\n\n\n\nOptional components\n\n\n\n\nEnhanced documentation\n\n\n\n\nDocumentation hosting\n\n\n\n\nOnline coding environment\n\n\n\n\nModel interface\n\n\n\n\nWeb app hosting"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/vrp/transport_charts.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/vrp/transport_charts.html",
    "title": "Transport model charts",
    "section": "",
    "text": "The code below produces the figures in the report illustrating the transport results.\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\nFILE_1 = '20_positive_CW.csv'\nFILE_2 = '40_positive_CW.csv'\nFILE_3 = '60_positive_CW.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity to HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n#'P(positive) = {p_pos}. P(need transport)={p_transport}')\nax[0].set_ylabel('total driving time (mins)')\n#ax[0].set_xlabel('ambulance seating capacity')\n#ax[1].set_xlabel('ambulance seating capacity')\n#ax[2].set_xlabel('ambulance seating capacity')\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\nfig.savefig('output/prelim_model_tuned.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity to HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n#'P(positive) = {p_pos}. P(need transport)={p_transport}')\nax[0].set_ylabel('total driving time (mins)')\n#ax[0].set_xlabel('ambulance seating capacity')\n#ax[1].set_xlabel('ambulance seating capacity')\n#ax[2].set_xlabel('ambulance seating capacity')\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\nfig.savefig('output/prelim_model_ils.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\nSCALE = 2\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_outward_ILS.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '30_positive_ILS.csv'\nFILE_3 = '40_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 1\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('30 COVID-19 Positive')\nax[2].set_title('40 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_ILS_20_30_40.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '30_positive_ILS.csv'\nFILE_3 = '40_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 2\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('30 COVID-19 Positive')\nax[2].set_title('40 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_outward_ILS_20_30_40.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nSummary statistics\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 2\n\nresults_20 = pd.read_csv(f'output/{FILE_1}')\nresults_20.columns = ['0', '1', '2', '3', '4']\nresults_20_double = results_20 * SCALE\n\n\n(results_20 / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n21.163067\n13.478783\n11.100733\n9.902833\n\n\nstd\n4.813657\n3.423492\n2.048313\n1.627923\n1.415795\n\n\nmin\n0.000000\n12.433333\n8.100000\n6.716667\n6.083333\n\n\n25%\n4.162500\n18.691667\n12.000000\n9.966667\n8.895833\n\n\n50%\n8.325000\n21.200000\n13.550000\n11.141667\n9.866667\n\n\n75%\n12.487500\n23.466667\n14.833333\n12.183333\n10.933333\n\n\nmax\n16.650000\n33.000000\n21.050000\n15.650000\n13.850000\n\n\n\n\n\n\n\n\n\n(results_20_double / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n42.326133\n26.957567\n22.201467\n19.805667\n\n\nstd\n9.627315\n6.846984\n4.096627\n3.255847\n2.831590\n\n\nmin\n0.000000\n24.866667\n16.200000\n13.433333\n12.166667\n\n\n25%\n8.325000\n37.383333\n24.000000\n19.933333\n17.791667\n\n\n50%\n16.650000\n42.400000\n27.100000\n22.283333\n19.733333\n\n\n75%\n24.975000\n46.933333\n29.666667\n24.366667\n21.866667\n\n\nmax\n33.300000\n66.000000\n42.100000\n31.300000\n27.700000\n\n\n\n\n\n\n\n\n\nresults_40 = pd.read_csv(f'output/{FILE_2}')\nresults_40.columns = ['0', '1', '2', '3', '4']\nresults_40_double = results_40 * SCALE\n(results_40 / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n40.191267\n24.244500\n19.077550\n16.572867\n\n\nstd\n4.813657\n4.685456\n2.658565\n2.002235\n1.701350\n\n\nmin\n0.000000\n24.500000\n14.983333\n11.716667\n10.616667\n\n\n25%\n4.162500\n36.900000\n22.383333\n17.662500\n15.416667\n\n\n50%\n8.325000\n40.100000\n24.258333\n19.066667\n16.550000\n\n\n75%\n12.487500\n43.333333\n26.066667\n20.416667\n17.716667\n\n\nmax\n16.650000\n55.033333\n32.150000\n24.733333\n21.433333\n\n\n\n\n\n\n\n\n\n(results_40_double / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n80.382533\n48.489000\n38.155100\n33.145733\n\n\nstd\n9.627315\n9.370911\n5.317131\n4.004470\n3.402700\n\n\nmin\n0.000000\n49.000000\n29.966667\n23.433333\n21.233333\n\n\n25%\n8.325000\n73.800000\n44.766667\n35.325000\n30.833333\n\n\n50%\n16.650000\n80.200000\n48.516667\n38.133333\n33.100000\n\n\n75%\n24.975000\n86.666667\n52.133333\n40.833333\n35.433333\n\n\nmax\n33.300000\n110.066667\n64.300000\n49.466667\n42.866667\n\n\n\n\n\n\n\n\n\n#iqr capacity 1\niqr_1 = (results_40_double / 60).describe().loc['75%']['1'] - (results_40_double / 60).describe().loc['25%']['1']\niqr_1\n\n12.866666666666674\n\n\n\niqr_1 = (results_40_double / 60).describe().loc['75%']['1'] - (results_40_double / 60).describe().loc['25%']['1']\niqr_2 = (results_40_double / 60).describe().loc['75%']['2'] - (results_40_double / 60).describe().loc['25%']['2']\niqr_3 = (results_40_double / 60).describe().loc['75%']['3'] - (results_40_double / 60).describe().loc['25%']['3']\niqr_4 = (results_40_double / 60).describe().loc['75%']['3'] - (results_40_double / 60).describe().loc['25%']['3']\n\n\nmdn_1 = (results_40_double / 60).describe().loc['50%']['1']\nmdn_2 = (results_40_double / 60).describe().loc['50%']['2']\nmdn_3 = (results_40_double / 60).describe().loc['50%']['3']\nmdn_4 = (results_40_double / 60).describe().loc['50%']['4']\n\n\n(mdn_1 - mdn_2) / mdn_1\n\n0.3950540315876975\n\n\n\n(mdn_1 - mdn_3) / mdn_1\n\n0.5245220282626767\n\n\n\n(mdn_1 - mdn_4) / mdn_1\n\n0.587281795511222\n\n\n\nresults_60 = pd.read_csv(f'output/{FILE_3}')\nresults_60.columns = ['0', '1', '2', '3', '4']\nresults_60_double = results_60 * SCALE\n\n\n(results_60 / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n56.972333\n33.508400\n25.832817\n22.076150\n\n\nstd\n4.813657\n5.562399\n3.053067\n2.263760\n1.883696\n\n\nmin\n0.000000\n40.033333\n24.100000\n19.166667\n16.483333\n\n\n25%\n4.162500\n53.100000\n31.433333\n24.300000\n20.733333\n\n\n50%\n8.325000\n56.800000\n33.491667\n25.825000\n22.066667\n\n\n75%\n12.487500\n60.766667\n35.650000\n27.450000\n23.437500\n\n\nmax\n16.650000\n76.633333\n44.066667\n34.116667\n28.183333\n\n\n\n\n\n\n\n\n\nmdn60_1 = (results_60_double / 60).describe().loc['50%']['1']\nmdn60_2 = (results_60_double / 60).describe().loc['50%']['2']\nmdn60_3 = (results_60_double / 60).describe().loc['50%']['3']\nmdn60_4 = (results_60_double / 60).describe().loc['50%']['4']\n\n\n(results_60_double / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n113.944667\n67.016800\n51.665633\n44.152300\n\n\nstd\n9.627315\n11.124798\n6.106134\n4.527521\n3.767392\n\n\nmin\n0.000000\n80.066667\n48.200000\n38.333333\n32.966667\n\n\n25%\n8.325000\n106.200000\n62.866667\n48.600000\n41.466667\n\n\n50%\n16.650000\n113.600000\n66.983333\n51.650000\n44.133333\n\n\n75%\n24.975000\n121.533333\n71.300000\n54.900000\n46.875000\n\n\nmax\n33.300000\n153.266667\n88.133333\n68.233333\n56.366667"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html",
    "title": "Dialysis capapcity model",
    "section": "",
    "text": "The dialysis model runs through a defined period (e.g.¬†one year) and simulates the progression of patients through phases of COVID infection: negative, positive (with some requiring inpatient care) and recovered or died. The speed of progression of infection through the population may be varied (typically 3-12 months).\nAs patients change COVID state the model seeks to place them in the appropriate unit and session, opening up COVID-positive sessions in units that allow it. COVID-positive patients do not mix with any other patients. Opening up COVID-positive sessions causes other patients to be displaced from that session, and the model seeks to reallocate them either to the same unit or, if there is no space left, to the closest alternative unit.\nWhen allocating patients to units, the following search strategy is employed.\nPatients, in the model, may end up being cared for at a more distant unit than their starting unit. Once every week, the model seeks to reallocate patients back to their starting unit, or closest available unit if room in their starting unit is not available. This will also compress COVID-positive patients into as few units and sessions as possible."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#input-files",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#input-files",
    "title": "Dialysis capapcity model",
    "section": "Input files",
    "text": "Input files\n\nUnit capacity and use\nThe input file ./sim/units.csv allows definition and use of units:\n\nunit: the name used in outputs.\nsubunit: units may be broken down into two or more subunits. This may be done, for example, if only a part of the unit will be made available to COVID-19 positive patients.\nChairs: the number of dialysis chairs available in each session.\ninpatient: Set to 1 for hospitals that can accept COVID postive dialysis inpatients.\nAllow cov +: a value of 1 indicates that sessions for that unit, or subunit, may be made available to COVID positive patients.\nCov +ve order: The order in which units open up for COVID positive dialysis out patients.\nMon_1 thru Tues_3: Three sessions per day on Mon/Tues (which repeat on Wed/Thurs and Fri/Sat). A 1 indicates that the session is open for booking.\n\n\n\nPatients\nThe input file ./sim/units.csv contains information on patients:\n\nPatient ID: Any id of patient.\nPatient type: Not currently used in model.\nPostcode sector: Home postcode sector of patient.\nSite: Site patient currently attends.\nSubunit: Allocation of patient to subunit (if subunits use, you can simply assign them to any of them at the beginning of the model).\nSite postcode: Postcode of dialysis unit\nCOVID status: Can be set to positive if patients known to be positive at the start of the model run.\nfirst_day: Either Mon or Tues for patients having dialysis Mon/Wed/Fri or Tues/Thurs/Sat.\ncount*: set to 1 for all patients.\n\n\n\nTravel matrix\nThe input file ./sim/travel_matrix.csv contains travel times (minutes) from all patient postcode sectors to all dialysis units. We used Routino (routino.org) to obtain travel times."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#code-and-example",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#code-and-example",
    "title": "Dialysis capapcity model",
    "section": "Code and example",
    "text": "Code and example\n\nimport sim_replicate as sim\nfrom sim.parameters import Scenario, Uniform, Normal\n\nScenarios are defined in dictionaries as below. Multiple sceanrios may be defined and all results are saved to the ./output folder.\nParameters in the dictionary are:\n\nrun_length: Model run in days.\ntotal_proportion_people_infected. The proportion of patients who may be infected in the model. We assume this will be limited by herd immunity (or a vaccine).\ntime_to_infection: The time from start of model run to the time patients are infected. For time to infection a normal distrubtion is used. The paramters applied are mean, standard deviation, and lower cut-off (use 0 to avoid negative values) in days. In scarios we describe as 3 months we assume that six standard deviations of the distrubution (3 either side of the mean) occur in 3 months, or 90 days, so a standard deviation of 90/6 (or 15) is used.\ntime_positive: The duration a patient is positive if they remain in outpatient dialysis. A uniform distribution is used.\nproportion_pos_requiring_inpatient: The poportion of infected patients who will require inpatient dialysis.\ntime_pos_before_inpatient: For patients who will receive inpatient care, this is the time spent as a COVID positive outpatient before being hospitalised. A uniform distribution is used.\ntime_inpatient: The length of stay as an inpatient. A uniform distribution is used.\nmortality: The average mortality of dialysis patients who become infected with COVID.\nrandom_positive_rate_at_start: The model allows a proportion of patients to be randomly infected at the start of the model run.\n\nDefine a sceanrio and the numebr of model runs below (the replicates will use all available CPU cores).\n\nnumber_of_replications = 30\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    total_proportion_people_infected = 0.8,\n    time_to_infection = Normal(60, 15, 0.0),\n    time_positive = Uniform(7, 14),\n    proportion_pos_requiring_inpatient= 0.6,\n    time_pos_before_inpatient = Uniform(3,7),\n    time_inpatient = Uniform(7.0, 14.0),\n    mortality = 0.15,\n    random_positive_rate_at_start = 0.0\n    )\n\nRun the scenario. Three sets of charts will be outputed for each scenario (and saved with sceanrio names in the ./output directory: * Numbers of patients in negative, positive outpatient, positive inpatient, recovered/died stages of COVID: * Number of patients displaced from their starting dialysis unit, and how much extra travel time there is to their unit of current care. * Numbers of patients (negative/recovered, positive outpatient, pisitive inpatient) at each dialysis unit.\n\nsim.run_replications(scenarios, number_of_replications)\n\nRunning 30 reps of base_3_month =&gt; Done."
  },
  {
    "objectID": "reproduction/example.html",
    "href": "reproduction/example.html",
    "title": "Reproduction attempt",
    "section": "",
    "text": "import sim_replicate as sim\nfrom sim.parameters import Scenario\n\n\nnumber_of_replications = 5\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    proportion_pos_requiring_inpatient= 0.6)\n\n\nsim.run_replications(scenarios, number_of_replications)\n\nRunning 5 reps of base_3_month =&gt; 1, 0, 2, 4, 3, Done."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nAllen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction code - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nReport - final report describing the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nAllen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction code - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nReport - final report describing the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#project-team",
    "href": "index.html#project-team",
    "title": "Reproducing Allen et al. 2020",
    "section": "Project team",
    "text": "Project team\n\nConducting this reproduction:\n\nAmy Heather \n\nOther members of the team on STARS:\n\nThomas Monks \nAlison Harper \nNavonil Mustafee \nAndrew Mayne"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Reproducing Allen et al. 2020",
    "section": "Citation",
    "text": "Citation\nAPA: Heather A. (2024). Reproducing Allen et al.¬†2020 URL: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020\nSee CITATION.cff and citation_bibtex.bib for alternative formats."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Reproducing Allen et al. 2020",
    "section": "License",
    "text": "License\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "Changelog\nAll notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning. Dates formatted as YYYY-MM-DD as per ISO standard."
  },
  {
    "objectID": "quarto_site/study_publication.html",
    "href": "quarto_site/study_publication.html",
    "title": "Publication",
    "section": "",
    "text": "View at: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020/tree/main/original_study/dialysis-service-delivery-covid19-v1.0"
  },
  {
    "objectID": "quarto_site/study_publication.html#code-and-data",
    "href": "quarto_site/study_publication.html#code-and-data",
    "title": "Publication",
    "section": "",
    "text": "View at: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020/tree/main/original_study/dialysis-service-delivery-covid19-v1.0"
  },
  {
    "objectID": "quarto_site/study_publication.html#journal-article",
    "href": "quarto_site/study_publication.html#journal-article",
    "title": "Publication",
    "section": "Journal article",
    "text": "Journal article"
  },
  {
    "objectID": "quarto_site/study_publication.html#supplementary-materials",
    "href": "quarto_site/study_publication.html#supplementary-materials",
    "title": "Publication",
    "section": "Supplementary materials",
    "text": "Supplementary materials"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/CONTRIBUTING.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/CONTRIBUTING.html",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "Michael Allen - m.allen@exeter.ac.uk\nThomas Monks - t.m.w.monks@exeter.ac.uk"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html",
    "title": "Patient Transport Modelling",
    "section": "",
    "text": "This notebook provides an overview and instructions to run the patient transport model and explore results."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#aims-of-the-modelling",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#aims-of-the-modelling",
    "title": "Patient Transport Modelling",
    "section": "Aims of the modelling",
    "text": "Aims of the modelling\nThe model can be used to explore the impact of increasing transport vehicle (e.g.¬†an ambulance) capacity on the total one-way travel time needed. We estimate two-way travel time via a simplification: doubling the one-way travel time.\nPlease note that:\n\nThe modelling is not intended to provide guidance on the number of vehicles needed.\n\nTravel time excludes vehicle turnaround time after each trip, duration of pickup and breaks rests for drivers.\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#the-vrp-package",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#the-vrp-package",
    "title": "Patient Transport Modelling",
    "section": "The VRP package",
    "text": "The VRP package\nThe python VRP package provides functions and classes to:\n\nGenerate a simple weighted sample of a patient population spread over a geographic area.\nConstruct multiple short (but not necessarily optimal) routes for transport vehicles, with a given capacity, to travel to each patient from a ‚Äòtreatment facility‚Äô and return.\nQuickly generate a large dataset of samples through parallel simulation.\n\n\nGeospatial and travel time data\nThe first step in parameterising a model is to load the input data files\n\nPatient count by postcode sector\nTravel times between each postcode sector\n\nThe data used in the analysis can be done access via functions in the module\nvrp.io\nNote the example here uses travel time. But travel distance could also be used.\n\nfrom vrp.io import (load_patient_postcode_count, \n                    load_travel_time)\n\n\ncost_matrix = load_travel_time()\nsector_counts = load_patient_postcode_count()\n\nThese functions each return a pandas.DataFrame\n\ntype(cost_matrix)\n\npandas.core.frame.DataFrame\n\n\n\ncost_matrix.shape\n\n(262, 262)\n\n\n\ntype(sector_counts)\n\npandas.core.frame.DataFrame\n\n\n\nsector_counts.head(3)\n\n\n\n\n\n\n\n\n\ncount\n\n\nsector\n\n\n\n\n\nL151\n1\n\n\nL91\n2\n\n\nL31\n1\n\n\n\n\n\n\n\n\n\n\nBuilt-in preprocessing\nTo convert a distribution of patient counts by postcodes to proportions use the following function\n\nfrom vrp.sim import create_postcode_distribution\n\n\npostcode_distribution = create_postcode_distribution(sector_counts)\n\n\ntype(postcode_distribution)\n\npandas.core.frame.DataFrame\n\n\n\npostcode_distribution.head(3)\n\n\n\n\n\n\n\n\n\ncount\nprob\n\n\nsector\n\n\n\n\n\n\nL151\n1\n0.001919\n\n\nL91\n2\n0.003839\n\n\nL31\n1\n0.001919\n\n\n\n\n\n\n\n\n\n\nRunning a transport experiment and exploring results\nThis can be done via six classes representing an simulated experiment, a scenario and a vehicle routing solvers.\nvrp.sim.TransportExperiment\nvrp.sim.Scenario\nvrp.sim.ILSWithConstructive\nvrp.constructive.SequentialClarkeWright\nvrp.sim.MultipleReplicationRunner\nvrp.sim.ScenarioManager\nTransportExperiment is a stochastic model. It generates a sample of the patient population to transport and then creates routes for patient transport services to use.\nScenario is a python dataclass. It is used to set the parameters for the simulation and passed to a TransportExperiment\nILSWithConstructive is a class that combines a simple constructive heuristic with Iterated Local Search\nSequentialClarkeWright is a constructive heuristic based for building transport routes based on the Clarke-Wright Savings algorithm.\nMultipleReplicationRunner allows a user to run multiple parallel replications of a simulation experiment.\nScenarioManager allows a user to run multiple parallel replications of multiple scenarios\n\nStep 1: create a scenario\nA Scenario accepts the following arguments\n\nn_patients: int, the number of patients to sample.\nwarehouse: str or int, the location of the depot/warehouse/facility where the vehicles start and end their trips.\nvehicle_capacities: list, e.g [2, 3, 4].\n\ncost_matrix: pandas.DataFrame, A travel distance or travel time matrix between all locations.\npostcode_distribution: pandas.DataFrame, the distribution of patients by postcode.\np_positive: float, the probability a sampled patient is positive\np_transport: float, the probability a sampled patient required transport\n\n\n#import the Scenario data class\nfrom vrp.sim import Scenario\n\n\nHOSP_LOCATION = 'L51'\nN_PATIENTS = 15\nCAPACITIES = [2, 3, 4]\nP_POS = 1.0\nP_TRAN = 1.0\n\n#sim parameters\nscenario_15 = Scenario(n_patients=N_PATIENTS,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n\n\nStep 2: create a Vehicle Routing Solver\n\n#import the Clark-Wright Savings euristic and ILS/Constructive wrapper classes\nfrom vrp.constructive import SequentialClarkeWright\nfrom vrp.sim import ILSWithConstructive\n\n\nN_ITER = 20\nsolver = ILSWithConstructive(constructive=SequentialClarkeWright(HOSP_LOCATION),\n                             warehouse=HOSP_LOCATION, \n                             iterations=N_ITER)\n\n\n\nStep 3: Create a transport experiment\n\n#import the TransportExperiment class\nfrom vrp.sim import TransportExperiment\n\n\nmodel = TransportExperiment(scenario=scenario_15, \n                            solver=solver)\n\n\n\nStep 3: Test run a single experiment\nThis should execute in &lt; 1 second.\n\n#set random seed to get a reproducible run\nSEED = 19\nnp.random.seed(SEED)\n\nresult = model.single_replication()\n\n\n#the result is a python dict with total travel time by capacity of vehicle\nresult\n\n{'capacity_1': 962,\n 'capacity_2': 630.0,\n 'capacity_3': 494.0,\n 'capacity_4': 463.0}\n\n\n\n\nStep 4: Execute multiple independent replications in parallel\nIt will take several seconds to run 10 replications. Depending on the population size, number of ILS iterations, and number of replications runtime can vary from seconds to hours.\n\nfrom vrp.sim import MultipleReplicationRunner\n\n\nrunner = MultipleReplicationRunner(model=model, random_state=SEED)\n\n\nN_REPS = 10\nresults = runner.execute(n_reps=N_REPS)\n\n\n#results is a list of dicts\ntype(results)\n\nlist\n\n\n\nresults[0]\n\n{'capacity_1': 974.0,\n 'capacity_2': 643.0,\n 'capacity_3': 528.0,\n 'capacity_4': 505.0}\n\n\n\n#convert results to a pandas DataFrame\ndf_results = pd.DataFrame(results)\n\n\ndf_results.head(3)\n\n\n\n\n\n\n\n\n\ncapacity_1\ncapacity_2\ncapacity_3\ncapacity_4\n\n\n\n\n0\n974.0\n643.0\n528.0\n505.0\n\n\n1\n1140.0\n707.0\n613.0\n492.0\n\n\n2\n712.0\n505.0\n411.0\n393.0\n\n\n\n\n\n\n\n\n\n#y-acis is in minutes in this example, but could be travel distance\ndf_results.boxplot(figsize=(12,5))\n\n\n\n\n\n\n\n\n\n\nStep 5: Analyse multiple scenarios\nFirst create multiple scenario objects\n\nHOSP_LOCATION = 'L51'\nCAPACITIES = [2, 3, 4]\nP_POS = 1.0\nP_TRAN = 1.0\n\n#scenario where 15 patients are positive on a day\nscenario_15 = Scenario(n_patients=15,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n#scenario where 25 patients are positive on a day\nscenario_25 = Scenario(n_patients=25,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n#store these in a dict\nscenarios = {}\nscenarios['15_covid_positive'] = scenario_15\nscenarios['25_covid_positive'] = scenario_25\n\n\n#create a sce\nfrom vrp.sim import ScenarioManager\n\n\nSEED = 999\nmanager = ScenarioManager(scenarios, solver, random_state=SEED)\n\n\nscenario_results = manager.execute(N_REPS)\n\nRunning scenario: 15_covid_positive... done.\nRunning scenario: 25_covid_positive... done.\nAll experiments completed.\n\n\n\n#plot multiple scenarios in one figure\nfig, ax = plt.subplots(1, 2, figsize=(12,5), sharey=True)\nindex = 0\nfor scenario_name, result in scenario_results.items():\n    result.boxplot(ax=ax[index])\n    ax[index].set_title(scenario_name)\n    index += 1\n    \nax[0].set_ylabel('Travel Time (mins)');\n\n#uncomment to save to file...\n#fig.savefig('scenario_boxplots.png', dpi=300)\n\n\n\n\n\n\n\n\n\n#access one of the scenarios\nscenario_results['25_covid_positive']\n\n#uncomment to save results to file\n#scenario_results['25_covid_positive'].to_csv('single_scenario_result.csv')\n\n\n\n\n\n\n\n\n\ncapacity_1\ncapacity_2\ncapacity_3\ncapacity_4\n\n\n\n\n0\n1306.0\n834.0\n681.0\n586.0\n\n\n1\n1562.0\n976.0\n771.0\n706.0\n\n\n2\n1618.0\n1059.0\n868.0\n750.0\n\n\n3\n1896.0\n1175.0\n883.0\n799.0\n\n\n4\n1756.0\n1027.0\n827.0\n724.0\n\n\n5\n1250.0\n798.0\n618.0\n571.0\n\n\n6\n1732.0\n1095.0\n921.0\n854.0\n\n\n7\n1972.0\n1201.0\n966.0\n870.0\n\n\n8\n1514.0\n942.0\n720.0\n661.0\n\n\n9\n1150.0\n784.0\n681.0\n619.0\n\n\n\n\n\n\n\n\n\n### Doubling travel times\ntwo_way = scenario_results['25_covid_positive'] * 2\ntwo_way.boxplot(figsize=(12,5))"
  },
  {
    "objectID": "evaluation/reproduction_report.html",
    "href": "evaluation/reproduction_report.html",
    "title": "Computational reproducibility report",
    "section": "",
    "text": "Plain english summary"
  },
  {
    "objectID": "evaluation/badges.html",
    "href": "evaluation/badges.html",
    "title": "Badges",
    "section": "",
    "text": "This page evaluates the extent to which Monks et al.¬†2016 meets the criteria of badges related to reproducibility from various organisations and journals.\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\ncriteria = {\n    'archive': 'Code is stored in a permanent archive that is publicly and openly accessible',\n    'id': 'It has a persistent identifier (e.g. DOI)',\n    'license': 'It has an open license',\n    'complete_open': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    'meta': 'Metadata describes data/code sufficiently to enable reproduction (e.g. package versions)',\n    'statement': 'Manuscript has data availability statement',\n    # DUPE with complete_open above (to reflect on)\n    'complete_review': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    # DUPE with meta above (to reflect on)\n    'describe_minimal': 'There is a minimal but sufficient description of artefacts',\n    'describe_careful': 'There is a more detailed, careful documentation of artefacts',\n    'artefacts_structure': 'Artefacts are well structured to facilitate reuse, adhering to norms and standards of research community',\n    'regenerated': 'Independent party regenerated results using the authors research artefacts',\n    'hour': 'Reproduced within approximately one hour (excluding compute time)',\n    # DUPE with artefacts_structure and meta/describe\n    'reproduce_organise': 'Requires data and scripts to be well-organised, clearly documented and with a README file with step-by-step instructions on how to reproduce results in the manuscript'\n}\n\nbadge_names = {\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'open_niso': 'NISO \"Open Research Objects\"',\n    'open_acm': 'ACM \"Artifacts Available\"',\n    'open_cos_data': 'COS \"Open Data\"',\n    'open_cos_materials': 'COS \"Open Materials\"',\n    'open_cos_code': 'COS \"Open Code\"',\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'open_ieee_code': 'IEEE \"Code Available\"',\n    'open_ieee_data': 'IEEE \"Datasets Available\"',\n    'open_springer': 'Springer Nature \"Badge for Open Data\"',\n    'review_acm_functional': 'ACM \"Artifacts Evaluated - Functional\"',\n    'review_acm_reusable': 'ACM \"Artifacts Evaluated - Reusable\"',\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'review_ieee_code': 'IEEE \"Code Reviewed\"',\n    'review_ieee_data': 'IEEE \"Datasets Reviewed\"',\n    'reproduce_niso': 'NISO \"Results Reproduced\"',\n    'reproduce_acm': 'ACM \"Results Reproduced\"',\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'reproduce_ieee_code': 'IEEE \"Code Reproducible\"',\n    'reproduce_ieee_data': 'IEEE \"Dataset Reproducible\"',\n    'reproduce_psy': 'Psychological Science \"Computational Reproducibility\"'\n}\n\nopen_cos = ['archive', 'id', 'license', 'complete_open', 'meta']\n\nbadges = {\n    'open_niso': ['archive', 'id', 'license', 'complete_open'],\n    'open_acm': ['archive', 'id'],\n    'open_cos_data': open_cos,\n    'open_cos_materials': open_cos,\n    'open_cos_code': open_cos,\n    'open_ieee_code': ['complete_open'],\n    # etc. etc.\n}\n\n\nTO DO: Change to full list of criteria\nTO DO: Change to full list of badges\nTO DO: Add a table (perhaps minimise-able) that summarises the criteria of each badge, so can see how/why did or did not meet each of the badges.\n\n\nCode\n# Example (not done for Monks et al. 2016 yet)\n# Based on the criteria dictionary above, populate with 1 and 0\neval = pd.Series({\n    'archive': 1,\n    'id': 1,\n    'license': 0,\n    'complete_open': 1,\n    'meta': 1,\n    'statement': 1\n    # etc. etc.\n})\n\n\n\n\nCode\n# Print compliance to each criteria\nfor key, value in eval.items(): \n    if value == 1:\n        icon = '‚úÖ'\n    else:\n        icon = '‚¨ú'\n    print(f'{icon} {criteria[key]}')\n\n\n‚úÖ Code is stored in a permanent archive that is publicly and openly accessible\n‚úÖ It has a persistent identifier (e.g. DOI)\n‚¨ú It has an open license\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n‚úÖ Metadata describes data/code sufficiently to enable reproduction (e.g. package versions)\n‚úÖ Manuscript has data availability statement\n\n\n\n\nCode\n# Identify which badges would be awarded based on criteria\naward = {}\nfor badge in badges:\n    award[badge] = all([eval[key] == 1 for key in badges[badge]])\n\n# Print results\nfor key, value in award.items(): \n    if value:\n        icon = '‚úÖ'\n    else:\n        icon = '‚¨ú'\n    print(f'{icon} {badge_names[key]}')\n\n\n‚¨ú NISO \"Open Research Objects\"\n‚úÖ ACM \"Artifacts Available\"\n‚¨ú COS \"Open Data\"\n‚¨ú COS \"Open Materials\"\n‚¨ú COS \"Open Code\"\n‚úÖ IEEE \"Code Available\""
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html",
    "href": "evaluation/posts/2024_05_22/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Note\n\n\n\nSet-up, reading and defining scope. Total time used: 1h 13m (3%)"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#work-log",
    "href": "evaluation/posts/2024_05_22/index.html#work-log",
    "title": "Day 1",
    "section": "Work log",
    "text": "Work log\n\nUntimed: Inform the authors\nNot relevant for this, as it is a test-run using a paper Tom was involved with and is one of the corresponding authors on.\n\n\nUntimed: Made repository\nAs this is a test-run, was not made using a template (as it does not yet exist, but will be created based on this repository).\n\n\n12.11 - 12.16: Upload materials\nLinks to source of uploaded materials‚Ä¶\nArticle:\n\nhttps://doi.org/10.1371%2Fjournal.pone.0237628\n\nSupplementary materials:\n\nhttps://doi.org/10.1371/journal.pone.0237628.s001\nhttps://doi.org/10.1371/journal.pone.0237628.s002\n\nCode - both code sources should be the same and pretty much same data, hence used Zenodo as that is the archived version:\n\nhttps://zenodo.org/records/3760626\nhttps://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19\n\n\n\n12.18-12.19: Choose license\nNo need to change from MIT, as that was used by Allen et al.¬†2020.\n\n\nUntimed: Display article on website\nSet up article and supplementary to display on website in study_publication.qmd.\n\n\n13.20-13.56: Reading article\nRead article, making notes in study_summary.qmd (initially rough notes, then tidied slightly).\n\n\n\n\n\n\nNotes from read through of paper\n\n\n\n\n\nType of model: Discrete event simulation (excluding sections of the paper relevant to another model - a Monte-Carlo vehicle routing model of patient transport)\nPurpose of model: Model service delivery in dialysis network during change in COVID-19 cases.\nHow model was created:\n\nPython 3.8\nSimPy 3\nMatPlotLib\nSTRESS reporting guidelines\nDES on Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux\n\nContext:\n\nWessex - mixed urban/rural setting, renal dialysis services cares for 644 patients, nine centres. 75% of patients use patient transport services.\nCOVID-positive patients treated seperately to COVID-negative.\n\nModel design:\n\nModel change in inpatient and outpatient workload during pandemic at each dialysis unit in network. Estimate over three to six months. Estimate number of patients required to travel to different unit and change in travel time.\nInputs: Patient location postcode. Travel time routine. Worst case time spread COVID Fergeson. Mortality rate, time patient COVID-positive before admission, and inpatient rate of stay were local parameters.\nDefined period (e.g.¬†one year). Patients progress through phases of COVID (negative, positive, some with inpatient care, recovred, died). In each COVID state, model seeks to put them in appropriate unit and session, opening COVID-positive sessions in units that allow it. COVID-positive don‚Äôt mis with others.\nRun 30 times, show median and extremes.\n\n\n\n\nPatient pathway figure from Allen et al.¬†2020\n\n\n\nAll patients receive dialysis 3 times a week. Each patient starts on either Monday or Tuesday.\nHave proportion of patients either fixed or sampled from stochastic distribution for phases of COVID state and care.\nCOVID seperate from uninfected and recovered.\n\n\n\n\nBaseline model parameters from Allen et al.¬†2020\n\n\nFor allocation to units, use search strategy:\n\nCOVID negative or recovered - look for place in current unit, if no space, find closest unit (by travel time) with available space\nCOVID positive - put in Queen Alexandara, and if full, make capacity in Basingstoke. If new COVID session required, more all COVID negative patients in that session as per neg rules.\nCOVID positive inpatient - all in Queen Alexandra (but allows search for unit with inpatients)\nUnallocated - if can‚Äôt allocate to any units, attempt again next day\n\nOnce every week, attempts to reallocate patients back to starting unit or closest available. This is so cared more nearby and to compress COVID positive patients into few units and sessions.\nCOVID positive converted back to COVID negative when no longer needed.\nResults:\n\nStates current median travel time from home to dialysis unit, and current capacity.\nFigures 2, 3, 4 show impact of COVID infecting 80% patients in next three months.\n\nFigure 2 - number of patients in each COVID state over 150 days\nFigure 3 - as figure 2, but divided by unit? and with diffferent categories shown.\nFigure 4 - patients displced from current unit, and travel time added\n\nUsing half of Queen Alexandra and then Basingstoke for excess for COVID positive copes without any patients being unallocated to session and no need to reduce dialysis frequency.\nReduces workflow in units not taking COVID positive patients.\nDisplaced patients typically need 20 extra minutes to get to temporary care place (sometimes 50 minutes)\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 4\n\n\nDiscusion:\n\nDialysis unit can cope with worst case spread. Requires reallocation of patients, will impact on ambulance and efficiency.\nLikely significant patient partessures, current capacity breached, consider moving dislaysi requipment during peak COVID positive.\nTransporting individually unsustainable.(Markov?)\nModel limitations - assumes can reallocate immediatley, assumes current capacity maintained (i.e.¬†no staff shortage), not modelled timing, not included home dialysis.\n\n\n\n\n\n\n13.56-14.27: Identifying scope\nMade page for scope under evaluation - scope.qmd. Then went through process of:\n\nUploading tables and figures\nAdded each table and figure, and marking as being within scope or not\nLooking through paper for key results, focussing on abstract and results section.\nCompared those against the tables and figures to check if they are captured or not.\n\n\n\n\n\n\n\nNotes from identification of key results and comparison with figures\n\n\n\n\n\nAbstract:\n\nNeed secondary site, reduces workload in other sites, increases in primary site: ‚ÄúOutpatient COVID-19 cases will spillover to a secondary site while other sites will experience a reduction in workload. The primary site chosen to manage infected patients will experience a significant increase in outpatients and inpatients.‚Äù\n\nCaptured in Figure 3\n\nUp to 140 COVID positive with 40-90 inpatients, breaching capacity: ‚ÄúAt the peak of infection, it is predicted there will be up to 140 COVID-19 positive patients with 40 to 90 of these as inpatients, likely breaching current inpatient capacity.‚Äù\n\nCaptured in Figure 2 (combine yellow and red lines) and Figure 3 (having inpatients across two sites and not just one)\n\n\nResults:\n\nNo patients unallocated: ‚ÄúIn the planned strategy of using half of one of the largest units (Queen Alexandra) for COVID-positive dialysis outpatients, and then using a second unit (Basingstoke, also provid- ing up to half of its capacity for COVID-positive dialysis outpatient patients) for any excess, the dialysis system copes without any patients being unable to be allocated to a session (or without any need in dropping dialysis frequency). Workload in units that do not take COVID- positive outpatients will fall during the outbreak (though some work will flow back to them if they need to care for COVID-negative patients displaced from the units caring for COVID- positive patients).‚Äù\n\nInitially thought this was out of scope, but following chat with Tom, noticed that Figure 2 shows no unallocated (purple line)\n\nDisplaced patients have 20 minutes (sometimes up to 50) extra travel time ‚ÄúOutpatients may be displaced from their usual unit of care either because they need to travel to a COVID-positive session in another hospital, or because their unit has had to free up sessions for COVID-positive sessions. These patients typically require 20 minutes extra travel time to get to their temporary place of care (assuming they are travelling alone), with some requiring 50 minutes extra travel in each direction to/from dialysis.‚Äù\n\nVisible in Figure 4\n\n\n\n\n\n\n\nUntimed: Reorganising scope page\nReorganised into collapsible boxes for clearer layout.\n\n\nUntimed: Consensus decision on scope\nDiscussed scope with Tom Monks.\n\nCorrected ‚ÄúMarkov‚Äù is ‚ÄúMonte Carlo‚Äù.\nWhilst discussing, noticed that the number of unallocated patients is in Figure 2, so removed from scope.\nOtherwise agreed with scope.\n\n\n\nUntimed: Uploading to Zenodo\nNot doing for this one as it is a test-run."
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#timings",
    "href": "evaluation/posts/2024_05_22/index.html#timings",
    "title": "Day 1",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 0\n\n# Times from today\ntimes = [\n    ('12.11', '12.16'),\n    ('12.18', '12.19'),\n    ('13.20', '13.56'),\n    ('13.56', '14.27')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 73m, or 1h 13m\nTotal used to date: 73m, or 1h 13m\nTime remaining: 2327m, or 38h 47m\nUsed 3.0% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_05_22/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 1",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nProtocol:\n\n‚úÖ Suggest keeping a record of the links where uploaded materials were sourced from within the logbook (as below)\n‚úÖ Template will contain MIT but default, so modify this section to explain that it is about checking whether need to change from MIT.\n‚úÖ Suggest that create pages to display the journal article, supplementary and code at a point after having gone through the code familiarisation steps.\n‚úÖ Remove suggestion of creating a summary page (as STRESS-DES and ISPOR provide rigorous summaries, and summaries for sake of understanding make more sense to be in logbook)\n\n‚úÖ And therefore, suggest those reporting guidelines bit include copying and pasting information to answer each there, as much as appropriate (rather than just stating a section in the text to refer to)\n\n‚úÖ Make reference to particular pages in template (e.g.¬†when define scope, the file path to the scope template)\nFor defining scope, add a suggestion that the description of the sample is unlikely to be part of scope, and that focus is on the discrete event simulation and the results of that model, and use that to guide you when deciding what is in scope.\nFor scope, change from suggesting what to include, to it being a step by step of first look at tables and figures, then look at rest of text for key results, then evaluate whether those key results are covered by the tables and figures.\nAdd to stage when upload journal articles, that at the same time, they also download the images and tables from the article (not supplementary) as individual files and upload them to the repository too.\nFor scope, simplify protocol to just look for key results in abstract and results sections. Don‚Äôt think should really need to look in discussion or conclusion, as those are more interpretation focussed, and should otherwise be highlighted in abstract - but don‚Äôt make it prescriptive, just a recommendation, as focus here is just on finding key results, and recommending where they are likely to be in most (but not necessarily all) papers\n\nTemplate:\n\nIn license, have set ‚ÄúCopyright (c) 2024 STARS Project Team‚Äù - is this correct? Also, should it mention the original authors or not? Presuming not, as they will already have license file within that folder, and we will add yet another license file to the reproduction folder so it is stand alone.\nShould we have MIT license for reproduction/ and then CC-BY license for main repository?\n\nIn which case, would need to specify in repository that changing license in reproduction/ folder and not main folder. And explain somewhere what the license files apply to.\n\n\nOther:\n\nWe might sometimes only reproduce part of a study - for example, a paper with multiple models and we focus on the discrete-event simulation. Think about the impact this has, and whether we need to note this somewhere? For example, whether the badges would actually be awarded for this work (or whether that matters - or if important bit is about ability to reproduce the simulation)? Depending on planned output for this work (e.g.¬†if did want to explore publishing with Rescience C, what this would mean). Doesn‚Äôt change what we do during replication - just perhaps comments around it re: badges, and what we do with it."
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html",
    "href": "evaluation/posts/2024_05_23/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Time elapsed\n\n\n\nReviewing code and running model with reproduction of results between runs. Total time used: 4h 36m (11.5%)"
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html#work-log",
    "href": "evaluation/posts/2024_05_23/index.html#work-log",
    "title": "Day 2",
    "section": "Work log",
    "text": "Work log\n\n10.24-11.00 - Describe code/data\nLooked over code and data from original study, taking notes below.\n\n\n\n\n\n\nNotes from looking over their code and data\n\n\n\n\n\nCode files in main folder:\n\nCapacity_Model_Template.ipynb - explain DES model, input files, code example importing sim_replicate.py and using functions from that\nsim_replicate.py - importing from sim/, single and multiple runs of model, and multiple runs of prescribed scenarios, and function to get audit results from multiple runs, and parameters\nsim_single.py - single run of model\n\nOther files in main folder:\n\nCONTRIBUTING.md - lists Mike and Tom as the contributors\nenvironment.yaml - conda environment\n.gitignore\nLICENSE - MIT\nREADME.md - Instructs to use environment and then refer to .ipynb files\nTransport_Model_Template.ipynb - Monte Carlo Model\nmain_vrp.py - importing from vrp/, but otherwise very similar to part of sim_replicate (single and multiple runs, and parameters). VRP = vehicle routing problem?\n\nOther folders:\n\noutput/ - empty\npatient_geography_data/ - patient data\nsim/ - Discrete event\nvrp/ - Monte Carlo\n\n‚îú‚îÄ‚îÄ output\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ patient_geography_data\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ sim\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ vrp\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ CONTRIBUTING.md\n‚îú‚îÄ‚îÄ Capacity_Model_Template.ipynb\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ Transport_Model_Template.ipynb\n‚îú‚îÄ‚îÄ environment.yaml\n‚îú‚îÄ‚îÄ main_vrp.py\n‚îú‚îÄ‚îÄ sim_replicate.py\n‚îî‚îÄ‚îÄ sim_single.py\nMore details on patient_geography_data/ folder:\n\npatient_counts_no_home_or_IOW.csv - ? counts per postcode\npatients.csv - table of patients with type, postcode, site, first day, and blank COVID status column\ntravel_matrix_distance_km.csv - travel distance (km) between postcodes\ntravel_matrix_time_min.csv - travel time (min) between postcodes\n\n‚îú‚îÄ‚îÄ patient_geography_data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patient_counts_no_home_or_IOW.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patients.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ travel_matrix_distance_km.csv\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ travel_matrix_time_min.csv\nMore details on sim/ folder:\n\nallocation.py - methods to allocate patients to units and shifts\naudit.py - audit on patient and unit metrics\nend_trial_analysis.py - analysis after replicates, creates charts\nhelper_functions.py - expands multi-index\ninit.py - blank, to initalise as package\nmodel.py - model classes to hold patients, simulation model class\nparameters.py - classes for normal and uniform distributions, and class with parameters for scenario\npatient.py - patient class\npatients.csv - looks similar to patients.csv in main folder\ntravel_matrix.csv - patient travel times to each of the units\nunits.csv - information on each of the units\nunits.py - unit information from CSV\n\n‚îú‚îÄ‚îÄ sim\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ allocation.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ audit.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ end_trial_analysis.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ helper_functions.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ .ipynb_checkpoints\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ end_trial_analysis-checkpoint.py\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ helper_functions-checkpoint.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ parameters.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patient.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patients.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ travel_matrix.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ units.csv\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ units.py\n\n\n\n\n\nUntimed: Trying out WebPlotDigitizer\nTried using version 4, found it worked really well except:\n\nIt couldn‚Äôt differentiate confidence interval lines from the primary lines, which makes the resulting points hard to use.\nThe points extracted from these charts don‚Äôt necessarily align with the points obtained from the simulation (i.e.¬†line chart draws line through the days but points are at specific locations and not completely continuous).\n\nHence, I‚Äôm going to suggest that I don‚Äôt think it is worth trying to use this tool, and that a simpler and more standardised approach would be visual comparison of figures, or overlaying of the figures when possible.\n\n\nNA: Compile items in scope\nAll items are figures, so no actions required.\n\n\n12.10-12.15 Search for code that produces item in scope\nCapacity_Model_Template.ipynb creates figures incredibly similar to the article. Can spot a few slight differences likely due to different parameters. Some examples: * Figure 2, slightly wider confidence intervals in the notebook * Figure 4 number of displaced patients, different ‚Äúbumps‚Äù in the line\n\n\n12.15-12.16 Identify dependencies\nFrom article:\n\nDES on Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux\nPython 3.8\n\nWithin environment.yaml, can see packages and versions, to create a conda environment.\n\n\n12.19-12.29 Create environment\nCopied environment.yaml file into reproduction. Run the command conda env create --name covid19 --file environment.yaml from terminal within reproduction folder to create environment.\nFound that:\n\nReceived error CondaEnvException: Pip failed, for installing pip dependencies, Pip subprocess error: ImportError: libffi.so.7: cannot open shared object file: No such file or directory\n\nNoticed it was including Spyder in the environment which is an IDE so removed that.\n\nThis was then successful, and built quickly (within 30s). A quick glance over the environment confirmed that it looked to have the correct python version and packages.\n\n\n13.26-13.52 Reproduction\n\nCopied sim/ and sim_replicate.py into reproduction/.\nCopied code cells from Capacity_Model_Template.ipynb.\nError no module named joblib - add this to environment.yaml. Code was archived 22 April 2020, paper was published 13 August 2020. Used date of code archive, looking at https://pypi.org/project/joblib/#history, can see the version closest to prior to that date is 0.14.1 (10 Dec 2019) (as the next is 0.15.0 which is 15 May 2020). Add it to environment.yaml then ran conda env update --file environment.yaml --prune. This fixed the error.\nFileNotFoundError: [Errno 2] No such file or directory: ‚Äòoutput/base_3_month_reps_30_patient_audit.csv‚Äô. Not resolved by adding output/ folder.\n\nProtocol suggestion: On reflection, perhaps it would‚Äôve better to copy over the whole code folder into reproduction/ and then modify there, rather than copying over stuff bit by bit?\nSwitched to doing that -\n\nKept environment.yaml and example.ipynb, but otherwise copied everything over.\nDeleted irrelevant files\nRan again and it worked fine, didn‚Äôt get the FileNoteFoundError\n\nImages look similar to their notebook from Zenodo but, as with those figures, slight differences to paper, likely due to parameters.\n\n\nUntimed: Set up display of their code within the Quarto website\nBut can‚Äôt decide how best to display it - or if it is worth trying to display it all, or better just to suggest to browse the code repository themselves. Feels like an unhelpful distraction at present, and misleading compared to just allowing people to browse the code, so have suggested to change it to just displaying the PDFs and call it a day.\nUpdated the files accordingly.\n\n\n14.19-15.12 Reproduction\nOriginal:\n\nRun 1:\n\nRun 2:\n\n\nRan again and compared images to see if its varying between runs - it looked quite different! I saved each under new file names so not overwritten\nModel parameters input in the notebook look to match the paper (Table 1). Its 30 replications as in the paper too.\n\n\n\n\nTable 1\n\n\nnumber_of_replications = 30\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    total_proportion_people_infected = 0.8,\n    time_to_infection = Normal(60, 15, 0.0),\n    time_positive = Uniform(7, 14),\n    proportion_pos_requiring_inpatient= 0.6,\n    time_pos_before_inpatient = Uniform(3,7),\n    time_inpatient = Uniform(7.0, 14.0),\n    mortality = 0.15,\n    random_positive_rate_at_start = 0.0\n    )\n\nLooked through the paper and code for mention of ‚Äúseed‚Äù and ‚Äúrandom_state‚Äù - found:\n\nparameters.py - UniformParams has optional seed/random_state, generally set to random_state or None.\n\n\nThinking differences are defintely down to this. Thinking options are:\n\nLooking in their GitHub history in case they previously used random_state\nRun more replications than 30, to see what it settles on\nRun 30 replications, with a seed set each time, and then compare each against the article and see what comes closest. Make sure seed was set though! That might be tricky though‚Ä¶ as they haven‚Äôt established it with one‚Ä¶\n\nGitLab history:\nLooked into GitLab history at https://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19/-/commits/master.\nCan see there are releases more recent than Zenodo (22 April), which I had used, and the paper (received 28 april 2020, published 13 Aug 2020). All commits since the Zenodo publication was:\n\n22 April 2020 - Adding vrp tests\n23 April 2020 - Environment to binder/ and .yml\n23 April 2020 - Add link to binder in README\n23 April 2020 - Add Joblib to environment, 0.14.1 (which matches up with what I‚Äôd added)\n18 November 2020 - Fixed typo in .ipynb title\n\nNone of these would have any impact on results (besides it being re-run). Does confirm correct version of Joblib was used.\nThen looked back over older releases, but these were only just prior to the Zenodo publication (first was 20 April) and none use random state etc.\nRun more replications than 30\nAlthough it doesn‚Äôt match with the paper, I tried increasing replications to see what the figure averaged out to. However, then concluded that wasn‚Äôt particularly helpful in trying to get their results (although could be a way of saying that these are ‚Äúmore stable‚Äù results - although, it would impact on the confidence intervals and so on - if not able to set a seed).\nModifying script to set a random seed, to make the result I am getting from this code reproducible\nChange random_state in parameters.py from None to having a value for each in their class:\n\nNormalParams 1\nUniformParams 2\n\nOriginal:\n\nRun 1 with seeds added:\n\nRun 2 with seeds:\n\nHowever, this definitely has not fixed the issue! Still varying - and I wouldn‚Äôt be able to reproduce my own results twice either.\nwhat to do when there are multiple links to code like this - and add recommendations to protocol\nwhat to do when they don‚Äôt include a seed in a paper - and add recommendations to protocol\ndo we need to focus on the interpretations and whether they hold? but we didn‚Äôt really want to do that as that is not our focus? but in this case, is it, if we want to know if we‚Äôve reproduced, but can‚Äôt actually necessarily get the exact same results due to randomness?\nlook at tom‚Äôs more recent examples where he has added seeds\ntest! idea is to check that you are getting the same results between runs\n\n\n15.23-16.35 Reproduction\n\n\n\n\n\n\nRandom seeds\n\n\n\nAt the moment, I would describe this model as reusable but not reproducible. It was really relatively quick to get the code up and running and see similar results to the paper. But in terms of getting it to match up to the paper, it is pretty much impossible, although I will try to get their via setting random seeds then running it lots of times to try and get a close match.\nThis is important for STARS framework improvement - that controlling randomness is important for reproducibility. It can also be handy for someone reusing a model, as they may wish to reproduce just to verify that its running properly for them.\nAnd so for each of the studies, if this is a recurring thing that comes up, its seeing where and how to add random seeds in different models and languages, to enable reproducibility.\n\n\nFrom this Stack Overflow post, I‚Äôm suspcious that perhaps the issue is that I am setting the random state as 1 and 2, which (a) would imply it‚Äôs making it the same between each run, but (b) all using the same stream in parallel processing. But it‚Äôs set using RandomState.\nTrying to google around use of seeds with parallel processing.\nHad a chat with Tom about it and he suggested:\n\nHe pointed out that NormalParams is not being used, and that it would need to be setting a seed in the class Normal() when you use it in Scenario - e.g.¬†extra parameter at end of here -\n\nrequiring_inpatient_random: Distribution = Uniform(0.0, 1.0)\ntime_pos_before_inpatient: Distribution = Uniform(3,7)\n\nGood example of how set up, would recommend this - https://pythonhealthdatascience.github.io/stars-simpy-example-docs/content/02_model_code/04_model.html#distribution-classes\nLLM model generation of seeds\n\nNeed seperate random number streams for each time make a distribution to use it.\nI thought best option is to switch to using it how it is uses in the treat-sim model docs, as focus here is just modifying code to allow it to reproduce each run.\nSo next things I did -\n\nDelete the NormalParams and UniformParams classes as not used - checked if still run fine which it did.\nModified the Normal and Uniform so the random number sampling matches up with treat-sim model docs, and Scenario class so it‚Äôs similar (class itself is just set up a little differently)\nIn .ipynb, removed the parameters from Scenario() that were identical to those when Scenario is created (except seed setting)\n\nThen ran it twice again (this time just with 5 replications). Not matching up yet -\nRun 1 with new random method:\n\nRun 2:\n\nUpdating documentation after I‚Äôve made changes to it - not priority during reproduction unless feel important to make obvious, but priority during the research compendium stage, to make sure documetnation is all as it should be or just do as go along‚Ä¶"
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html#timings",
    "href": "evaluation/posts/2024_05_23/index.html#timings",
    "title": "Day 2",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 73\n\n# Times from today\ntimes = [\n    ('10.24', '11.00'),\n    ('12.10', '12.16'),\n    ('12.19', '12.29'),\n    ('13.26', '13.52'),\n    ('14.19', '15.12'),\n    ('15.23', '16.35')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 203m, or 3h 23m\nTotal used to date: 276m, or 4h 36m\nTime remaining: 2124m, or 35h 24m\nUsed 11.5% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_05_23/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 2",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nProtocol:\n\nJust suggestion not requirement to make notes about study, and make the notes within the logbook, as purpose is familiarising with study, and at this stage, may get details wrong! So rather than it be a seperate page where we‚Äôre worried about getting it right, do it in logbook as still learning.\nThere‚Äôs a balance between trying to understand the code, and just trying to run the code. Reading through and making notes on files is more along the lines of understanding, but without a direct purpose. Do we like it or not? It feels like a necessity, but it also feels a little unclear? Although perhaps that is ok. It felt like well used time to me, but would suggest not making it as prespective as I‚Äôd suggested, and that you and read and take notes if you like\nRemove sugestion of WebPlotDigitizer etc., and instead suggest standardised approach of visually comparing the figures (with overlaying where possible done to support that - need to explore simplest way of doing that).\nTo end of 3.2.3, suggest displaying those within the scope page also (that would be untimed though? although currently time writing out of scope above as that is just part of defining scope‚Ä¶ so maybe just include for simplicity?)\nModify 3.2.4 - as we describe the scope during 3.2.2\nRE: reproduction package, having the figures created within the notebooks if really handy when spotting what parts of the code create figures from article\nWith regards to creating the environment, I think taking the simplest approach is appropriate - so using their environment file (or creating based on packages), and not worrying about operating system used. Could consider that with regards to troubleshooting though.\n\nDon‚Äôt worry about operating system\nKeep suggestion about package list and versions using close to publication date but need to include instructions on HOW to find that out\nSimplest might just be looking manually for each of the packages. Can‚Äôt find a way to prevent it in Python. Knowing versions of the imported packages is as close as you get to if they provided a yaml file (as even with a yaml file, the dependencies they install alongside may be more recent). Go with this.\n\nFor 3.4.2, this is the first time we might start using and modifying materials, so important to note that we should COPY over any environment stuff into our reproduction folder/, and not directly run scripts in original_study/, those should stay untouched.\nTurn 3.5.1 into step-by-step instructions (e.g.¬†make notebook, copy over code, insert images from article, create images). Or perhaps just more bolding.\nFor 3.5.1, need to shift emphasis onto the key things of (a) copying over stuff when running, and (b) taking very detailed notes in the logbook as go along of each copy, change, success, error. Super super detailed!\nFor finding packages that were missing, base version date on Zenodo/code archive/github if possible/earlier than the paper - if later than the paper, then base on the paper - or just base on the paper.\nStill feels unclear on when we are setting up the website (showing article, showing code). Decision I have made from trying to display the code is that actually, the simplest and clearest thing is to let people explore the code themselves (just direct them to the right folder on the GitHub), whilst for the article, it takes one minute to embed the PDFs, so just have that step (plus adding link to where the scripts are) when upload the articles, and call it a day.\nTo do: move download sources from logbook to original study page (and modify as appropraite in protocol)\nAdd suggestion to save outputs as go, as and when appropriate, as it‚Äôs helpful to be able to include images in the logbook, for example. So perhaps, copying images from output into the logbook folder images. Yes. I‚Äôve started copying over and storing within the logbook folder, and just focusisng on e.g.¬†the figure I was looking at and not copying over all the data associated.\nCan I ask for advice on issues with reproduction from rest of team? Would presume so, and that include that in timing and record what is discussed and said.\n\nThoughts as reading through code:\n\nPEP8 of code (?)\nCommenting/docstrings (if not already) in code (?)\nData not all stored in one place, mixing scripts and data\nREADME stating what folders mean (e.g.¬†vrp, took me a little while to realise this stood for vehicle routing problem)\nLocations of parameters for simulation and finding them - convention is storing data seperately, but can be a little harder to spot where those parameters are\nIncluding an IDE within the dependencies (Spyder) created an issue, and also, am using own IDE. Or is that similar to when people require Jupyterlab?\nFor reproducing stuff, it‚Äôs helpful to know how long code takes to run?\nRemoving unused packages"
  },
  {
    "objectID": "evaluation/reproduction_success.html",
    "href": "evaluation/reproduction_success.html",
    "title": "Reproduction success",
    "section": "",
    "text": "A"
  }
]
[
  {
    "objectID": "evaluation/scope.html",
    "href": "evaluation/scope.html",
    "title": "Scope",
    "section": "",
    "text": "This page outlines that parts of the journal article which we will attempt to reproduce."
  },
  {
    "objectID": "evaluation/scope.html#within-scope",
    "href": "evaluation/scope.html#within-scope",
    "title": "Scope",
    "section": "Within scope",
    "text": "Within scope\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\nFigure 2. ‚ÄúPatient state over time by unit. The patient population progresses through infection over three months (with 80% infected). The bold line shows the median results of 30 trials, and the fainter lines show the minimum and maximum from the 30 trials.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\nFigure 3. ‚ÄúProgression of patient population through COVID infection, assuming 80% become infected over three months, with 15% mortality. The figure also shows the number of patients not allocated to a dialysis session at any time. The bold line shows the median results of 30 trials, and the fainter lines show the minimum and maximum from the 30 trials.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\n\n\n\n\n\n\n\nFigure 4. ‚ÄúPatient displacement. The number of patients displaced from their current unit (left panel) and the additional travel time to the unit of care (right panel) for displaced patients. These results do not include those receiving inpatient care. The patient population progresses through infection over three months (with 80% infected). The bold line shows the median results of 30 trials, and the fainter lines show the minimum and maximum from the 30 trials.‚Äù"
  },
  {
    "objectID": "evaluation/scope.html#outside-scope",
    "href": "evaluation/scope.html#outside-scope",
    "title": "Scope",
    "section": "Outside scope",
    "text": "Outside scope\n\n\n\n\n\n\nTable 1\n\n\n\n\n\nOutside scope as it is a table of model parameters rather than outputs.\n\n\n\nTable 1. ‚ÄúBaseline model parameters.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nOutside scope as it is a flow chart representing the model pathways.\n\n\n\nFigure 1. ‚ÄúSchematic representation of patient pathway.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 5\n\n\n\n\n\nOutside scope as it is a result of the Monte Carlo model.\n\n\n\nFigure 5. ‚ÄúOne-way ambulance transport time distributions (1000 model runs). Results compare population COVID-positive and ambulance seating capacity (e.g.¬†2 = 2 seats.) Figures do not include ambulance clean-down/turnaround time.‚Äù\n\n\n\n\n\n\n\n\n\n\n\nFigure 6\n\n\n\n\n\nOutside scope as it is a result of the Monte Carlo model.\n\n\n\nFigure 6. ‚ÄúTwo-way ambulance transport time distributions (1000 model runs). Results compare population COVID-positive and ambulance seating capacity (e.g.¬†2 = 2 seats.) Figures do not include ambulance clean-down/turnaround time.‚Äù"
  },
  {
    "objectID": "evaluation/logbook.html",
    "href": "evaluation/logbook.html",
    "title": "Logbook",
    "section": "",
    "text": "These diary entries record daily progress in reproduction of the study, providing a transparent and detailed record of work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 6\n\n\n\n\n\n\nguidelines\n\n\n\n\n\n\n\n\n\nJun 5, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 5\n\n\n\n\n\n\nguidelines\n\n\n\n\n\n\n\n\n\nJun 4, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 4\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nJun 3, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 3\n\n\n\n\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 2\n\n\n\n\n\n\nread\n\n\nreproduce\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\nAmy Heather\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nsetup\n\n\nread\n\n\nscope\n\n\n\n\n\n\n\n\n\nMay 22, 2024\n\n\nAmy Heather\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "evaluation/posts/2024_06_03/index.html",
    "href": "evaluation/posts/2024_06_03/index.html",
    "title": "Day 4",
    "section": "",
    "text": "Note\n\n\n\nChose a seed that produced fairly similar figures to paper. Decided that each figure had now been successfully reproduced. Total time used: 7h 6m (17.8%)."
  },
  {
    "objectID": "evaluation/posts/2024_06_03/index.html#work-log",
    "href": "evaluation/posts/2024_06_03/index.html#work-log",
    "title": "Day 4",
    "section": "Work log",
    "text": "Work log\n\n10.30-11.03 Modifying code to provide more control over replication seeds\nMade changes to sim_replicate.py:\n\nChanged multiple_replications() to accept a base number, so the random number set is the replication number plus the base number\nChanged run_replications() to accept base number to function, and input this to call of multiple_replications()\n\nStarted changing end_trial_analysis.py to enable the function to accept changes to the filename, but then decided a simpler solution (that doesn‚Äôt require changing their code in multiple places) is just to use os.rename() within our notebook. Set up notebook to run through 15 different base seeds. Paused timing whilst this ran‚Ä¶\n\n\n11.29-11.36 Fixed issue in duplication between my replications\nLooked over images, but all looked very similar to one another. Realised this was because my method for modifying the seeds still had lots of matching seeds between each run - for example:\n\nBase 0: Random number sets are 0-30\nBase 1: Random number sets are 1-31\nBase 2: Random number sets are 2-32\n\nHence, changed this in reproduction.ipynb so the base numbers were 0, 100, 200, 300 etc, and so:\n\nBase 0: Random number set 0-30\nBase 100: Random number set 100-130\nBase 200: Random number set 200-230\n\nThen paused timing as reran again‚Ä¶\n\n\n11.56-12.00 Compared against article figures\nCompared against paper figures. Figures 2 and 3 always generally look quite consistent. Figure 4 can look quite different, and from the runs I‚Äôve done, you can spot for example that our peaks in the left figure, and in the maximum of the right figure, often look lower.\nTrying again with another set of 15, this time 1500 to 2900.\nAn alternative to this would be to identify the number of replications required for stable results - but that feels like less of a focus on reproducibility, and more of a focus on valid results.\n\n\n\n\n\n\nSimulation stability\n\n\n\nFrom 15 different versions, I‚Äôm finding the peaks of the figures from the paper to be slightly higher than typical. Assuming that model parameters are correct and that control of randomness is now implemented appropriately, this highlights the relevance of simulation stability. Although 30 replications were performed, there was not assessment of whether this was the number needed for stability of results. This might be relevant to consider for STARS framework.\nAs in ‚ÄòSimulation: The Practice of Model Development and Use‚Äô by Stewart Robinson, there are three approaches for selecting the number of replications:\n\nRule of thumb - Law and McComas (1990) suggest at least 3-5, although models will often need more than that\nGraphical method - Plot cumulative mean of an output in a graph (X axis is replication number, and Y axis is cumulative mean), and identify when that line becomes flat\nConfidence interval method (recommended method) - Similar to above, but including confidence intervals in the plot (e.g.¬†95%), and basing decision on narrowness of these itnervals. This can be done by calculating the percentage deviations of the confidence interval on each side of the mean with the increasing number of replications. You then set a threshold of the amount of deviation desired.\n\n\n\n\n\n12.19-12.45 Comparing against original paper\nStill none with similar blue peak, but decided appropriate number of different seeds have now been tried. From visual comparison, felt base of 2700 produced results that were fairly visually similar - but from looking across them all, often there wasn‚Äôt alot between them.\nHere are comparisons of:\n\nOriginal study figure\nFigure from base 2700\nFigure from base 2100 (which you can see looks more different from the original than base 2700 - although still pretty similar!)\n\nExamples of differences to spot between them:\n\nPeaks of lines in left figure of Figure 4 (and resultant Y axis)\nPeaks of red line in right figure of Figure 4\nInterval of green line in Figure 2\n\n\n\n\n\n\n\nOriginal Figure 2: \n\n\nBase 2700: \n\n\nBase 2100: \n\n\n\n\n\n\n\n\n\nOriginal Figure 3: \n\n\nBase 2700: \n\n\nBase 2100: \n\n\n\n\n\n\n\n\n\nOriginal Figure 4: \n\n\nBase 2700: \n\n\nBase 2100: \n\n\n\nAs I believe the parameters are consistent with the paper (as checked on Day 2), and as the models successfully run and produce broadly similar figures (with differences believed to be due to randomness/seeds, and related to simulation stability with this number of replications), I hence believe that at this point, reproduction is complete, and that each of these figures can be considered a successful reproduction.\n\n\n16.13-16.24 Tidying the notebook, and creating reproduction success page\nSimplified the reproduction notebook to just use the base number 2700, deleting the other results.\nCreated a reproduction success page, presenting those figures alongside the figures from the original study.\nNot archiving on Zenodo as this is the test-run."
  },
  {
    "objectID": "evaluation/posts/2024_06_03/index.html#timings",
    "href": "evaluation/posts/2024_06_03/index.html#timings",
    "title": "Day 4",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 345\n\n# Times from today\ntimes = [\n    ('10.30', '11.03'),\n    ('11.29', '11.36'),\n    ('11.56', '12.00'),\n    ('12.19', '12.45'),\n    ('16.13', '16.24')]\n\n# Print time used and remaining\ncalculate_times(used_to_date, times)\n\nTime spent today: 81m, or 1h 21m\nTotal used to date: 426m, or 7h 6m\nTime remaining: 1974m, or 32h 54m\nUsed 17.8% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_06_03/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_06_03/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 4",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nProtocol:\n\n‚úÖ Reproduction complete not necessarily when figures exactly match, but when you think they are quite similar and you think differences are due to things like seeds/randomness, and model stability"
  },
  {
    "objectID": "evaluation/posts/2024_06_04/index.html",
    "href": "evaluation/posts/2024_06_04/index.html",
    "title": "Day 5",
    "section": "",
    "text": "Note\n\n\n\nEvaluated study against guidelines (badges, sharing artefacts, and starting on STRESS-DES reporting)."
  },
  {
    "objectID": "evaluation/posts/2024_06_04/index.html#work-log",
    "href": "evaluation/posts/2024_06_04/index.html#work-log",
    "title": "Day 5",
    "section": "Work log",
    "text": "Work log\n\nBadges\nEvaluating artefacts as in https://zenodo.org/records/3760626 and https://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19.\nUncertainties:\n\nexecute: ‚ÄúScripts can be successfully executed‚Äù (and then regenerated: ‚ÄúIndependent party regenerated results using the authors research artefacts‚Äù)\n\nRequired some minor changes to environment in order for scripts to run\nHowever, not certain whether the badges would allow minor troubleshooting (or major troubleshooting) in order for a script to run?\nBy my criteria (allowing troubleshooting) this would be fine. The step up from this criteria is reproduction (which I again allow troubleshooting) - so it would make sense that this is getting it to run, whilst next step is getting sufficiently similar results. May just need to add a caveat that this is with troubleshooting allowed (which may not be journal policy) - in same way that caveat, this is my interpretation of badges from available information and cannot guarantee would or would not be awarded.\nChat with Tom: Fine to just caveat.\n\nhour: Reproduced within approximately one hour (excluding compute time)\n\nTook longer than an hour, but I wasn‚Äôt trying to get it done in that time\nIf I hadn‚Äôt spent time reading and documenting and fiddling with the seeds, then I anticipate I could‚Äôve run it within an hour\nHowever, I‚Äôm assuming to follow our process and fail it (for consistency with how we are working and timing)\nChat with Tom: Fine to just caveat.\n\ndocumentation_readme: ‚ÄúArtefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript‚Äù\n\nI wouldn‚Äôt say it explicitly meets this criteria\nAlthough it was simple enough that it could do it anyway - directed me to notebook, run that, job done.\nUncertain on this one\nUncertainty is fine - just make a choice, and justify and document that choice in the logbook\n\n\n\n\nSharing research artefacts\nEvaluated again, this time against recommendations for sharing of research artefacts (STARS, and Monks and Harper best practice audit).\nUncertainties:\n\nREADME: ‚ÄúDoes the readme file or similar describe the steps required to execute the simulation model?‚Äù\n\nFor this, is it sufficient that README is provided which explains environment and links to template that runs model? I‚Äôm assuming so.\nHowever, this decision differs from documentation_readme above, although that requires ‚Äúclear‚Äù documentation\n\nDo they meet criteria is changes are made to a repository after publications? (this is general, not specific to this test-run)\n\nExample: If we asked them to add a licence - do we then fail them on that? I‚Äôm presuming so?\nChat with Tom: Agree that it should be based on stuff prior to publication.\n\n\n\n\nEvaluation against reporting guidelines (STRESS-DES pt.¬†1)\nThese were evaluated based ONLY on the journal article and supplementary materials (and not on the linked code repository).\nStarted work on evaluating against STRESS-DES.\n\n\n\n\n\n\nIncluding checklist\n\n\n\nTom mentioned how this study they provided the filled out STRESS checklist to the journal, but it wasn‚Äôt published alongside the article, but that would have been beneficial. This is a good suggestion to think about.\nAlso, it has proven quite time consuming to evaluate against the checklist - hence, moreso reason to include it with the article, to make it easier for readers to spot these things."
  },
  {
    "objectID": "evaluation/posts/2024_06_04/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_06_04/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 5",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nüí¨ = Noted to discuss with team.\nProtocol:\n\n‚úÖ Suggest that uncertainties on whether a badge criteria is met or not could be discussed within the STARS team. Suggest to detail those uncertainties within logbook\n‚úÖ If there are multiple code locations (e.g.¬†code repository and archive), then refer to both when assessing against criteria\n‚úÖ Recommended sources for evaluation (e.g.¬†reporting guidelines is based on article, badges and sharing of research artefacts are based on code)\nüí¨ Given how long it is taking, would it be relevant to time these steps?"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html",
    "href": "evaluation/posts/2024_05_22/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Note\n\n\n\nSet-up, reading and defining scope. Total time used: 1h 13m (3%)"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#work-log",
    "href": "evaluation/posts/2024_05_22/index.html#work-log",
    "title": "Day 1",
    "section": "Work log",
    "text": "Work log\n\nUntimed: Inform the authors\nNot relevant for this, as it is a test-run using a paper Tom was involved with and is one of the corresponding authors on.\n\n\nUntimed: Made repository\nAs this is a test-run, was not made using a template (as it does not yet exist, but will be created based on this repository).\n\n\n12.11 - 12.16: Upload materials\nLinks to source of uploaded materials‚Ä¶\nArticle:\n\nhttps://doi.org/10.1371%2Fjournal.pone.0237628\n\nSupplementary materials:\n\nhttps://doi.org/10.1371/journal.pone.0237628.s001\nhttps://doi.org/10.1371/journal.pone.0237628.s002\n\nCode - both code sources should be the same and pretty much same data, hence used Zenodo as that is the archived version:\n\nhttps://zenodo.org/records/3760626\nhttps://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19\n\n\n\n12.18-12.19: Choose license\nNo need to change from MIT, as that was used by Allen et al.¬†2020.\n\n\nUntimed: Display article on website\nSet up article and supplementary to display on website in study_publication.qmd.\n\n\n13.20-13.56: Reading article\nRead article, making notes in study_summary.qmd (initially rough notes, then tidied slightly).\n\n\n\n\n\n\nNotes from read through of paper\n\n\n\n\n\nType of model: Discrete event simulation (excluding sections of the paper relevant to another model - a Monte-Carlo vehicle routing model of patient transport)\nPurpose of model: Model service delivery in dialysis network during change in COVID-19 cases.\nHow model was created:\n\nPython 3.8\nSimPy 3\nMatPlotLib\nSTRESS reporting guidelines\nDES on Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux\n\nContext:\n\nWessex - mixed urban/rural setting, renal dialysis services cares for 644 patients, nine centres. 75% of patients use patient transport services.\nCOVID-positive patients treated seperately to COVID-negative.\n\nModel design:\n\nModel change in inpatient and outpatient workload during pandemic at each dialysis unit in network. Estimate over three to six months. Estimate number of patients required to travel to different unit and change in travel time.\nInputs: Patient location postcode. Travel time routine. Worst case time spread COVID Fergeson. Mortality rate, time patient COVID-positive before admission, and inpatient rate of stay were local parameters.\nDefined period (e.g.¬†one year). Patients progress through phases of COVID (negative, positive, some with inpatient care, recovred, died). In each COVID state, model seeks to put them in appropriate unit and session, opening COVID-positive sessions in units that allow it. COVID-positive don‚Äôt mis with others.\nRun 30 times, show median and extremes.\n\n\n\n\nPatient pathway figure from Allen et al.¬†2020\n\n\n\nAll patients receive dialysis 3 times a week. Each patient starts on either Monday or Tuesday.\nHave proportion of patients either fixed or sampled from stochastic distribution for phases of COVID state and care.\nCOVID seperate from uninfected and recovered.\n\n\n\n\nBaseline model parameters from Allen et al.¬†2020\n\n\nFor allocation to units, use search strategy:\n\nCOVID negative or recovered - look for place in current unit, if no space, find closest unit (by travel time) with available space\nCOVID positive - put in Queen Alexandara, and if full, make capacity in Basingstoke. If new COVID session required, more all COVID negative patients in that session as per neg rules.\nCOVID positive inpatient - all in Queen Alexandra (but allows search for unit with inpatients)\nUnallocated - if can‚Äôt allocate to any units, attempt again next day\n\nOnce every week, attempts to reallocate patients back to starting unit or closest available. This is so cared more nearby and to compress COVID positive patients into few units and sessions.\nCOVID positive converted back to COVID negative when no longer needed.\nResults:\n\nStates current median travel time from home to dialysis unit, and current capacity.\nFigures 2, 3, 4 show impact of COVID infecting 80% patients in next three months.\n\nFigure 2 - number of patients in each COVID state over 150 days\nFigure 3 - as figure 2, but divided by unit? and with diffferent categories shown.\nFigure 4 - patients displced from current unit, and travel time added\n\nUsing half of Queen Alexandra and then Basingstoke for excess for COVID positive copes without any patients being unallocated to session and no need to reduce dialysis frequency.\nReduces workflow in units not taking COVID positive patients.\nDisplaced patients typically need 20 extra minutes to get to temporary care place (sometimes 50 minutes)\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 4\n\n\nDiscusion:\n\nDialysis unit can cope with worst case spread. Requires reallocation of patients, will impact on ambulance and efficiency.\nLikely significant patient partessures, current capacity breached, consider moving dislaysi requipment during peak COVID positive.\nTransporting individually unsustainable.(Markov?)\nModel limitations - assumes can reallocate immediatley, assumes current capacity maintained (i.e.¬†no staff shortage), not modelled timing, not included home dialysis.\n\n\n\n\n\n\n13.56-14.27: Identifying scope\nMade page for scope under evaluation - scope.qmd. Then went through process of:\n\nUploading tables and figures\nAdded each table and figure, and marking as being within scope or not\nLooking through paper for key results, focussing on abstract and results section.\nCompared those against the tables and figures to check if they are captured or not.\n\n\n\n\n\n\n\nNotes from identification of key results and comparison with figures\n\n\n\n\n\nAbstract:\n\nNeed secondary site, reduces workload in other sites, increases in primary site: ‚ÄúOutpatient COVID-19 cases will spillover to a secondary site while other sites will experience a reduction in workload. The primary site chosen to manage infected patients will experience a significant increase in outpatients and inpatients.‚Äù\n\nCaptured in Figure 3\n\nUp to 140 COVID positive with 40-90 inpatients, breaching capacity: ‚ÄúAt the peak of infection, it is predicted there will be up to 140 COVID-19 positive patients with 40 to 90 of these as inpatients, likely breaching current inpatient capacity.‚Äù\n\nCaptured in Figure 2 (combine yellow and red lines) and Figure 3 (having inpatients across two sites and not just one)\n\n\nResults:\n\nNo patients unallocated: ‚ÄúIn the planned strategy of using half of one of the largest units (Queen Alexandra) for COVID-positive dialysis outpatients, and then using a second unit (Basingstoke, also provid- ing up to half of its capacity for COVID-positive dialysis outpatient patients) for any excess, the dialysis system copes without any patients being unable to be allocated to a session (or without any need in dropping dialysis frequency). Workload in units that do not take COVID- positive outpatients will fall during the outbreak (though some work will flow back to them if they need to care for COVID-negative patients displaced from the units caring for COVID- positive patients).‚Äù\n\nInitially thought this was out of scope, but following chat with Tom, noticed that Figure 2 shows no unallocated (purple line)\n\nDisplaced patients have 20 minutes (sometimes up to 50) extra travel time ‚ÄúOutpatients may be displaced from their usual unit of care either because they need to travel to a COVID-positive session in another hospital, or because their unit has had to free up sessions for COVID-positive sessions. These patients typically require 20 minutes extra travel time to get to their temporary place of care (assuming they are travelling alone), with some requiring 50 minutes extra travel in each direction to/from dialysis.‚Äù\n\nVisible in Figure 4\n\n\n\n\n\n\n\nUntimed: Reorganising scope page\nReorganised into collapsible boxes for clearer layout.\n\n\nUntimed: Consensus decision on scope\nDiscussed scope with Tom Monks.\n\nCorrected ‚ÄúMarkov‚Äù is ‚ÄúMonte Carlo‚Äù.\nWhilst discussing, noticed that the number of unallocated patients is in Figure 2, so removed from scope.\nOtherwise agreed with scope.\n\n\n\nUntimed: Uploading to Zenodo\nNot doing for this one as it is a test-run."
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#timings",
    "href": "evaluation/posts/2024_05_22/index.html#timings",
    "title": "Day 1",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 0\n\n# Times from today\ntimes = [\n    ('12.11', '12.16'),\n    ('12.18', '12.19'),\n    ('13.20', '13.56'),\n    ('13.56', '14.27')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 73m, or 1h 13m\nTotal used to date: 73m, or 1h 13m\nTime remaining: 2327m, or 38h 47m\nUsed 3.0% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_05_22/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 1",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nüí¨ = Noted to discuss with team.\nProtocol:\n\n‚úÖ Suggest keeping a record of the links where uploaded materials were sourced from within the logbook (as below)\n‚úÖ Template will contain MIT but default, so modify this section to explain that it is about checking whether need to change from MIT.\n‚úÖ Suggest that create pages to display the journal article, supplementary and code at a point after having gone through the code familiarisation steps.\n‚úÖ Remove suggestion of creating a summary page (as STRESS-DES and ISPOR provide rigorous summaries, and summaries for sake of understanding make more sense to be in logbook)\n\n‚úÖ And therefore, suggest those reporting guidelines bit include copying and pasting information to answer each there, as much as appropriate (rather than just stating a section in the text to refer to)\n\n‚úÖ Make reference to particular pages in template (e.g.¬†when define scope, the file path to the scope template)\n‚úÖ For scope, suggest focus is on results of simulation, rather than other results like description of sample\n‚úÖ For scope, change from suggesting what to include, to it being a step by step of first look at tables and figures, then look at rest of text for key results, then evaluate whether those key results are covered by the tables and figures.\n‚úÖ When upload journal articles, require to also download the images and tables from the article (not supplementary) as individual files and upload them to the repository too.\n‚úÖ For scope, simplify protocol to just look for key results in abstract and results sections. Don‚Äôt think should really need to look in discussion or conclusion, as those are more interpretation focussed, and should otherwise be highlighted in abstract - but don‚Äôt make it prescriptive, just a recommendation, as focus here is just on finding key results, and recommending where they are likely to be in most (but not necessarily all) papers\n\nTemplate:\n\nüí¨ In license, have set ‚ÄúCopyright (c) 2024 STARS Project Team‚Äù - is this correct? Also, should it mention the original authors or not? Presuming not, as they will already have license file within that folder, and we will add yet another license file to the reproduction folder so it is stand alone.\nüí¨ Should we have MIT license for reproduction/ and then CC-BY license for main repository? In which case, would need to specify in repository that changing license in reproduction/ folder and not main folder. And explain somewhere what the license files apply to.\n\nOther:\n\nüí¨ We might sometimes only reproduce part of a study - for example, a paper with multiple models and we focus on the discrete-event simulation. Think about the impact this has, and whether we need to note this somewhere? For example, whether the badges would actually be awarded for this work (or whether that matters - or if important bit is about ability to reproduce the simulation)? Depending on planned output for this work (e.g.¬†if did want to explore publishing with Rescience C, what this would mean). Doesn‚Äôt change what we do during replication - just perhaps comments around it re: badges, and what we do with it."
  },
  {
    "objectID": "evaluation/badges.html",
    "href": "evaluation/badges.html",
    "title": "Badges",
    "section": "",
    "text": "This page evaluates the extent to which the author-published research artefacts meet the criteria of badges related to reproducibility from various organisations and journals.\nCaveat: Please note that these criteria are based on available information about each badge online, and that we have likely differences in our procedure (e.g.¬†allowed troubleshooting for execution and reproduction, not under tight time pressure to complete). We cannot guarantee that the badges below would have been awarded in practice by these journals."
  },
  {
    "objectID": "evaluation/badges.html#criteria",
    "href": "evaluation/badges.html#criteria",
    "title": "Badges",
    "section": "Criteria",
    "text": "Criteria\n\n\nCode\nfrom IPython.display import display, Markdown\nimport numpy as np\nimport pandas as pd\n\n# Criteria and their definitions\ncriteria = {\n    'archive': 'Stored in a permanent archive that is publicly and openly accessible',\n    'id': 'Has a persistent identifier',\n    'license': 'Includes an open license',\n    'relevant': '''Arefacts are relevant to and contribute to the article's results''',\n    'complete': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    'structure': 'Artefacts are well structured/organised (e.g. to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)',\n    'documentation_sufficient': 'Artefacts are sufficiently documented (i.e. to understand how it works, to enable it to be run, including package versions)',\n    'documentation_careful': 'Artefacts are carefully documented (more than sufficient - i.e. to the extent that reuse and repurposing is facilitated (e.g. changing parameters, reusing for own purpose))',\n    # This criteria is kept seperate to documentation_careful, as it specifically requires a README file\n    'documentation_readme': 'Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript',\n    'execute': 'Scripts can be successfully executed',\n    'regenerated': 'Independent party regenerated results using the authors research artefacts',\n    'hour': 'Reproduced within approximately one hour (excluding compute time)',\n}\n\n# Evaluation for this study\neval = pd.Series({\n    'archive': 1,\n    'id': 1,\n    'license': 1,\n    'complete': 1,\n    'documentation_sufficient': 1,\n    'documentation_careful': 0,\n    'relevant': 1,\n    'execute': 1,\n    'structure': 1,\n    'regenerated': 1,\n    'hour': 0,\n    'documentation_readme': 0,\n})\n\n# Get list of criteria met (True/False) overall\neval_list = list(eval)\n\n# Define function for creating the markdown formatted list of criteria met\ndef create_criteria_list(criteria_dict):\n    '''\n    Creates a string which contains a Markdown formatted list with icons to\n    indicate whether each criteria was met\n\n    Parameters:\n    -----------\n    criteria_dict : dict\n        Dictionary where keys are the criteria (variable name) and values are\n        Boolean (True/False of whether this study met the criteria)\n\n    Returns:\n    --------\n    formatted_list : string\n        Markdown formatted list\n    '''\n    callout_icon = {True: '‚úÖ',\n                    False: '‚ùå'}\n    # Create list with...\n    formatted_list = ''.join([\n        '* ' +\n        callout_icon[eval[key]] + # Icon based on whether it met criteria\n        ' ' +\n        value + # Full text description of criteria\n        '\\n' for key, value in criteria_dict.items()])\n    return(formatted_list)\n\n# Define groups of criteria\ncriteria_share_how = ['archive', 'id', 'license']\ncriteria_share_what = ['relevant', 'complete']\ncriteria_doc_struc = ['structure', 'documentation_sufficient', 'documentation_careful', 'documentation_readme']\ncriteria_run = ['execute', 'regenerated', 'hour']\n\n# Create text section\ndisplay(Markdown(f'''\nTo assess whether the author's materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\n\nThis study met **{sum(eval_list)} of the {len(eval_list)}** unique criteria items. These were as follows:\n\nCriteria related to how artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_how})}\n\nCriteria related to what artefacts are shared -\n\n{create_criteria_list({k: criteria[k] for k in criteria_share_what})}\n\nCriteria related to the structure and documentation of the artefacts -\n\n{create_criteria_list({k: criteria[k] for k in criteria_doc_struc})}\n\nCriteria related to running and reproducing results -\n\n{create_criteria_list({k: criteria[k] for k in criteria_run})}\n'''))\n\n\nTo assess whether the author‚Äôs materials met the requirements of each badge, a list of criteria was produced. Between each badge (and between categories of badge), there is often alot of overlap in criteria.\nThis study met 9 of the 12 unique criteria items. These were as follows:\nCriteria related to how artefacts are shared -\n\n‚úÖ Stored in a permanent archive that is publicly and openly accessible\n‚úÖ Has a persistent identifier\n‚úÖ Includes an open license\n\nCriteria related to what artefacts are shared -\n\n‚úÖ Arefacts are relevant to and contribute to the article‚Äôs results\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n\nCriteria related to the structure and documentation of the artefacts -\n\n‚úÖ Artefacts are well structured/organised (e.g.¬†to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n‚úÖ Artefacts are sufficiently documented (i.e.¬†to understand how it works, to enable it to be run, including package versions)\n‚ùå Artefacts are carefully documented (more than sufficient - i.e.¬†to the extent that reuse and repurposing is facilitated (e.g.¬†changing parameters, reusing for own purpose))\n‚ùå Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript\n\nCriteria related to running and reproducing results -\n\n‚úÖ Scripts can be successfully executed\n‚úÖ Independent party regenerated results using the authors research artefacts\n‚ùå Reproduced within approximately one hour (excluding compute time)"
  },
  {
    "objectID": "evaluation/badges.html#badges",
    "href": "evaluation/badges.html#badges",
    "title": "Badges",
    "section": "Badges",
    "text": "Badges\n\n\nCode\n# Full badge names\nbadge_names = {\n    # Open objects\n    'open_niso': 'NISO \"Open Research Objects (ORO)\"',\n    'open_niso_all': 'NISO \"Open Research Objects - All (ORO-A)\"',\n    'open_acm': 'ACM \"Artifacts Available\"',\n    'open_cos': 'COS \"Open Code\"',\n    'open_ieee': 'IEEE \"Code Available\"',\n    # Object review\n    'review_acm_functional': 'ACM \"Artifacts Evaluated - Functional\"',\n    'review_acm_reusable': 'ACM \"Artifacts Evaluated - Reusable\"',\n    'review_ieee': 'IEEE \"Code Reviewed\"',\n    # Results reproduced\n    'reproduce_niso': 'NISO \"Results Reproduced (ROR-R)\"',\n    'reproduce_acm': 'ACM \"Results Reproduced\"',\n    'reproduce_ieee': 'IEEE \"Code Reproducible\"',\n    'reproduce_psy': 'Psychological Science \"Computational Reproducibility\"'\n}\n\n# Criteria required by each badge\nbadges = {\n    # Open objects\n    'open_niso': ['archive', 'id', 'license'],\n    'open_niso_all': ['archive', 'id', 'license', 'complete'],\n    'open_acm': ['archive', 'id'],\n    'open_cos': ['archive', 'id', 'license', 'complete', 'documentation_sufficient'],\n    'open_ieee': ['complete'],\n    # Object review\n    'review_acm_functional': ['documentation_sufficient', 'relevant', 'complete', 'execute'],\n    'review_acm_reusable': ['documentation_sufficient', 'documentation_careful', 'relevant', 'complete', 'execute', 'structure'],\n    'review_ieee': ['complete', 'execute'],\n    # Results reproduced\n    'reproduce_niso': ['regenerated'],\n    'reproduce_acm': ['regenerated'],\n    'reproduce_ieee': ['regenerated'],\n    'reproduce_psy': ['regenerated', 'hour', 'structure', 'documentation_readme'],\n}\n\n# Identify which badges would be awarded based on criteria\n# Get list of badges met (True/False) overall\naward = {}\nfor badge in badges:\n    award[badge] = all([eval[key] == 1 for key in badges[badge]])\naward_list = list(award.values())\n\n# Write introduction\n# Get list of badges met (True/False) by category\naward_open = [v for k,v in award.items() if k.startswith('open_')]\naward_review = [v for k,v in award.items() if k.startswith('review_')]\naward_reproduce = [v for k,v in award.items() if k.startswith('reproduce_')]\n\n# Create and display text for introduction\ndisplay(Markdown(f'''\nIn total, the original study met the criteria for **{sum(award_list)} of the {len(award_list)} badges**. This included:\n\n* **{sum(award_open)} of the {len(award_open)}** ‚Äúopen objects‚Äù badges\n* **{sum(award_review)} of the {len(award_review)}** ‚Äúobject review‚Äù badges\n* **{sum(award_reproduce)} of the {len(award_reproduce)}** ‚Äúreproduced‚Äù badges\n'''))\n\n# Make function that creates collapsible callouts for each badge\ndef create_badge_callout(award_dict):\n    '''\n    Displays Markdown callouts created for each badge in the dictionary, showing\n    whether the criteria for that badge was met.\n\n    Parameters:\n    -----------\n    award_dict : dict\n        Dictionary where key is badge (as variable name), and value is Boolean\n        (whether badge is awarded)\n    '''\n    callout_appearance = {True: 'tip',\n                          False: 'warning'}\n    callout_icon = {True: '‚úÖ',\n                    False: '‚ùå'}\n    callout_text = {True: 'Meets all criteria:',\n                    False: 'Does not meet all criteria:'}\n\n    for key, value in award_dict.items():\n        # Create Markdown list with...\n        criteria_list = ''.join([\n            '* ' +\n            callout_icon[eval[k]] + # Icon based on whether it met criteria\n            ' ' +\n            criteria[k] + # Full text description of criteria\n            '\\n' for k in badges[key]])\n        # Create the callout and display it\n        display(Markdown(f'''\n::: {{.callout-{callout_appearance[value]} appearance=\"minimal\" collapse=true}}\n\n## {callout_icon[value]} {badge_names[key]}\n\n{callout_text[value]}\n\n{criteria_list}\n:::\n'''))\n\n# Create badge functions with introductions and callouts\ndisplay(Markdown('''\n### \"Open objects\" badges\n\nThese badges relate to research artefacts being made openly available.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('open_')})\n\ndisplay(Markdown('''\n### \"Object review\" badges\n\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('review_')})\n\ndisplay(Markdown('''\n### \"Reproduced\" badges\n\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n'''))\ncreate_badge_callout({k: v for (k, v) in award.items() if k.startswith('reproduce_')})\n\n\nIn total, the original study met the criteria for 10 of the 12 badges. This included:\n\n5 of the 5 ‚Äúopen objects‚Äù badges\n2 of the 3 ‚Äúobject review‚Äù badges\n3 of the 4 ‚Äúreproduced‚Äù badges\n\n\n\n‚ÄúOpen objects‚Äù badges\nThese badges relate to research artefacts being made openly available.\n\n\n\n\n\n\n\n\n‚úÖ NISO ‚ÄúOpen Research Objects (ORO)‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Stored in a permanent archive that is publicly and openly accessible\n‚úÖ Has a persistent identifier\n‚úÖ Includes an open license\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ NISO ‚ÄúOpen Research Objects - All (ORO-A)‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Stored in a permanent archive that is publicly and openly accessible\n‚úÖ Has a persistent identifier\n‚úÖ Includes an open license\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ ACM ‚ÄúArtifacts Available‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Stored in a permanent archive that is publicly and openly accessible\n‚úÖ Has a persistent identifier\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ COS ‚ÄúOpen Code‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Stored in a permanent archive that is publicly and openly accessible\n‚úÖ Has a persistent identifier\n‚úÖ Includes an open license\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n‚úÖ Artefacts are sufficiently documented (i.e.¬†to understand how it works, to enable it to be run, including package versions)\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ IEEE ‚ÄúCode Available‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n\n\n\n\n\n\n‚ÄúObject review‚Äù badges\nThese badges relate to the research artefacts being reviewed against criteria of the badge issuer.\n\n\n\n\n\n\n\n\n‚úÖ ACM ‚ÄúArtifacts Evaluated - Functional‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Artefacts are sufficiently documented (i.e.¬†to understand how it works, to enable it to be run, including package versions)\n‚úÖ Arefacts are relevant to and contribute to the article‚Äôs results\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n‚úÖ Scripts can be successfully executed\n\n\n\n\n\n\n\n\n\n\n\n\n‚ùå ACM ‚ÄúArtifacts Evaluated - Reusable‚Äù\n\n\n\n\n\nDoes not meet all criteria:\n\n‚úÖ Artefacts are sufficiently documented (i.e.¬†to understand how it works, to enable it to be run, including package versions)\n‚ùå Artefacts are carefully documented (more than sufficient - i.e.¬†to the extent that reuse and repurposing is facilitated (e.g.¬†changing parameters, reusing for own purpose))\n‚úÖ Arefacts are relevant to and contribute to the article‚Äôs results\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n‚úÖ Scripts can be successfully executed\n‚úÖ Artefacts are well structured/organised (e.g.¬†to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ IEEE ‚ÄúCode Reviewed‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Complete set of materials shared (as would be needed to fully reproduce article)\n‚úÖ Scripts can be successfully executed\n\n\n\n\n\n\n‚ÄúReproduced‚Äù badges\nThese badges relate to an independent party regenerating the reuslts of the article using the author objects.\n\n\n\n\n\n\n\n\n‚úÖ NISO ‚ÄúResults Reproduced (ROR-R)‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ ACM ‚ÄúResults Reproduced‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n‚úÖ IEEE ‚ÄúCode Reproducible‚Äù\n\n\n\n\n\nMeets all criteria:\n\n‚úÖ Independent party regenerated results using the authors research artefacts\n\n\n\n\n\n\n\n\n\n\n\n\n‚ùå Psychological Science ‚ÄúComputational Reproducibility‚Äù\n\n\n\n\n\nDoes not meet all criteria:\n\n‚úÖ Independent party regenerated results using the authors research artefacts\n‚ùå Reproduced within approximately one hour (excluding compute time)\n‚úÖ Artefacts are well structured/organised (e.g.¬†to the extent that reuse and repurposing is facilitated, adhering to norms and standards of research community)\n‚ùå Artefacts are clearly documented and accompanied by a README file with step-by-step instructions on how to reproduce results in the manuscript"
  },
  {
    "objectID": "evaluation/badges.html#sources",
    "href": "evaluation/badges.html#sources",
    "title": "Badges",
    "section": "Sources",
    "text": "Sources\nNational Information Standards Organisation (NISO) (NISO Reproducibility Badging and Definitions Working Group (2021))\n\n‚ÄúOpen Research Objects (ORO)‚Äù\n‚ÄúOpen Research Objects - All (ORO-A)‚Äù\n‚ÄúResults Reproduced (ROR-R)‚Äù\n\nAssociation for Computing Machinery (ACM) (Association for Computing Machinery (ACM) (2020))\n\n‚ÄúArtifacts Available‚Äù\n‚ÄúArtifacts Evaluated - Functional‚Äù\n‚ÄúArtifacts Evaluated - Resuable‚Äù\n‚ÄúResults Reproduced‚Äù\n\nCenter for Open Science (COS) (Blohowiak et al. (2023))\n\n‚ÄúOpen Code‚Äù\n\nInstitute of Electrical and Electronics Engineers (IEEE) (Institute of Electrical and Electronics Engineers (IEEE) (n.d.))\n\n‚ÄúCode Available‚Äù\n‚ÄúCode Reviewed‚Äù\n‚ÄúCode Reproducible‚Äù\n\nPsychological Science (Hardwicke and Vazire (2023) and Association for Psychological Science (APS) (2023))\n\n‚ÄúComputational Reproducibility‚Äù"
  },
  {
    "objectID": "evaluation/reproduction_report.html",
    "href": "evaluation/reproduction_report.html",
    "title": "Computational reproducibility report",
    "section": "",
    "text": "Allen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\nManuscript title:\nAuthors (with email + orcid if known):\nSummary of paper:\nLinks (DOI/URL) to everything available for that article (pre-reg, article, supplementary, code):\nCite the protocol used for reproduction.\nScope of reproducibility report:\n\nThe overall reproduction success of the paper can be described as the proportion of items from the scope that were determined to be reproduced (e.g.¬†4 out of 5, 80%). This provides more context than just stating that a paper was or was not reproduced. When describing the reproduction success, it is important to include context on troubleshooting steps required (such as writing new code or contacting the author).\n\nResults:\n\nReproduction success\nEvaluation (against sharing, badges, and reporting guidelines)"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html",
    "title": "Patient Transport Modelling",
    "section": "",
    "text": "This notebook provides an overview and instructions to run the patient transport model and explore results."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#aims-of-the-modelling",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#aims-of-the-modelling",
    "title": "Patient Transport Modelling",
    "section": "Aims of the modelling",
    "text": "Aims of the modelling\nThe model can be used to explore the impact of increasing transport vehicle (e.g.¬†an ambulance) capacity on the total one-way travel time needed. We estimate two-way travel time via a simplification: doubling the one-way travel time.\nPlease note that:\n\nThe modelling is not intended to provide guidance on the number of vehicles needed.\n\nTravel time excludes vehicle turnaround time after each trip, duration of pickup and breaks rests for drivers.\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#the-vrp-package",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#the-vrp-package",
    "title": "Patient Transport Modelling",
    "section": "The VRP package",
    "text": "The VRP package\nThe python VRP package provides functions and classes to:\n\nGenerate a simple weighted sample of a patient population spread over a geographic area.\nConstruct multiple short (but not necessarily optimal) routes for transport vehicles, with a given capacity, to travel to each patient from a ‚Äòtreatment facility‚Äô and return.\nQuickly generate a large dataset of samples through parallel simulation.\n\n\nGeospatial and travel time data\nThe first step in parameterising a model is to load the input data files\n\nPatient count by postcode sector\nTravel times between each postcode sector\n\nThe data used in the analysis can be done access via functions in the module\nvrp.io\nNote the example here uses travel time. But travel distance could also be used.\n\nfrom vrp.io import (load_patient_postcode_count, \n                    load_travel_time)\n\n\ncost_matrix = load_travel_time()\nsector_counts = load_patient_postcode_count()\n\nThese functions each return a pandas.DataFrame\n\ntype(cost_matrix)\n\npandas.core.frame.DataFrame\n\n\n\ncost_matrix.shape\n\n(262, 262)\n\n\n\ntype(sector_counts)\n\npandas.core.frame.DataFrame\n\n\n\nsector_counts.head(3)\n\n\n\n\n\n\n\n\ncount\n\n\nsector\n\n\n\n\n\nL151\n1\n\n\nL91\n2\n\n\nL31\n1\n\n\n\n\n\n\n\n\n\nBuilt-in preprocessing\nTo convert a distribution of patient counts by postcodes to proportions use the following function\n\nfrom vrp.sim import create_postcode_distribution\n\n\npostcode_distribution = create_postcode_distribution(sector_counts)\n\n\ntype(postcode_distribution)\n\npandas.core.frame.DataFrame\n\n\n\npostcode_distribution.head(3)\n\n\n\n\n\n\n\n\ncount\nprob\n\n\nsector\n\n\n\n\n\n\nL151\n1\n0.001919\n\n\nL91\n2\n0.003839\n\n\nL31\n1\n0.001919\n\n\n\n\n\n\n\n\n\nRunning a transport experiment and exploring results\nThis can be done via six classes representing an simulated experiment, a scenario and a vehicle routing solvers.\nvrp.sim.TransportExperiment\nvrp.sim.Scenario\nvrp.sim.ILSWithConstructive\nvrp.constructive.SequentialClarkeWright\nvrp.sim.MultipleReplicationRunner\nvrp.sim.ScenarioManager\nTransportExperiment is a stochastic model. It generates a sample of the patient population to transport and then creates routes for patient transport services to use.\nScenario is a python dataclass. It is used to set the parameters for the simulation and passed to a TransportExperiment\nILSWithConstructive is a class that combines a simple constructive heuristic with Iterated Local Search\nSequentialClarkeWright is a constructive heuristic based for building transport routes based on the Clarke-Wright Savings algorithm.\nMultipleReplicationRunner allows a user to run multiple parallel replications of a simulation experiment.\nScenarioManager allows a user to run multiple parallel replications of multiple scenarios\n\nStep 1: create a scenario\nA Scenario accepts the following arguments\n\nn_patients: int, the number of patients to sample.\nwarehouse: str or int, the location of the depot/warehouse/facility where the vehicles start and end their trips.\nvehicle_capacities: list, e.g [2, 3, 4].\n\ncost_matrix: pandas.DataFrame, A travel distance or travel time matrix between all locations.\npostcode_distribution: pandas.DataFrame, the distribution of patients by postcode.\np_positive: float, the probability a sampled patient is positive\np_transport: float, the probability a sampled patient required transport\n\n\n#import the Scenario data class\nfrom vrp.sim import Scenario\n\n\nHOSP_LOCATION = 'L51'\nN_PATIENTS = 15\nCAPACITIES = [2, 3, 4]\nP_POS = 1.0\nP_TRAN = 1.0\n\n#sim parameters\nscenario_15 = Scenario(n_patients=N_PATIENTS,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n\n\nStep 2: create a Vehicle Routing Solver\n\n#import the Clark-Wright Savings euristic and ILS/Constructive wrapper classes\nfrom vrp.constructive import SequentialClarkeWright\nfrom vrp.sim import ILSWithConstructive\n\n\nN_ITER = 20\nsolver = ILSWithConstructive(constructive=SequentialClarkeWright(HOSP_LOCATION),\n                             warehouse=HOSP_LOCATION, \n                             iterations=N_ITER)\n\n\n\nStep 3: Create a transport experiment\n\n#import the TransportExperiment class\nfrom vrp.sim import TransportExperiment\n\n\nmodel = TransportExperiment(scenario=scenario_15, \n                            solver=solver)\n\n\n\nStep 3: Test run a single experiment\nThis should execute in &lt; 1 second.\n\n#set random seed to get a reproducible run\nSEED = 19\nnp.random.seed(SEED)\n\nresult = model.single_replication()\n\n\n#the result is a python dict with total travel time by capacity of vehicle\nresult\n\n{'capacity_1': 962,\n 'capacity_2': 630.0,\n 'capacity_3': 494.0,\n 'capacity_4': 463.0}\n\n\n\n\nStep 4: Execute multiple independent replications in parallel\nIt will take several seconds to run 10 replications. Depending on the population size, number of ILS iterations, and number of replications runtime can vary from seconds to hours.\n\nfrom vrp.sim import MultipleReplicationRunner\n\n\nrunner = MultipleReplicationRunner(model=model, random_state=SEED)\n\n\nN_REPS = 10\nresults = runner.execute(n_reps=N_REPS)\n\n\n#results is a list of dicts\ntype(results)\n\nlist\n\n\n\nresults[0]\n\n{'capacity_1': 974.0,\n 'capacity_2': 643.0,\n 'capacity_3': 528.0,\n 'capacity_4': 505.0}\n\n\n\n#convert results to a pandas DataFrame\ndf_results = pd.DataFrame(results)\n\n\ndf_results.head(3)\n\n\n\n\n\n\n\n\ncapacity_1\ncapacity_2\ncapacity_3\ncapacity_4\n\n\n\n\n0\n974.0\n643.0\n528.0\n505.0\n\n\n1\n1140.0\n707.0\n613.0\n492.0\n\n\n2\n712.0\n505.0\n411.0\n393.0\n\n\n\n\n\n\n\n\n#y-acis is in minutes in this example, but could be travel distance\ndf_results.boxplot(figsize=(12,5))\n\n\n\n\n\n\n\n\n\n\nStep 5: Analyse multiple scenarios\nFirst create multiple scenario objects\n\nHOSP_LOCATION = 'L51'\nCAPACITIES = [2, 3, 4]\nP_POS = 1.0\nP_TRAN = 1.0\n\n#scenario where 15 patients are positive on a day\nscenario_15 = Scenario(n_patients=15,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n#scenario where 25 patients are positive on a day\nscenario_25 = Scenario(n_patients=25,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n#store these in a dict\nscenarios = {}\nscenarios['15_covid_positive'] = scenario_15\nscenarios['25_covid_positive'] = scenario_25\n\n\n#create a sce\nfrom vrp.sim import ScenarioManager\n\n\nSEED = 999\nmanager = ScenarioManager(scenarios, solver, random_state=SEED)\n\n\nscenario_results = manager.execute(N_REPS)\n\nRunning scenario: 15_covid_positive... done.\nRunning scenario: 25_covid_positive... done.\nAll experiments completed.\n\n\n\n#plot multiple scenarios in one figure\nfig, ax = plt.subplots(1, 2, figsize=(12,5), sharey=True)\nindex = 0\nfor scenario_name, result in scenario_results.items():\n    result.boxplot(ax=ax[index])\n    ax[index].set_title(scenario_name)\n    index += 1\n    \nax[0].set_ylabel('Travel Time (mins)');\n\n#uncomment to save to file...\n#fig.savefig('scenario_boxplots.png', dpi=300)\n\n\n\n\n\n\n\n\n\n#access one of the scenarios\nscenario_results['25_covid_positive']\n\n#uncomment to save results to file\n#scenario_results['25_covid_positive'].to_csv('single_scenario_result.csv')\n\n\n\n\n\n\n\n\ncapacity_1\ncapacity_2\ncapacity_3\ncapacity_4\n\n\n\n\n0\n1306.0\n834.0\n681.0\n586.0\n\n\n1\n1562.0\n976.0\n771.0\n706.0\n\n\n2\n1618.0\n1059.0\n868.0\n750.0\n\n\n3\n1896.0\n1175.0\n883.0\n799.0\n\n\n4\n1756.0\n1027.0\n827.0\n724.0\n\n\n5\n1250.0\n798.0\n618.0\n571.0\n\n\n6\n1732.0\n1095.0\n921.0\n854.0\n\n\n7\n1972.0\n1201.0\n966.0\n870.0\n\n\n8\n1514.0\n942.0\n720.0\n661.0\n\n\n9\n1150.0\n784.0\n681.0\n619.0\n\n\n\n\n\n\n\n\n### Doubling travel times\ntwo_way = scenario_results['25_covid_positive'] * 2\ntwo_way.boxplot(figsize=(12,5))"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/CONTRIBUTING.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/CONTRIBUTING.html",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "Michael Allen - m.allen@exeter.ac.uk\nThomas Monks - t.m.w.monks@exeter.ac.uk"
  },
  {
    "objectID": "quarto_site/license.html",
    "href": "quarto_site/license.html",
    "title": "Open Source License",
    "section": "",
    "text": "This repository is licensed under the MIT License.\n\n\n\n\n\n\nView license\n\n\n\n\n\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nThis is aligned with the original study, who also licensed their work under the MIT License.\n\n\n\n\n\n\nView license\n\n\n\n\n\nMIT License\nCopyright (c) 2020 tmwm201\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nAllen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction code - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nReport - final report describing the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nAllen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction code - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nReport - final report describing the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#project-team",
    "href": "index.html#project-team",
    "title": "Reproducing Allen et al. 2020",
    "section": "Project team",
    "text": "Project team\n\nConducting this reproduction:\n\nAmy Heather \n\nOther members of the team on STARS:\n\nThomas Monks \nAlison Harper \nNavonil Mustafee \nAndrew Mayne"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Reproducing Allen et al. 2020",
    "section": "Citation",
    "text": "Citation\nAPA: Heather A. (2024). Reproducing Allen et al.¬†2020 URL: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020\nSee CITATION.cff and citation_bibtex.bib for alternative formats."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Reproducing Allen et al. 2020",
    "section": "License",
    "text": "License\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning. Dates formatted as YYYY-MM-DD as per ISO standard.\n\n\nRelease date: 3rd June 2024\nContributors: Amy Heather\nCompleted work on reproducing items from the agreed scope.\n\n\n\nAttempted reproduction of items from the original study.\n\n\n\n\n\nRelease date: 22nd May 2024\nContributors: Amy Heather\nDefined scope for the reproducibility assessment.\n\n\n\nBasic repository which includes a page defining the agreed scope for the reproducibility assessment."
  },
  {
    "objectID": "CHANGELOG.html#v0.2.0",
    "href": "CHANGELOG.html#v0.2.0",
    "title": "Changelog",
    "section": "",
    "text": "Release date: 3rd June 2024\nContributors: Amy Heather\nCompleted work on reproducing items from the agreed scope.\n\n\n\nAttempted reproduction of items from the original study."
  },
  {
    "objectID": "CHANGELOG.html#v0.1.0",
    "href": "CHANGELOG.html#v0.1.0",
    "title": "Changelog",
    "section": "",
    "text": "Release date: 22nd May 2024\nContributors: Amy Heather\nDefined scope for the reproducibility assessment.\n\n\n\nBasic repository which includes a page defining the agreed scope for the reproducibility assessment."
  },
  {
    "objectID": "quarto_site/study_publication.html",
    "href": "quarto_site/study_publication.html",
    "title": "Publication",
    "section": "",
    "text": "View at: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020/tree/main/original_study/dialysis-service-delivery-covid19-v1.0"
  },
  {
    "objectID": "quarto_site/study_publication.html#code-and-data",
    "href": "quarto_site/study_publication.html#code-and-data",
    "title": "Publication",
    "section": "",
    "text": "View at: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020/tree/main/original_study/dialysis-service-delivery-covid19-v1.0"
  },
  {
    "objectID": "quarto_site/study_publication.html#journal-article",
    "href": "quarto_site/study_publication.html#journal-article",
    "title": "Publication",
    "section": "Journal article",
    "text": "Journal article"
  },
  {
    "objectID": "quarto_site/study_publication.html#supplementary-materials",
    "href": "quarto_site/study_publication.html#supplementary-materials",
    "title": "Publication",
    "section": "Supplementary materials",
    "text": "Supplementary materials"
  },
  {
    "objectID": "reproduction/reproduction.html",
    "href": "reproduction/reproduction.html",
    "title": "Reproduction attempt",
    "section": "",
    "text": "Import required packages.\n\nimport sim_replicate as sim\nfrom sim.parameters import Scenario\n\nSet parameters for simulation.\n\n# Scenario\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    proportion_pos_requiring_inpatient=0.6)\n\n# Number of replications\nnumber_of_replications = 30\n\n# Base number for creation of random number sets\nbase_random_set = 2700\n\nRun simulation. In the order that these appear, these figures are the attempted reproductions of Figure 2, 3 and 4 respectively.\n\n# Run the simulation\nsim.run_replications(\n    scenarios, number_of_replications, base_random_set)\n\nRunning 30 reps of base_3_month =&gt; 2, 4, 7, 1, 0, 9, 5, 11, 8, 6, 12, 15, 13, 10, 16, 3, 18, 14, 19, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, Done."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html",
    "title": "Dialysis capapcity model",
    "section": "",
    "text": "The dialysis model runs through a defined period (e.g.¬†one year) and simulates the progression of patients through phases of COVID infection: negative, positive (with some requiring inpatient care) and recovered or died. The speed of progression of infection through the population may be varied (typically 3-12 months).\nAs patients change COVID state the model seeks to place them in the appropriate unit and session, opening up COVID-positive sessions in units that allow it. COVID-positive patients do not mix with any other patients. Opening up COVID-positive sessions causes other patients to be displaced from that session, and the model seeks to reallocate them either to the same unit or, if there is no space left, to the closest alternative unit.\nWhen allocating patients to units, the following search strategy is employed.\nPatients, in the model, may end up being cared for at a more distant unit than their starting unit. Once every week, the model seeks to reallocate patients back to their starting unit, or closest available unit if room in their starting unit is not available. This will also compress COVID-positive patients into as few units and sessions as possible."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#input-files",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#input-files",
    "title": "Dialysis capapcity model",
    "section": "Input files",
    "text": "Input files\n\nUnit capacity and use\nThe input file ./sim/units.csv allows definition and use of units:\n\nunit: the name used in outputs.\nsubunit: units may be broken down into two or more subunits. This may be done, for example, if only a part of the unit will be made available to COVID-19 positive patients.\nChairs: the number of dialysis chairs available in each session.\ninpatient: Set to 1 for hospitals that can accept COVID postive dialysis inpatients.\nAllow cov +: a value of 1 indicates that sessions for that unit, or subunit, may be made available to COVID positive patients.\nCov +ve order: The order in which units open up for COVID positive dialysis out patients.\nMon_1 thru Tues_3: Three sessions per day on Mon/Tues (which repeat on Wed/Thurs and Fri/Sat). A 1 indicates that the session is open for booking.\n\n\n\nPatients\nThe input file ./sim/units.csv contains information on patients:\n\nPatient ID: Any id of patient.\nPatient type: Not currently used in model.\nPostcode sector: Home postcode sector of patient.\nSite: Site patient currently attends.\nSubunit: Allocation of patient to subunit (if subunits use, you can simply assign them to any of them at the beginning of the model).\nSite postcode: Postcode of dialysis unit\nCOVID status: Can be set to positive if patients known to be positive at the start of the model run.\nfirst_day: Either Mon or Tues for patients having dialysis Mon/Wed/Fri or Tues/Thurs/Sat.\ncount*: set to 1 for all patients.\n\n\n\nTravel matrix\nThe input file ./sim/travel_matrix.csv contains travel times (minutes) from all patient postcode sectors to all dialysis units. We used Routino (routino.org) to obtain travel times."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#code-and-example",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#code-and-example",
    "title": "Dialysis capapcity model",
    "section": "Code and example",
    "text": "Code and example\n\nimport sim_replicate as sim\nfrom sim.parameters import Scenario, Uniform, Normal\n\nScenarios are defined in dictionaries as below. Multiple sceanrios may be defined and all results are saved to the ./output folder.\nParameters in the dictionary are:\n\nrun_length: Model run in days.\ntotal_proportion_people_infected. The proportion of patients who may be infected in the model. We assume this will be limited by herd immunity (or a vaccine).\ntime_to_infection: The time from start of model run to the time patients are infected. For time to infection a normal distrubtion is used. The paramters applied are mean, standard deviation, and lower cut-off (use 0 to avoid negative values) in days. In scarios we describe as 3 months we assume that six standard deviations of the distrubution (3 either side of the mean) occur in 3 months, or 90 days, so a standard deviation of 90/6 (or 15) is used.\ntime_positive: The duration a patient is positive if they remain in outpatient dialysis. A uniform distribution is used.\nproportion_pos_requiring_inpatient: The poportion of infected patients who will require inpatient dialysis.\ntime_pos_before_inpatient: For patients who will receive inpatient care, this is the time spent as a COVID positive outpatient before being hospitalised. A uniform distribution is used.\ntime_inpatient: The length of stay as an inpatient. A uniform distribution is used.\nmortality: The average mortality of dialysis patients who become infected with COVID.\nrandom_positive_rate_at_start: The model allows a proportion of patients to be randomly infected at the start of the model run.\n\nDefine a sceanrio and the numebr of model runs below (the replicates will use all available CPU cores).\n\nnumber_of_replications = 30\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    total_proportion_people_infected = 0.8,\n    time_to_infection = Normal(60, 15, 0.0),\n    time_positive = Uniform(7, 14),\n    proportion_pos_requiring_inpatient= 0.6,\n    time_pos_before_inpatient = Uniform(3,7),\n    time_inpatient = Uniform(7.0, 14.0),\n    mortality = 0.15,\n    random_positive_rate_at_start = 0.0\n    )\n\nRun the scenario. Three sets of charts will be outputed for each scenario (and saved with sceanrio names in the ./output directory: * Numbers of patients in negative, positive outpatient, positive inpatient, recovered/died stages of COVID: * Number of patients displaced from their starting dialysis unit, and how much extra travel time there is to their unit of current care. * Numbers of patients (negative/recovered, positive outpatient, pisitive inpatient) at each dialysis unit.\n\nsim.run_replications(scenarios, number_of_replications)\n\nRunning 30 reps of base_3_month =&gt; Done."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/vrp/transport_charts.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/vrp/transport_charts.html",
    "title": "Transport model charts",
    "section": "",
    "text": "The code below produces the figures in the report illustrating the transport results.\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\nFILE_1 = '20_positive_CW.csv'\nFILE_2 = '40_positive_CW.csv'\nFILE_3 = '60_positive_CW.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity to HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n#'P(positive) = {p_pos}. P(need transport)={p_transport}')\nax[0].set_ylabel('total driving time (mins)')\n#ax[0].set_xlabel('ambulance seating capacity')\n#ax[1].set_xlabel('ambulance seating capacity')\n#ax[2].set_xlabel('ambulance seating capacity')\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\nfig.savefig('output/prelim_model_tuned.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity to HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n#'P(positive) = {p_pos}. P(need transport)={p_transport}')\nax[0].set_ylabel('total driving time (mins)')\n#ax[0].set_xlabel('ambulance seating capacity')\n#ax[1].set_xlabel('ambulance seating capacity')\n#ax[2].set_xlabel('ambulance seating capacity')\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\nfig.savefig('output/prelim_model_ils.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\nSCALE = 2\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_outward_ILS.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '30_positive_ILS.csv'\nFILE_3 = '40_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 1\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('30 COVID-19 Positive')\nax[2].set_title('40 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_ILS_20_30_40.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '30_positive_ILS.csv'\nFILE_3 = '40_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 2\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('30 COVID-19 Positive')\nax[2].set_title('40 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_outward_ILS_20_30_40.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nSummary statistics\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 2\n\nresults_20 = pd.read_csv(f'output/{FILE_1}')\nresults_20.columns = ['0', '1', '2', '3', '4']\nresults_20_double = results_20 * SCALE\n\n\n(results_20 / 60).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n21.163067\n13.478783\n11.100733\n9.902833\n\n\nstd\n4.813657\n3.423492\n2.048313\n1.627923\n1.415795\n\n\nmin\n0.000000\n12.433333\n8.100000\n6.716667\n6.083333\n\n\n25%\n4.162500\n18.691667\n12.000000\n9.966667\n8.895833\n\n\n50%\n8.325000\n21.200000\n13.550000\n11.141667\n9.866667\n\n\n75%\n12.487500\n23.466667\n14.833333\n12.183333\n10.933333\n\n\nmax\n16.650000\n33.000000\n21.050000\n15.650000\n13.850000\n\n\n\n\n\n\n\n\n(results_20_double / 60).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n42.326133\n26.957567\n22.201467\n19.805667\n\n\nstd\n9.627315\n6.846984\n4.096627\n3.255847\n2.831590\n\n\nmin\n0.000000\n24.866667\n16.200000\n13.433333\n12.166667\n\n\n25%\n8.325000\n37.383333\n24.000000\n19.933333\n17.791667\n\n\n50%\n16.650000\n42.400000\n27.100000\n22.283333\n19.733333\n\n\n75%\n24.975000\n46.933333\n29.666667\n24.366667\n21.866667\n\n\nmax\n33.300000\n66.000000\n42.100000\n31.300000\n27.700000\n\n\n\n\n\n\n\n\nresults_40 = pd.read_csv(f'output/{FILE_2}')\nresults_40.columns = ['0', '1', '2', '3', '4']\nresults_40_double = results_40 * SCALE\n(results_40 / 60).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n40.191267\n24.244500\n19.077550\n16.572867\n\n\nstd\n4.813657\n4.685456\n2.658565\n2.002235\n1.701350\n\n\nmin\n0.000000\n24.500000\n14.983333\n11.716667\n10.616667\n\n\n25%\n4.162500\n36.900000\n22.383333\n17.662500\n15.416667\n\n\n50%\n8.325000\n40.100000\n24.258333\n19.066667\n16.550000\n\n\n75%\n12.487500\n43.333333\n26.066667\n20.416667\n17.716667\n\n\nmax\n16.650000\n55.033333\n32.150000\n24.733333\n21.433333\n\n\n\n\n\n\n\n\n(results_40_double / 60).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n80.382533\n48.489000\n38.155100\n33.145733\n\n\nstd\n9.627315\n9.370911\n5.317131\n4.004470\n3.402700\n\n\nmin\n0.000000\n49.000000\n29.966667\n23.433333\n21.233333\n\n\n25%\n8.325000\n73.800000\n44.766667\n35.325000\n30.833333\n\n\n50%\n16.650000\n80.200000\n48.516667\n38.133333\n33.100000\n\n\n75%\n24.975000\n86.666667\n52.133333\n40.833333\n35.433333\n\n\nmax\n33.300000\n110.066667\n64.300000\n49.466667\n42.866667\n\n\n\n\n\n\n\n\n#iqr capacity 1\niqr_1 = (results_40_double / 60).describe().loc['75%']['1'] - (results_40_double / 60).describe().loc['25%']['1']\niqr_1\n\n12.866666666666674\n\n\n\niqr_1 = (results_40_double / 60).describe().loc['75%']['1'] - (results_40_double / 60).describe().loc['25%']['1']\niqr_2 = (results_40_double / 60).describe().loc['75%']['2'] - (results_40_double / 60).describe().loc['25%']['2']\niqr_3 = (results_40_double / 60).describe().loc['75%']['3'] - (results_40_double / 60).describe().loc['25%']['3']\niqr_4 = (results_40_double / 60).describe().loc['75%']['3'] - (results_40_double / 60).describe().loc['25%']['3']\n\n\nmdn_1 = (results_40_double / 60).describe().loc['50%']['1']\nmdn_2 = (results_40_double / 60).describe().loc['50%']['2']\nmdn_3 = (results_40_double / 60).describe().loc['50%']['3']\nmdn_4 = (results_40_double / 60).describe().loc['50%']['4']\n\n\n(mdn_1 - mdn_2) / mdn_1\n\n0.3950540315876975\n\n\n\n(mdn_1 - mdn_3) / mdn_1\n\n0.5245220282626767\n\n\n\n(mdn_1 - mdn_4) / mdn_1\n\n0.587281795511222\n\n\n\nresults_60 = pd.read_csv(f'output/{FILE_3}')\nresults_60.columns = ['0', '1', '2', '3', '4']\nresults_60_double = results_60 * SCALE\n\n\n(results_60 / 60).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n56.972333\n33.508400\n25.832817\n22.076150\n\n\nstd\n4.813657\n5.562399\n3.053067\n2.263760\n1.883696\n\n\nmin\n0.000000\n40.033333\n24.100000\n19.166667\n16.483333\n\n\n25%\n4.162500\n53.100000\n31.433333\n24.300000\n20.733333\n\n\n50%\n8.325000\n56.800000\n33.491667\n25.825000\n22.066667\n\n\n75%\n12.487500\n60.766667\n35.650000\n27.450000\n23.437500\n\n\nmax\n16.650000\n76.633333\n44.066667\n34.116667\n28.183333\n\n\n\n\n\n\n\n\nmdn60_1 = (results_60_double / 60).describe().loc['50%']['1']\nmdn60_2 = (results_60_double / 60).describe().loc['50%']['2']\nmdn60_3 = (results_60_double / 60).describe().loc['50%']['3']\nmdn60_4 = (results_60_double / 60).describe().loc['50%']['4']\n\n\n(results_60_double / 60).describe()\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n113.944667\n67.016800\n51.665633\n44.152300\n\n\nstd\n9.627315\n11.124798\n6.106134\n4.527521\n3.767392\n\n\nmin\n0.000000\n80.066667\n48.200000\n38.333333\n32.966667\n\n\n25%\n8.325000\n106.200000\n62.866667\n48.600000\n41.466667\n\n\n50%\n16.650000\n113.600000\n66.983333\n51.650000\n44.133333\n\n\n75%\n24.975000\n121.533333\n71.300000\n54.900000\n46.875000\n\n\nmax\n33.300000\n153.266667\n88.133333\n68.233333\n56.366667"
  },
  {
    "objectID": "evaluation/artefacts.html",
    "href": "evaluation/artefacts.html",
    "title": "Sharing research artefacts",
    "section": "",
    "text": "This page evaluates the extent to which the original study meets the recommendations for the sharing of code and associated materials. We compare against two standards:"
  },
  {
    "objectID": "evaluation/artefacts.html#best-practice-audit",
    "href": "evaluation/artefacts.html#best-practice-audit",
    "title": "Sharing research artefacts",
    "section": "Best practice audit",
    "text": "Best practice audit\nOf the 11 items in this audit:\n\n9 were met fully (‚úÖ)\n1 was met partially (üü°)\n1 was not met (‚ùå)\n\n\n\n\n\n\n\n\n\n\nItem\nDescription\nMet by study?\nEvidence/location\n\n\n\n\nDigital Object Identifier\nDoes the model have a DOI and promise of persistence? Can it be cited?\n‚úÖ Fully\n10.5281/zenodo.3760625\n\n\nOpen Researcher and Contributor ID (ORCID)\nIs the model linked to one or more of the authors via an ORCID?\n‚úÖ Fully\nMonks linked to ORCID on Zenodo and in journal article\n\n\nLicense\nDoes the repository have a recognised open license to control the use of code, liabilty and credit?\n‚úÖ Fully\nMIT license\n\n\nModel overview\nIs there an obvious file that provides an overview of the repository/model and it purpose (e.g.¬†in README file)?\n‚úÖ Fully\nREADME.md present but doesn‚Äôt overview repository/model or purpose, although does like to Capacity_Model_Template.ipynb which does overview the model\n\n\nLink to published paper\nDo models shared externally from journal articles contain a link to the published article?\nüü° Partially\nZenodo citations section includes link to the article\n\n\nSteps to run code\nDoes the readme file or similar describe the steps required to execute the simulation model?\n‚úÖ Fully\nProvided in Capacity_Model_Template.ipynb\n\n\nFormal dependency management\nHas a formal tool, e.g.¬†renv, conda, or poetry been used to manage software dependencies for the simulation model?\n‚úÖ Fully\nConda - environment.yaml\n\n\nInformal dependency management\nHas an informal list or description of software, or OS dependencies been provided?\n‚úÖ Fully\nWithin environment.yaml\n\n\nCode Testing\nIs there any evidence of tests that have been applied to the code to check that it functions correctly?\n‚ùå Not met\nNo tests found for DES model (tests for Monte Carlo model are available in GitLab repository)\n\n\nLocal execution\nCan the simulation model and associated files be downloaded and in theory executed on a local machine\n‚úÖ Fully\nI have successfully executed\n\n\nRemote execution\nCan the simulation model be executed online using free or commercial infrastructure?\n‚úÖ Fully\nThe archived code on Zenodo has not been set up to allow this but the production code on GitLab was set up to allow this (on 23rd April 2020, prior to date journal received article)"
  },
  {
    "objectID": "evaluation/artefacts.html#stars",
    "href": "evaluation/artefacts.html#stars",
    "title": "Sharing research artefacts",
    "section": "STARS",
    "text": "STARS\nOf the 7 essential STARS components:\n\n5 were met fully (‚úÖ)\n1 was met partially (üü°)\n1 was not met (‚ùå)\n\nOf the 5 optional STARS components:\n\n1 was met fully (‚úÖ)\n4 were not met (‚ùå)\n\n\n\n\n\n\n\n\n\n\nComponent\nDescription\nMet by study?\nEvidence/location\n\n\n\n\nEssential components\n\n\n\n\n\nOpen license\nFree and open-source software (FOSS) license (e.g.¬†MIT, GNU Public License (GPL))\n‚úÖ Fully\nMIT license\n\n\nDependency management\nSpecify software libraries, version numbers and sources (e.g.¬†dependency management tools like pip virtual environment, conda environment, poetry)\n‚úÖ Fully\nConda - environment.yaml\n\n\nFOSS model\nCoded in FOSS language (e.g.¬†R, Julia, Python)\n‚úÖ Fully\nPython\n\n\nMinimum documentation\nMinimal instructions (e.g.¬†in README) that overview (a) what model does, (b) how to install and run model to obtain results, and (c) how to vary parameters to run new experiements\n\n\n\n\nORCID\nORCID for each study author\nüü° Partially\nOnly provided for Monks\n\n\nCitation information\nInstructions on how to cite the research artefact (e.g.¬†CITATION.cff file)\n‚ùå Not met\nNot provided\n\n\nRemote code repository\nCode available in a remote code repository (e.g.¬†GitHub, GitLab, BitBucket)\n‚úÖ Fully\nGitLab\n\n\nOpen science archive\nCode stored in an open science archive with FORCE11 compliant citation and guaranteed persistance of digital artefacts (e.g.¬†Figshare, Zenodo, the Open Science Framework (OSF), and the Computational Modeling in the Social and Ecological Sciences Network (CoMSES Net))\n‚úÖ Fully\nZenodo\n\n\nOptional components\n\n\n\n\n\nEnhanced documentation\nOpen and high quality documentation on how the model is implemented and works (e.g.¬†via notebooks and markdown files, brought together using software like Quarto and Jupyter Book). Suggested content includes:‚Ä¢ Plain english summary of project and model‚Ä¢ Clarifying license‚Ä¢ Citation instructions‚Ä¢ Contribution instructions‚Ä¢ Model installation instructions‚Ä¢ Structured code walk through of model‚Ä¢ Documentation of modelling cycle using TRACE‚Ä¢ Annotated simulation reporting guidelines‚Ä¢ Clear description of model validation including its intended purpose\n‚ùå Not met\nREADME.md has simple installation instructions, whilst Capacity_Model_Template.ipynb has plain english summary of model and simple walk through. However, many of these suggestions are not captured, and documentation is felt to just meet the criteria of ‚Äúminimum documentation‚Äù\n\n\nDocumentation hosting\nHost documentation (e.g.¬†with GitHub pages, GitLab pages, BitBucket Cloud, Quarto Pub)\n‚ùå Not met\nNot hosted.\n\n\nOnline coding environment\nProvide an online environment where users can run and change code (e.g.¬†BinderHub, Google Colaboratory, Deepnote)\n‚úÖ Fully\nThe archived code on Zenodo has not been set up to allow this but the production code on GitLab was set up to allow this (on 23rd April 2020, prior to date journal received article)\n\n\nModel interface\nProvide web application interface to the model so it is accessible to less technical simulation users\n‚ùå Not met\n-\n\n\nWeb app hosting\nHost web app online (e.g.¬†Streamlit Community Cloud, ShinyApps hosting)\n‚ùå Not met\n-"
  },
  {
    "objectID": "evaluation/reporting.html",
    "href": "evaluation/reporting.html",
    "title": "Reporting guidelines",
    "section": "",
    "text": "This page evaluates the extent to which the journal article meets the criteria from two discrete-event simulation study reporting guidelines:"
  },
  {
    "objectID": "evaluation/reporting.html#stress-des",
    "href": "evaluation/reporting.html#stress-des",
    "title": "Reporting guidelines",
    "section": "STRESS-DES",
    "text": "STRESS-DES\nOf the 24 items in the checklist:\n\n15 were met fully (‚úÖ)\n3 were partially met (üü°)\n4 were not met (‚ùå)\n2 were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\nItem\nRecommendation\nMet by study?\nEvidence\n\n\n\n\nObjectives\n\n\n\n\n\n1.1 Purpose of the model\nExplain the background and objectives for the model\n‚úÖ Fully\nIntroduction: ‚ÄúPlanning service delivery that separates COVID-positive patients is complicated, due to the uncertainty of the spread of SARS-CoV-2, the variability seen in symptom onset, length of infectivity, and regional delivery of dialysis. We therefore sought to support decision making in the period prior to peak infection by developing mathematical models of dialysis service delivery and patient transport. We aimed to provide reusable tools to provide rapid information under various scenarios including a worst case three month spread.‚Äù\n\n\n1.2 Model outputs\nDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\n‚úÖ Fully\nMaterials and methods - Outcome measures: ‚ÄúWe estimated the the change in outpatient and inpatient workload during the epidemic in terms of COVID-positive negative and recovered, at each dialysis unit in the network. Estimates were produced over periods three to six months. We also estimated the number of patients who were required to travel to a different unit from normal and the change in travel time.‚ÄùMaterials and methods - Dialysis model: ‚ÄúThe dialysis model is run 30 times to simulate 30 alternative years as, due to the randomness of infection, no two years will be exactly alike. Results show typical (median) and extreme years.‚Äù\n\n\n1.3 Experimentation aims\nIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis ‚Äì Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments ‚Äì Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation ‚Äì (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n‚úÖ Fully\nModel can technically explore multiple scenarios, but the paper presents a single scenario: worst-case three month spread. The parameters for this scenario are described and justified.Introduction: ‚ÄúWe aimed to provide reusable tools to provide rapid information under various scenarios including a worst case three month spread.‚ÄùMaterials and methods - patient progression model: ‚ÄúThe baseline model takes a worst case progression of COVID, infecting 80% of the dialysis population over 3 months.‚ÄùMaterials and methods - data sources: ‚ÄúThe worst case time of spread of COVID-positive was taken from Fergeson et al.¬†Mortality rate, time a patient was COVID-positive before admission and inpatient length of stay were local parameters.‚ÄùMaterials and methods - verification and validation: ‚ÄúWe instead worked closely with clinicians, managers and informatics specialists within the local health system to review iterative versions of the model. We also opted to model a range of likely scenarios including what is widely believed to be the worst case.‚Äù\n\n\nLogic\n\n\n\n\n\n2.1 Base model overview diagram\nDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n‚úÖ Fully\nFigure 1: ‚ÄúSchematic representation of patient pathway‚Äù\n\n\n2.2 Base model logic\nGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n‚úÖ Fully\nMaterials and methods - Dialysis model section provides a detailed description of how the model works, and how patients flow through it\n\n\n2.3 Scenario logic\nGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\nN/A\nNot applicable (single scenario).\n\n\n2.4 Algorithms\nProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e.¬†scheduling of arrivals/ appointments/ operations/ maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n‚úÖ Fully\nMaterials and methods - patient progression model: ‚ÄúThe proportions of patients and times in each phase is either fixed or sampled from stochastic distributions as given in Table 1‚ÄùTable 1: Baseline model parametersMaterials and methods - unit search strategy: ‚ÄúWhen allocating patients to units, the following search strategy is employed.‚Ä¢ COVID negative: First look for place in current unit attended. If no room there place in the closest unit (judged by estimated travel time) with available space.‚Ä¢ COVID-positive: Place all COVID-positive patients first in Queen Alexandra Hospital, Portsmouth, and if capacity there is fully utilised open up capacity in Basingstoke. If a new COVID session is required, the model will displace all COVID negative patients in that session, and seek to re-allocate them according to the rules for allocating COVID negative patients.‚Ä¢ COVID-positive inpatient: All inpatients are placed in Queen Alexandra Hospital, Portsmouth (though the model allows searching by travel time if another unit were to open to renal COVID-positive inpatients).‚Ä¢ COVID-recovered: Treat as COVID negative.‚Ä¢ Unallocated patients: If a patient cannot be allocated to any unit, the model attempts to allocate them each day.‚Äù\n\n\n2.5.1 Components - entities\nGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n‚úÖ Fully\nThere is one entity - patients - and these can be in different COVID states, and inpatients or outpatients.Materials and methods - dialysis model: ‚Äúsimulates the progression of patients through phases of COVID infection: negative, positive (with some requiring inpatient care) and recovered or died.‚Äù\n\n\n2.5.2 Components - activities\nDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n‚úÖ Fully\nPatients are allocated to units to receive dialysis three times a week. The unit search strategy for each patient type is provided.Materials and methods - patient progression model: ‚Äúall patients should receive dialysis three times weekly, with each patient allocated to a starting day for the week of either Monday or Tuesday‚ÄùMaterials and methods - unit search strategy: ‚ÄúWhen allocating patients to units, the following search strategy is employed.‚Ä¢ COVID negative: First look for place in current unit attended. If no room there place in the closest unit (judged by estimated travel time) with available space.‚Ä¢ COVID-positive: Place all COVID-positive patients first in Queen Alexandra Hospital, Portsmouth, and if capacity there is fully utilised open up capacity in Basingstoke. If a new COVID session is required, the model will displace all COVID negative patients in that session, and seek to re-allocate them according to the rules for allocating COVID negative patients.‚Ä¢ COVID-positive inpatient: All inpatients are placed in Queen Alexandra Hospital, Portsmouth (though the model allows searching by travel time if another unit were to open to renal COVID-positive inpatients).‚Ä¢ COVID-recovered: Treat as COVID negative.‚Ä¢ Unallocated patients: If a patient cannot be allocated to any unit, the model attempts to allocate them each day.‚Äù\n\n\n2.5.3 Components - resources\nList all the resources included within the model and which activities make use of them.\n‚úÖ Fully\nThere are nine units, and these are the only resource, used for dialysis appointments.Materials and methods - study setting: ‚ÄúThe service operates a network of nine centres‚Ä¶ The Queen Alexandra will be used as the primary site for positive outpatients and inpatients with spillover to a second site (Basingstoke) when capacity is insufficient.‚ÄùSupplementary Materials 1 provides further details on the units (e.g.¬†locations, inpatient facilities, whether accept COVID-19 positive).\n\n\n2.5.4 Components - queues\nGive details of the assumed queuing discipline used in the model (e.g.¬†First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\nN/A\nNot applicable as there are no queues\n\n\n2.5.5 Components - entry/exit points\nGive details of the model boundaries i.e.¬†all arrival and exit points of entities. Detail the arrival mechanism (e.g.¬†‚Äòthinning‚Äô to mimic a non-homogenous Poisson process or balking)\n‚ùå Not met\nNot explicitly described in the paper. However, understand from Tom that it is a fixed population where patients exit the dialysis model at mortality. This is indicated by Figure 1, but as I did not feel it to be clearly detailed in the paper, this has been evaluated as not met.\n\n\nData\n\n\n\n\n\n3.1 Data sources\nList and detail all data sources. Sources may include:‚Ä¢ Interviews with stakeholders,‚Ä¢ Samples of routinely collected data,‚Ä¢ Prospectively collected samples for the purpose of the simulation study,‚Ä¢ Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n‚úÖ Fully\nMaterials and methods - study setting: ‚ÄúWe apply the service delivery modelling tools in the South of England in the region of Wessex: a mixed urban/rural setting where the renal dialysis service cares for 644 patients‚Ä¶ In the analysis we excluded home patients (n = 80) and due to its separation from the mainland the Isle of Wight (n = 44).‚ÄùMaterials and methods - data sources: ‚ÄúResearchers had no access to individual patient level data. To ensure confidentiality, patient geographic locations was provided at the UK postcode sector level (alternatives might be output areas or northings and eastings). Travel times between these sectors were estimated using Routino (routino.org) with data from OpenStreetMap (openstreetmap.org). The worst case time of spread of COVID-positive was taken from Fergeson et al.¬†Mortality rate, time a patient was COVID-positive before admission and inpatient length of stay were local parameters.‚Äù\n\n\n3.2 Pre-processing\nProvide details of any data manipulation that has taken place before its use in the simulation, e.g.¬†interpolation to account for missing data or the removal of outliers.\n‚úÖ Fully\nGenerated travel time matrix - Materials and methods - data sources: ‚Äúpatient geographic locations was provided at the UK postcode sector level (alternatives might be output areas or northings and eastings). Travel times between these sectors were estimated using Routino (routino.org) with data from OpenStreetMap (openstreetmap.org).‚Äù\n\n\n3.3 Input parameters\nList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:‚Ä¢ Base case data‚Ä¢ Data use in experimentation, where different from the base case.‚Ä¢ Where optimisation or design of experiments has been used, state the range of values that parameters can take.‚Ä¢ Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n‚úÖ Fully\nMaterials and methods - patient progression model: ‚ÄúThe proportions of patients and times in each phase is either fixed or sampled from stochastic distributions as given in Table 1‚Ä¶ The baseline model takes a worst case progression of COVID, infecting 80% of the dialysis population over 3 months.‚ÄùTable 1: Baseline model parameters\n\n\n3.4 Assumptions\nWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n‚úÖ Fully\nAssumes worst-case scenario (80% infected in 3 months with 15% mortality).Materials and methods - patient progression model: ‚ÄúWe assume that COVID patients must be separated from uninfected patients, and that patients who have recovered from a COVID episode do not mix with those currently testing COVID positive. We do not deal specifically with suspected COVID patients in the model, anticipating that rapid testing will soon be available to diagnose which group they belong to.‚ÄùAssumes that patients travel alone - Results - dialysis network: ‚ÄúThese patients typically require 20 minutes extra travel time to get to their temporary place of care (assuming they are travelling alone)‚ÄùDiscussion - limitations of the study:‚Ä¢ ‚ÄúThe model assumes that patients can be re-allocated to units/sessions immediately. In practice changes to session allocation (e.g.¬†shifting from COVID-negative to COVID-positive are likely to be made a little in advance.‚Ä¢ The results reported here assume that current capacity is maintained throughout the COVID outbreak.‚Ä¢ We have not modelled the effect of reductions in capacity that may be caused by staff shortages. We have not modelled timing of sessions, but the model progressively allocates COVID-positive sessions as needed, and we would assume that these sessions would come later in the day, enabling cleaning at the end of the day, ready for any COVID-negative session the next morning.‚Ä¢ We have not included home dialysis patients, which may affect inpatient demand. A likely worst-case scenario (with home dialysis patients following the transmission spread, and need for inpatient care, of the dialysis units, is that inpatient demand may be increased 15%.‚Äù\n\n\nExperimentation\n\n\n\n\n\n4.1 Initialisation\nReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n‚ùå Not met\nNot stated - but understand from Tom that the model is non-terminating.\n\n\n4.2 Run length\nDetail the run length of the simulation model and time units.\n‚úÖ Fully\nDaily time unit (with ‚Äúper day‚Äù mentioned throughout article), and run length of three months - Materials and methods - patient progression model: ‚ÄúThe baseline model takes a worst case progression of COVID, infecting 80% of the dialysis population over 3 months.‚Äù\n\n\n4.3 Estimation approach\nState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\nüü° Partially\nMultiple replications (30). Justification for method and number of replications not provided.Materials and methods - dialysis model: ‚ÄúThe dialysis model is run 30 times to simulate 30 alternative years as, due to the randomness of infection, no two years will be exactly alike.‚Äù\n\n\nImplementation\n\n\n\n\n\n5.1 Software or programming language\nState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g.¬†Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\nüü° Partially\nMaterials and methods - analysis environment: ‚ÄúAll models were written in Python 3.8. We used SimPy 3 to implement the DES model‚Ä¶ All charts were produced with MatPlotLib‚Ä¶ The dialysis model results were run on an Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux.‚ÄùFull details for the libraries is provided in the linked code repository within the environment file, but as this is not within the article itself (which is what STRESS evaluates), have set as partially met\n\n\n5.2 Random sampling\nState the algorithm used to generate random samples in the software/programming language used e.g.¬†Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n‚ùå Not met\nNot described. From the code, can see that they did not control the random numbers using seeds or streams, and instead just used the global pseudo random number generator in Python. Hence, results vary between runs of the model.\n\n\n5.3 Model execution\nState the event processing mechanism used e.g.¬†three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n‚ùå Not met\nNot described, but understand from Tom that as it used SimPy, it was a process-based simulation worldview.\n\n\n5.4 System specification\nState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\nüü° Partially\nDo not state model run time, but do provide hardware specification, and use parallelismMaterials and methods - analysis environment: ‚ÄúThe dialysis model results were run on an Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux.‚ÄùConclusion: ‚ÄúWe have designed the tools to scale to large international dialysis planning situations and exploit parallelism and fast well known heuristics.‚Äù\n\n\nCode access\n\n\n\n\n\n6.1 Computer model sharing statement\nDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these.\n‚úÖ Fully\nData availability statement: ‚ÄúThe python code and anonymous aggregate level data used this study are available from Zenodo https://zenodo.org/record/3760626. Production code is hosted on University of Exeter‚Äôs GitLab https://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19.‚Äù"
  },
  {
    "objectID": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "href": "evaluation/reporting.html#des-checklist-derived-from-ispor-sdm",
    "title": "Reporting guidelines",
    "section": "DES checklist derived from ISPOR-SDM",
    "text": "DES checklist derived from ISPOR-SDM\nOf the 18 items in the checklist:\n\n14 were met fully (‚úÖ)\n1 were partially met (üü°)\n1 were not met (‚ùå)\n2 were not applicable (N/A)\n\n\n\n\n\n\n\n\n\n\n\nItem\nAssessed if‚Ä¶\nMet by study?\nEvidence/location\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?\n‚Ä¶the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\n‚úÖ Fully\nPlanning service delivery when need to keep COVID-positive and COVID-negative patients seperate, testing the plan under worst-case scenario three-month spread.Introduction: ‚ÄúRapid guidelines for dialysis service delivery have been published. These include separation of COVID-positive and COVID-negative patients; dialysis units working with transport providers to minimise the risk of cross-infection; and continuing to treat patients as close to home as possible. Planning service delivery that separates COVID-positive patients is complicated, due to the uncertainty of the spread of SARS-CoV-2, the variability seen in symptom onset, length of infectivity, and regional delivery of dialysis. We therefore sought to support decision making in the period prior to peak infection by developing mathematical models of dialysis service delivery‚ÄùMaterials and methods - study setting: ‚ÄúDuring the epidemic, COVID-positive patients will be treated separately from negative and recovered. The Queen Alexandra will be used as the primary site for positive outpatients and inpatients with spillover to a second site (Basingstoke) when capacity is insufficient. Patient transport services will provide COVID only ambulances with a policy of single patient transport‚Äù\n\n\n2 Is the modeled healthcare setting/health condition clarified?\n‚Ä¶the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n‚úÖ Fully\nPatients with Chronic Kidney Disease visiting dialysis units during COVID-19Introduction: ‚ÄúSevere Acute Respiratory Syndrome-Corona Virus-2 (SARS-CoV-2) and the disease it causes COVID-19 (henceforth known as COVID) is causing widespread disruption to normal healthcare services, as the number COVID-positive cases increases‚Ä¶ Although social distancing measures are in place both in the UK and internationally, patients with Chronic Kidney Disease who must visit dialysis units are limited in their ability to be fully isolated.‚Äù\n\n\n3 Is the model structure described?\n‚Ä¶the model‚Äôs conceptual structure was described in the form of either graphical or text presentation.\n‚úÖ Fully\nFigure 1: ‚ÄúSchematic representation of patient pathway‚ÄùMaterials and methods - Dialysis model section provides a detailed description of how the model works, and how patients flow through it\n\n\n4 Is the time horizon given?\n‚Ä¶the time period covered by the simulation was reported.\n‚úÖ Fully\nThree months - Materials and methods - patient progression model: ‚ÄúThe baseline model takes a worst case progression of COVID, infecting 80% of the dialysis population over 3 months.‚Äù\n\n\n5 Are all simulated strategies/scenarios specified?\n‚Ä¶the comparators under test were described in terms of their components, corresponding variations, etc\n‚úÖ Fully\nThere is a single scenario: worst-case three month spread. The parameters for this scenario are described and justified.Materials and methods - patient progression model: ‚ÄúThe baseline model takes a worst case progression of COVID, infecting 80% of the dialysis population over 3 months.‚Äù\n\n\n6 Is the target population described?\n‚Ä¶the entities simulated and their main attributes were characterized.\n‚úÖ Fully\nMaterials and methods - study setting: - ‚ÄúWe apply the service delivery modelling tools in the South of England in the region of Wessex: a mixed urban/rural setting where the renal dialysis service cares for 644 patients. The service operates a network of nine centres. The largest of which is located at the Queen Alexandra (QA) Hospital, Portsmouth. To access dialysis services 75% of patients make use of patient transport services.‚ÄùResults - dialysis network: ‚ÄúCurrently the median travel time from home to dialysis unit (one way, with a single passenger) is 14 minutes. The minimum, lower quartile, upper quartile, and maximum travel times are 1, 9, 22, and 76 minutes. Currently there is sufficient capacity for 668 dialysis patients in the outpatient sessions which are currently open, with 583 patients currently receiving dialysis (87% capacity utilisation).‚Äù\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?\n‚Ä¶the sources of all data used to inform model inputs were reported.\n‚úÖ Fully\nMaterials and methods - study setting: ‚ÄúWe apply the service delivery modelling tools in the South of England in the region of Wessex: a mixed urban/rural setting where the renal dialysis service cares for 644 patients‚Ä¶ In the analysis we excluded home patients (n = 80) and due to its separation from the mainland the Isle of Wight (n = 44).‚ÄùMaterials and methods - data sources: ‚ÄúResearchers had no access to individual patient level data. To ensure confidentiality, patient geographic locations was provided at the UK postcode sector level (alternatives might be output areas or northings and eastings). Travel times between these sectors were estimated using Routino (routino.org) with data from OpenStreetMap (openstreetmap.org). The worst case time of spread of COVID-positive was taken from Fergeson et al.¬†Mortality rate, time a patient was COVID-positive before admission and inpatient length of stay were local parameters.‚Äù\n\n\n8 Are the parameters used to populate model frameworks specified?\n‚Ä¶all relevant parameters fed into model frameworks were disclosed.\n‚úÖ Fully\nMaterials and methods - patient progression model: ‚ÄúThe proportions of patients and times in each phase is either fixed or sampled from stochastic distributions as given in Table 1‚Ä¶ The baseline model takes a worst case progression of COVID, infecting 80% of the dialysis population over 3 months.‚ÄùTable 1: Baseline model parameters\n\n\n9 Are model uncertainties discussed?\n‚Ä¶the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n‚úÖ Fully\nAll figures include the minimum and maximum from 30 trials (shown with fainter lines), alongside the median results (shown with bolder lines). Example from Figure 2:\n\n\n10 Are sensitivity analyses performed and reported?\n‚Ä¶the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters‚Äô plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n‚ùå Not met\nNot reported.\n\n\nValidation\n\n\n\n\n\n11 Is face validity evaluated and reported?\n‚Ä¶it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n‚úÖ Fully\nMaterials and methods - verification and validation: They ‚Äúworked closely with clinicians, managers and informatics specialists within the local health system to review iterative versions of the model. We also opted to model a range of likely scenarios including what is widely believed to be the worst case.‚Äù\n\n\n12 Is cross validation performed and reported\n‚Ä¶comparison across similar modeling studies which deal with the same decision problem was undertaken.\nN/A\nThis was not possible as, at the point the study was conducted, similar studies on the same decision problem were not available.Materials and methods - verification and validation: ‚ÄúQuantitative validation of models (checking models are appropriate detailed and sufficiently accurate) is challenging in the COVID epidemic as the forecast is of unprecedented conditions‚Äù\n\n\n13 Is external validation performed and reported?\n‚Ä¶the modeler(s) examined how well the model‚Äôs results match the empirical data of an actual event modeled.\nN/A\nThis was not possible as, at the point the study was conducted, no empirical data was available.Materials and methods - verification and validation: ‚ÄúQuantitative validation of models (checking models are appropriate detailed and sufficiently accurate) is challenging in the COVID epidemic as the forecast is of unprecedented conditions‚Äù\n\n\n14 Is predictive validation performed or attempted?\n‚Ä¶the modeler(s) examined the consistency of a model‚Äôs predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\n‚úÖ Fully\nNot performed but justified. Discussion - strengths of the study: ‚ÄúOur toolkit complements the existing epidemiological and ICU literature and aligns itself with the recent call to build new tools that can support operational decision making in health services during the pandemic. Indeed a strength of our toolkit is its practical utility in supporting the continuous safe treatment of a vulnerable group during a national or regional outbreak of COVID infection. We argue that more work like ours is needed to support health services and that the data science community must now focus on research translation. While the world‚Äôs population awaits the results of vaccine trials, the risk of a secondary wave of infections remains a reality. To protect the public and support health services under these circumstances we urgently need more research and development of novel practical decision support tools. These tools must be findable, accessible and verified. Our approach has been to make our modelling tools freely available, verifiable and open online.‚Äù\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n15 Is the model generalizability issue discussed?\n‚Ä¶the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\nüü° Partially\nThe authors state that the tools from this work can be used in other populations - Conclusion: ‚ÄúThe study we present applies these tools in the South of England where they were used to stress test capacity planning plans. As the pandemic progresses internationally there are risks of regional outbreaks or secondary national spikes in cases. At the start of the pandemic, there were limited operational modelling tools available to support decision makers. Our simulation toolkit is now available for use immediately by health planners. We have designed the tools to scale to large international dialysis planning situations and exploit parallelism and fast well known heuristics.‚ÄùThe authors provide a description of the sample in the paper, with further information on the study setting and dialysis units in the Supplementary Materials 1: Study setting geography. This supports readers understanding of potential generalisaibility.The study encourages reuse of the tools in other settings, but doesn‚Äôt explicitly describe whether the results of this study are generalisable or not, and to whom.\n\n\n16 Are decision makers or other stakeholders involved in modeling?\n‚Ä¶the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n‚úÖ Fully\nReview of model - Materials and methods - verification and validation: they ‚Äúworked closely with clinicians, managers and informatics specialists within the local health system to review iterative versions of the model.‚Äù\n\n\n17 Is the source of funding stated?\n‚Ä¶the sponsorship of the study was indicated.\n‚úÖ Fully\nFunding: ‚ÄúThis article presents independent research funded by the National Institute for Health Research (NIHR) Applied Research Collaboration (ARC) South West Peninsula (MA, SL). The views expressed in this publication are those of the author(s) and not necessarily those of the National Health Service, the NIHR or the Department of Health and Social Care. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.‚Äù\n\n\n18 Are model limitations discussed?\n‚Ä¶limitations of the assessed model, especially limitations of interest to decision makers, were discussed.\n‚úÖ Fully\nLimitations are detailed in Discussion - limitations of the study - dialysis network model."
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html",
    "href": "evaluation/posts/2024_05_24/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Note\n\n\n\nFixed model so that it is reproducible between runs. Total time used: 5h 45m (14.4%)"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#work-log",
    "href": "evaluation/posts/2024_05_24/index.html#work-log",
    "title": "Day 3",
    "section": "Work log",
    "text": "Work log\n\nUntimed - Revision on random numbers\nSpent some time revises how number generation works in Python - notes here. I felt this was external to reproducing the model, so did not include it in time.\nIf I would have timed it though, it would‚Äôve been apx. 9.30-11.28.\n\n\n11.29-12.38 Reproduction\nI returned to trying to modify the code so it can reproduce results between runs.\nA simple fix of adding a seed to some of the Uniform() functions that were still using random_seed=None meant that the simulation would now run exactly the same each time.\nRun 1:\n\nRun 2:\n\nThen we needed a seperate seed with each run (else every run will produce identical results) This required changes to:\n\nsingle_run() within sim_replicate.py so it can accept random number set as an argument, and then when it was called in multiple_replications(), to use the rep number as the starting seed\nScenario, changing it from a frozen dataclass to a class with a function that accepts a random number set, and then prompts generation of distributions from that\n\nThese changes were based on this model.\nAs can see, this has fixed it, as we have reproducible results between runs, and varying results within runs.\nRun 1:\n\nRun 2:\n\n\n\nUntimed: Exploring methods for overlaying figures\nExploring methods for overlaying figures. Not timed as not about reproduction of this study, but about how we are going to do this each time when reproducing.\nDecided that it‚Äôs not helpful to do this - spend more time fiddling around with getting them to resize and overlay correctly - and that the simplest option here would be to compare by eye.\nIf timed, 13.33-13.57.\n\nimport cv2\nimport matplotlib.pyplot as plt\n\noriginal = cv2.imread('../../../original_study/article_fig4.png')\noverlay = cv2.imread('figure_2a.png')\n\n# Resize overlay to match original image dimensions\noverlay_resize = cv2.resize(overlay, (original.shape[1], original.shape[0]))\n\n# View new image\nimg = plt.imshow(overlay_resize)\nplt.axis('off')\nimg\n\n\n\n\n\n\n\n\n\n# Overlay transparently\ncombined = cv2.addWeighted(original,0.4,overlay_resize,0.1,0)\n\n# View new image\nimg = plt.imshow(combined)\nplt.axis('off')\nimg"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#timings",
    "href": "evaluation/posts/2024_05_24/index.html#timings",
    "title": "Day 3",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 276\n\n# Times from today\ntimes = [\n    ('11.29', '12.38')]\n\n# Print time used and remaining\ncalculate_times(used_to_date, times)\n\nTime spent today: 69m, or 1h 9m\nTotal used to date: 345m, or 5h 45m\nTime remaining: 2055m, or 34h 15m\nUsed 14.4% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_05_24/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_05_24/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 3",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nüí¨ = Noted to discuss with team.\nProtocol:\n\nüí¨ Protocol should more clearly state if certain timestamps are needed. Currently the suggestion is time to create each figure - but is this definitely our focus? Or is it instead, time to set up the environment, time to get the simulation running, time to get it to reproduce between runs, time to successful reproduction. For this study, the figure from Krafczyk wouldn‚Äôt make alot of sense, as we all-or-nothing reproduce them. Depending on decision, need to be clear in protocol about what is being timed and what is not."
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html",
    "href": "evaluation/posts/2024_05_23/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Time elapsed\n\n\n\nReviewing code and running model with reproduction of results between runs. Total time used: 4h 36m (11.5%)"
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html#work-log",
    "href": "evaluation/posts/2024_05_23/index.html#work-log",
    "title": "Day 2",
    "section": "Work log",
    "text": "Work log\n\n10.24-11.00 - Describe code/data\nLooked over code and data from original study, taking notes below.\n\n\n\n\n\n\nNotes from looking over their code and data\n\n\n\n\n\nCode files in main folder:\n\nCapacity_Model_Template.ipynb - explain DES model, input files, code example importing sim_replicate.py and using functions from that\nsim_replicate.py - importing from sim/, single and multiple runs of model, and multiple runs of prescribed scenarios, and function to get audit results from multiple runs, and parameters\nsim_single.py - single run of model\n\nOther files in main folder:\n\nCONTRIBUTING.md - lists Mike and Tom as the contributors\nenvironment.yaml - conda environment\n.gitignore\nLICENSE - MIT\nREADME.md - Instructs to use environment and then refer to .ipynb files\nTransport_Model_Template.ipynb - Monte Carlo Model\nmain_vrp.py - importing from vrp/, but otherwise very similar to part of sim_replicate (single and multiple runs, and parameters). VRP = vehicle routing problem?\n\nOther folders:\n\noutput/ - empty\npatient_geography_data/ - patient data\nsim/ - Discrete event\nvrp/ - Monte Carlo\n\n‚îú‚îÄ‚îÄ output\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ patient_geography_data\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ sim\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ vrp\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ...\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ CONTRIBUTING.md\n‚îú‚îÄ‚îÄ Capacity_Model_Template.ipynb\n‚îú‚îÄ‚îÄ LICENSE\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ Transport_Model_Template.ipynb\n‚îú‚îÄ‚îÄ environment.yaml\n‚îú‚îÄ‚îÄ main_vrp.py\n‚îú‚îÄ‚îÄ sim_replicate.py\n‚îî‚îÄ‚îÄ sim_single.py\nMore details on patient_geography_data/ folder:\n\npatient_counts_no_home_or_IOW.csv - ? counts per postcode\npatients.csv - table of patients with type, postcode, site, first day, and blank COVID status column\ntravel_matrix_distance_km.csv - travel distance (km) between postcodes\ntravel_matrix_time_min.csv - travel time (min) between postcodes\n\n‚îú‚îÄ‚îÄ patient_geography_data\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patient_counts_no_home_or_IOW.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patients.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ travel_matrix_distance_km.csv\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ travel_matrix_time_min.csv\nMore details on sim/ folder:\n\nallocation.py - methods to allocate patients to units and shifts\naudit.py - audit on patient and unit metrics\nend_trial_analysis.py - analysis after replicates, creates charts\nhelper_functions.py - expands multi-index\ninit.py - blank, to initalise as package\nmodel.py - model classes to hold patients, simulation model class\nparameters.py - classes for normal and uniform distributions, and class with parameters for scenario\npatient.py - patient class\npatients.csv - looks similar to patients.csv in main folder\ntravel_matrix.csv - patient travel times to each of the units\nunits.csv - information on each of the units\nunits.py - unit information from CSV\n\n‚îú‚îÄ‚îÄ sim\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ allocation.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ audit.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ end_trial_analysis.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ helper_functions.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ .ipynb_checkpoints\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ end_trial_analysis-checkpoint.py\n‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ helper_functions-checkpoint.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ model.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ parameters.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patient.py\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ patients.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ travel_matrix.csv\n‚îÇ¬†¬† ‚îú‚îÄ‚îÄ units.csv\n‚îÇ¬†¬† ‚îî‚îÄ‚îÄ units.py\n\n\n\n\n\nUntimed: Trying out WebPlotDigitizer\nTried using version 4, found it worked really well except:\n\nIt couldn‚Äôt differentiate confidence interval lines from the primary lines, which makes the resulting points hard to use.\nThe points extracted from these charts don‚Äôt necessarily align with the points obtained from the simulation (i.e.¬†line chart draws line through the days but points are at specific locations and not completely continuous).\n\nHence, I‚Äôm going to suggest that I don‚Äôt think it is worth trying to use this tool, and that a simpler and more standardised approach would be visual comparison of figures, or overlaying of the figures when possible.\n\n\nNA: Compile items in scope\nAll items are figures, so no actions required.\n\n\n12.10-12.15 Search for code that produces item in scope\nCapacity_Model_Template.ipynb creates figures incredibly similar to the article. Can spot a few slight differences likely due to different parameters. Some examples: * Figure 2, slightly wider confidence intervals in the notebook * Figure 4 number of displaced patients, different ‚Äúbumps‚Äù in the line\n\n\n12.15-12.16 Identify dependencies\nFrom article:\n\nDES on Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux\nPython 3.8\n\nWithin environment.yaml, can see packages and versions, to create a conda environment.\n\n\n12.19-12.29 Create environment\nCopied environment.yaml file into reproduction. Run the command conda env create --name covid19 --file environment.yaml from terminal within reproduction folder to create environment.\nFound that:\n\nReceived error CondaEnvException: Pip failed, for installing pip dependencies, Pip subprocess error: ImportError: libffi.so.7: cannot open shared object file: No such file or directory\n\nNoticed it was including Spyder in the environment which is an IDE so removed that.\n\nThis was then successful, and built quickly (within 30s). A quick glance over the environment confirmed that it looked to have the correct python version and packages.\n\n\n13.26-13.52 Reproduction\n\nCopied sim/ and sim_replicate.py into reproduction/.\nCopied code cells from Capacity_Model_Template.ipynb.\nError no module named joblib - add this to environment.yaml. Code was archived 22 April 2020, paper was published 13 August 2020. Used date of code archive, looking at https://pypi.org/project/joblib/#history, can see the version closest to prior to that date is 0.14.1 (10 Dec 2019) (as the next is 0.15.0 which is 15 May 2020). Add it to environment.yaml then ran conda env update --file environment.yaml --prune. This fixed the error.\nFileNotFoundError: [Errno 2] No such file or directory: ‚Äòoutput/base_3_month_reps_30_patient_audit.csv‚Äô. Not resolved by adding output/ folder.\n\nProtocol suggestion: On reflection, perhaps it would‚Äôve better to copy over the whole code folder into reproduction/ and then modify there, rather than copying over stuff bit by bit?\nSwitched to doing that -\n\nKept environment.yaml and example.ipynb, but otherwise copied everything over.\nDeleted irrelevant files\nRan again and it worked fine, didn‚Äôt get the FileNoteFoundError\n\nImages look similar to their notebook from Zenodo but, as with those figures, slight differences to paper, likely due to parameters.\n\n\nUntimed: Set up display of their code within the Quarto website\nBut can‚Äôt decide how best to display it - or if it is worth trying to display it all, or better just to suggest to browse the code repository themselves. Feels like an unhelpful distraction at present, and misleading compared to just allowing people to browse the code, so have suggested to change it to just displaying the PDFs and call it a day.\nUpdated the files accordingly.\n\n\n14.19-15.12 Reproduction\nOriginal:\n\nRun 1:\n\nRun 2:\n\n\nRan again and compared images to see if its varying between runs - it looked quite different! I saved each under new file names so not overwritten\nModel parameters input in the notebook look to match the paper (Table 1). Its 30 replications as in the paper too.\n\n\n\n\nTable 1\n\n\nnumber_of_replications = 30\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    total_proportion_people_infected = 0.8,\n    time_to_infection = Normal(60, 15, 0.0),\n    time_positive = Uniform(7, 14),\n    proportion_pos_requiring_inpatient= 0.6,\n    time_pos_before_inpatient = Uniform(3,7),\n    time_inpatient = Uniform(7.0, 14.0),\n    mortality = 0.15,\n    random_positive_rate_at_start = 0.0\n    )\n\nLooked through the paper and code for mention of ‚Äúseed‚Äù and ‚Äúrandom_state‚Äù - found:\n\nparameters.py - UniformParams has optional seed/random_state, generally set to random_state or None.\n\n\nThinking differences are defintely down to this. Thinking options are:\n\nLooking in their GitHub history in case they previously used random_state\nRun more replications than 30, to see what it settles on\nRun 30 replications, with a seed set each time, and then compare each against the article and see what comes closest. Make sure seed was set though! That might be tricky though‚Ä¶ as they haven‚Äôt established it with one‚Ä¶\n\nGitLab history:\nLooked into GitLab history at https://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19/-/commits/master.\nCan see there are releases more recent than Zenodo (22 April), which I had used, and the paper (received 28 april 2020, published 13 Aug 2020). All commits since the Zenodo publication was:\n\n22 April 2020 - Adding vrp tests\n23 April 2020 - Environment to binder/ and .yml\n23 April 2020 - Add link to binder in README\n23 April 2020 - Add Joblib to environment, 0.14.1 (which matches up with what I‚Äôd added)\n18 November 2020 - Fixed typo in .ipynb title\n\nNone of these would have any impact on results (besides it being re-run). Does confirm correct version of Joblib was used.\nThen looked back over older releases, but these were only just prior to the Zenodo publication (first was 20 April) and none use random state etc.\nRun more replications than 30\nAlthough it doesn‚Äôt match with the paper, I tried increasing replications to see what the figure averaged out to. However, then concluded that wasn‚Äôt particularly helpful in trying to get their results (although could be a way of saying that these are ‚Äúmore stable‚Äù results - although, it would impact on the confidence intervals and so on - if not able to set a seed).\nModifying script to set a random seed, to make the result I am getting from this code reproducible\nChange random_state in parameters.py from None to having a value for each in their class:\n\nNormalParams 1\nUniformParams 2\n\nOriginal:\n\nRun 1 with seeds added:\n\nRun 2 with seeds:\n\nHowever, this definitely has not fixed the issue! Still varying - and I wouldn‚Äôt be able to reproduce my own results twice either.\n\n\n15.23-16.35 Reproduction\n\n\n\n\n\n\nRandom seeds\n\n\n\nAt the moment, I would describe this model as reusable but not reproducible. It was really relatively quick to get the code up and running and see similar results to the paper. But in terms of getting it to match up to the paper, it is pretty much impossible, although I will try to get their via setting random seeds then running it lots of times to try and get a close match.\nThis is important for STARS framework improvement - that controlling randomness is important for reproducibility. It can also be handy for someone reusing a model, as they may wish to reproduce just to verify that its running properly for them.\nAnd so for each of the studies, if this is a recurring thing that comes up, its seeing where and how to add random seeds in different models and languages, to enable reproducibility.\n\n\nFrom this Stack Overflow post, I‚Äôm suspicious that perhaps the issue is that I am setting the random state as 1 and 2, which (a) would imply it‚Äôs making it the same between each run, but (b) all using the same stream in parallel processing. But it‚Äôs set using RandomState.\nTrying to google around use of seeds with parallel processing.\nHad a chat with Tom about it and he suggested:\n\nHe pointed out that NormalParams is not being used, and that it would need to be setting a seed in the class Normal() when you use it in Scenario - e.g.¬†extra parameter at end of here -\n\nrequiring_inpatient_random: Distribution = Uniform(0.0, 1.0)\ntime_pos_before_inpatient: Distribution = Uniform(3,7)\n\nGood example of how set up, would recommend this - https://pythonhealthdatascience.github.io/stars-simpy-example-docs/content/02_model_code/04_model.html#distribution-classes\nLLM model generation of seeds\n\nNeed seperate random number streams for each time make a distribution to use it.\nI thought best option is to switch to using it how it is uses in the treat-sim model docs, as focus here is just modifying code to allow it to reproduce each run.\nSo next things I did -\n\nDelete the NormalParams and UniformParams classes as not used - checked if still run fine which it did.\nModified the Normal and Uniform so the random number sampling matches up with treat-sim model docs, and Scenario class so it‚Äôs similar (class itself is just set up a little differently)\nIn .ipynb, removed the parameters from Scenario() that were identical to those when Scenario is created (except seed setting)\n\nThen ran it twice again (this time just with 5 replications). Not matching up yet -\nRun 1 with new random method:\n\nRun 2:"
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html#timings",
    "href": "evaluation/posts/2024_05_23/index.html#timings",
    "title": "Day 2",
    "section": "Timings",
    "text": "Timings\n\nimport sys\nsys.path.append('../')\nfrom timings import calculate_times\n\n# Minutes used prior to today\nused_to_date = 73\n\n# Times from today\ntimes = [\n    ('10.24', '11.00'),\n    ('12.10', '12.16'),\n    ('12.19', '12.29'),\n    ('13.26', '13.52'),\n    ('14.19', '15.12'),\n    ('15.23', '16.35')]\n\ncalculate_times(used_to_date, times)\n\nTime spent today: 203m, or 3h 23m\nTotal used to date: 276m, or 4h 36m\nTime remaining: 2124m, or 35h 24m\nUsed 11.5% of 40 hours max"
  },
  {
    "objectID": "evaluation/posts/2024_05_23/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_05_23/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 2",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nüí¨ = Noted to discuss with team.\nProtocol:\n\n‚úÖ Change from requiring to make notes about code and data, to just suggesting this. Focus should be on familiarisation rather than record keeping. These notes should just be within the logbook.\n‚úÖ Change from requiring search for code that produces scope, to just recommending it (as feel it can be helpful in familiarising, but not a necessity).\n‚úÖ Remove sugestion of WebPlotDigitizer etc., and instead suggest standardised approach of visually comparing the figures.\n‚úÖ For environment, suggest using the simplest approach - so using their environment file (or creating based on packages), and not worrying about operating system used. Could consider that with regards to troubleshooting though.\n\n‚úÖ Don‚Äôt worry about operating system\n‚úÖ Keep suggestion about package list and versions using close to publication date. Include how - i.e.¬†for finding packages that were missing, base version date on Zenodo/code archive/github if possible/earlier than the paper - if later than the paper, then base on the paper - or just base on the paper.\n‚úÖ To select packages, use the simplest method: looking manually at version history of each package. Can‚Äôt find a way to prevent it in Python. Knowing versions of the imported packages is as close as you get to if they provided a yaml file (as even with a yaml file, the dependencies they install alongside may be more recent).\n\n‚úÖ When create environment, this is the first time we might start using and modifying materials, so important to note that we should COPY over any environment stuff into our reproduction folder/, and not directly run scripts in original_study/, those should stay untouched\n‚úÖ Recommend that if there are multiple versions of code available (e.g.¬†a GitHub and Zenodo repository), that it is at researcher discretion to choose which is appropriate (for example, if one has later date than publication, then that aligning with publication date should be used).\n\nChange section of reproducing items to:\n\n‚úÖ Emphasise importance of copying over stuff when running (and not working in original_study/)\n‚úÖ Reminder to take very detailed notes in the logbook as go along of each copy, change, success, error.\n‚úÖ Suggestion to copy outputs (e.g.¬†images, tables) into blog post folder and displaying them in the post, so can easily share where up to at a given point.\n‚úÖ Allow troubleshooting step of asking STARS team, and that in these cases, that should be timed and a record should be made of the discussion and any recommendations made.\n‚úÖ Add recommendation on what to do if there is no control for randomness with seeds etc. (which anticipate to be likely)\n‚úÖ Integrate reproduction success within this (as it is done iteratively as you work, rather than all in one go at the end).\n‚úÖ Change figure reproduction success to be less about numbers (as not extracting those), and just about comparison by eye\n‚úÖ For all assessment of reproduction success, recommend that doesn‚Äôt require perfect match to state that it is successfully reproduced, but instead should be belief of researcher that the differences could likely be down to randomness (if not controlled).\n\nSuggestions to consider for research compendium stage:\n\nüí¨ Improve README (e.g.¬†repository overview - in this example, it took me a while to realise that ‚Äúvrp‚Äù was vehicle routing problem)\nüí¨ Appropriate seperation of data and code (as per convention for simulation - but ideal if parameters are stored seperately as easier to spot)\nüí¨ Improvements to code and clarity (e.g.¬†PEP-8, comments, docstrings)\nüí¨ Include description of run time for given examples\nüí¨ Remove unused packages\nüí¨ Add testing, focussed on being able to get same results from models with particular runs"
  },
  {
    "objectID": "evaluation/posts/2024_06_05/index.html",
    "href": "evaluation/posts/2024_06_05/index.html",
    "title": "Day 6",
    "section": "",
    "text": "Note\n\n\n\nEvaluation against reporting guidelines - finished STRESS-DES, and did for ISPOR-SDM."
  },
  {
    "objectID": "evaluation/posts/2024_06_05/index.html#work-log",
    "href": "evaluation/posts/2024_06_05/index.html#work-log",
    "title": "Day 6",
    "section": "Work log",
    "text": "Work log\n\nEvaluation against reporting guidelines (pt.¬†2)\nFinished STRESS-DES.\nUncertainties:\n\n2.5.5 Components - entry and exit points\n\nGet a second opinion on this - have I been too harsh?\nChat with Tom - fine, just describe and justify.\n\n5.1 Software or programming language: ‚ÄúWhere frameworks and libraries have been used provide all details including version numbers.‚Äù\n\nThis part of criteria is not in the report, but is in the linked code.\nPassed them anyway, as other parts of this criteria (OS, version, build DES software, Python) were provided - and also, wouldn‚Äôt think you would put this extra level of information in the report?\nChat with Tom - take a consistent approach (only basing on article) and therefore partially met if missing this (as purpose is to learn what people do and do not do)\n\n5.3 Model execution: ‚ÄúState the event processing mechanism used e.g.¬†three phase, event, activity, process interaction.‚Äù\n\nFeeling quite unclear on this. Did some research onto it but that hasn‚Äôt really cleared it up‚Ä¶\nBased answer on Tom‚Äôs, but don‚Äôt feel confident guessing at this for future ones\nChat with Tom - can often find based on package used, but do fail if not explicitly stated method in text\n\n\n\n\n\n\n\n\nEvent processing mechanism\n\n\n\n\n\nSimulation - The Practice of Model Development and Use (Stewart Robinson):\n\nThere are a few ways to model progress of time - one is time-slicing method, and other is discrete-event simulation (three phase method). ‚ÄúA number of machisms have been proposed for carrying out discrete-event simulation, among them are the event-based, activity-based, process-based and three-phase approaches. For a detailed discussion on these see Pidd (1998)‚Äù\nThree phase - Events are classified as B (bound or booked) or C (conditional). B events are state changes scheduled at a point in time (often relates to arrivals or finishing an activity). C events are state changes that depend on cidions of a model (e.g.¬†needing to wait until operator is free, often relat to start of an activity)\n\nIntro to DES:\n\nActivity scanning - ‚ÄúBasic building block is the activity. Model program‚Äôs code segments consist of sequences of activities (operations) waiting to be executed. An activity sequence‚Äôs conditions must be satisfied before it is executed. Simulation executive moves from event to event executing those activity sequences whose conditions are satisfied.‚Äù\nEvent scheduling - ‚ÄúBasic building block is the event. Model program‚Äôs code segments consist of event routines waiting to be executed. Event routine associated with each event type ‚Äì performs required operations for that type. Simulation executive moves from event to event executing the corresponding event routines‚Äù\nProcess interaction - ‚ÄúBasic building block is the process. System consists of a set of interacting processes. Model program‚Äôs code for each process includes the operations that it carries out throughout its lifetime. Event sequence for system consists of merging of event sequences for all processes. Future event list consists of a sequence of event nodes (or notices). Each event node indicates the event time and process to which it belongs. Simulation executive carries out the following tasks: (a) placement of processes at particular points of time in the list (b) removal of processes from the event list (c) activation of the process corresponding to the next event node from the event list (d) rescheduling of processes in the event list. Typically, a process object can be in one of several states: (a) active ‚Äì process is currently executing There is only one such process in a system. (b) ready ‚Äì process is in event list, waiting for activation at a certain time (c) idle (or blocked) ‚Äì process is not in event list, but eligible to be be reactivated by some other entity (e.g., waiting for a passive resource) (d) terminated ‚Äì process has completed its sequence of actions, is not in event list, and cannot be reactivated‚Äù\n\n\n\n\nThen completed the guidelines adapted from ISPOR-SDM.\nUncertainties:\n\n15 Is the model generalizability issue discussed?\n\nHave I been too harsh on this one? Or do we want it to be explicitly addressed?\nChat with Tom - fine, as before, just justify choice made\n\n\n\n\nComparison of my STRESS-DES against the original study\nTom shared the completed STRESS-DES checklits from the original study, and I compared against my evaluation (bearing in mind that theirs relates to the DES model and the Mone-Carlo vehicle routing model, whilst mine just relates to the former). Amendments:\n\n\n\n\n\n\n\n\nSection\nDifference between checklists\nChange made\n\n\n\n\n2.4 Algorithms\nThey included patient allocation to units (unit search strategy)\nI have now added this\n\n\n2.5.3 Components - resources\nThey refer to appendices to provide more details on units\nI have now added this\n\n\n2.5.4 Components - queues\nThey state this is N/A as there are no queues - I had been uncertain around this,\nI think their answer is appropriate (and no need for article to have described queues when there are none)\n\n\n2.5.5 - Components - entry/exit points\nI had been uncertain on this. They state that this is a fixed population, and that patients exit the dialysis model at mortality, citing Figure 1.\nIt remains unmet (as I do not feel this is clearly stated in the paper), but I have added their description.\n\n\n3.2 - Pre-processing\nI had stated as not applicable. They stated that there was processing in generating a travel time matrix from routine and open street map\nI have now added this\n\n\n4.1 - Initialisation\nThis was not described in the paper. I had suggested it was terminating, but original study states it is non-terminating.\nIt remains unmet, but I have added their description.\n\n\n5.3 - Model execution\nI had been unsure on what the mechanism was. They state that SimPy was used and that this has a Process based simulation worldview.\nIt remains unmet, but I have added their description.\n\n\n5.4 - System specification\nThey mention that replications were run in parallel across multiple CPU cores.\nI had not noted this, but as paper mentions using parallelism, have added a note of this.\n\n\n\n\n\n\n\nComparing best practice audit results with Monks and Harper\nCompared my decisions for the best practice audit against those made in Monks and Harper.\nTheir GitHub is TomMonks/des_sharing_lit_review, which provides the file bp_audit.zip. I used the provided code to clean this and saved it as bp_audit_clean.csv, which can then view here:\n\nimport pandas as pd\n\n# Import review results\nreview = pd.read_csv('bp_audit_clean.csv')\n\n# View the results for Allen et al. 2020\nreview[review['key'] == 'R4ZLYWPP'].T\n\n\n\n\n\n\n\n\n17\n\n\n\n\nUnnamed: 0\n17\n\n\nmodel_format\nCODE\n\n\nkey\nR4ZLYWPP\n\n\nitem_type\njournalArticle\n\n\npub_yr\n2020\n\n\nauthor\nAllen, M.; Bhanji, A.; Willemsen, J.; Dudfield...\n\n\ndoi\n10.1371/journal.pone.0237628\n\n\nreporting_guidelines_mention\nSTRESS\n\n\ncovid\n1\n\n\nsim_software\nSimPy\n\n\nfoss_sim\n1\n\n\nmodel_archive\nZenodo\n\n\nmodel_repo\nGitHub\n\n\nmodel_journal_supp\nNaN\n\n\nmodel_personal_org\nNaN\n\n\nmodel_platform\nBinderHub\n\n\ngithub_url\nhttps://git.exeter.ac.uk/tmwm201/dialysis-serv...\n\n\nmodel_has_doi\n1\n\n\norcid\n0.0\n\n\nlicense\nMIT\n\n\nreadme\n1\n\n\nlink_to_paper\n0.0\n\n\nsteps_run\n1\n\n\nformal_dep_mgt\n1\n\n\ninformal_dep_mgt\n0\n\n\nevidence_testing\n1.0\n\n\ndownloadable\n1\n\n\ninteractive_online\n1\n\n\n\n\n\n\n\nDifferent results:\n\nLink to published paper\n\nI said yes as its within Zenodo, but they said no\nI have amended my answer, as on reflection, I agree that this should be part of the artefacts themselves, and not just meta-data on Zenodo, as the artefacts are what you download, but have kept this as ‚Äúpartially met‚Äù\n\nInformal dependency management\n\nThey failed it as it was formal, but I will keep as passed, as the intention is to understand whether they had dependency management or not, so no changes to make here.\n\nCode testing\n\nThey said yes but I said no\nAsk tom what they felt was evidence of testing?\nChat with Tom - evidence was in GitLab rather than Zenodo (but was for the vehicle model, so evaluation remains the same)"
  },
  {
    "objectID": "evaluation/posts/2024_06_05/index.html#suggested-changes-for-protocoltemplate",
    "href": "evaluation/posts/2024_06_05/index.html#suggested-changes-for-protocoltemplate",
    "title": "Day 6",
    "section": "Suggested changes for protocol/template",
    "text": "Suggested changes for protocol/template\n‚úÖ = Made the change.\nProtocol:\n\n‚úÖ When not provided in article, my assumption might sometimes be wrong - e.g.¬†4.1 terminating when it was non-terminating - hence, importance here of (a) highlighting that this is my assumption and not stated by paper, and (b) checking those suggestions with other team members if possible.\n‚úÖ Quite a few differences between mine and the original - is this a concern or not? Always some human error on both sides of things. If wanted to be super rigorous you could have multiple evaluators. However, is that appropriate for this study, given motivations and capacity? Probably not. But would cite it as a limitation.\n‚úÖ All the studies should have been audited by Monks and Harper, so could add this comparison as a standard step to sense-check?"
  },
  {
    "objectID": "evaluation/reproduction_success.html",
    "href": "evaluation/reproduction_success.html",
    "title": "Reproduction success",
    "section": "",
    "text": "Of the three items in the scope, 100% (3 out of 3) were considered to be successfully reproduced.\nIn each case, it was felt that there were minimal variation between the original figures and reproduction, and that any variation was likely due to randomness of the simulation (as the original simulation was not controlled using seeds)."
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-2",
    "href": "evaluation/reproduction_success.html#figure-2",
    "title": "Reproduction success",
    "section": "Figure 2",
    "text": "Figure 2\nOriginal figure:\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-3",
    "href": "evaluation/reproduction_success.html#figure-3",
    "title": "Reproduction success",
    "section": "Figure 3",
    "text": "Figure 3\nOriginal figure:\n\n\n\n\n\nReproduction:"
  },
  {
    "objectID": "evaluation/reproduction_success.html#figure-4",
    "href": "evaluation/reproduction_success.html#figure-4",
    "title": "Reproduction success",
    "section": "Figure 4",
    "text": "Figure 4\nOriginal figure:\n\n\n\n\n\nReproduction:"
  }
]
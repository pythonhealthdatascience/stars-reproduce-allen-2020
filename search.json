[
  {
    "objectID": "evaluation/reproduction_success.html",
    "href": "evaluation/reproduction_success.html",
    "title": "Reproduction success",
    "section": "",
    "text": "A"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html",
    "href": "evaluation/posts/2024_05_22/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Created repository, uploaded materials, chose license."
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#made-repository-3.1.2",
    "href": "evaluation/posts/2024_05_22/index.html#made-repository-3.1.2",
    "title": "Day 1",
    "section": "Made repository (3.1.2)",
    "text": "Made repository (3.1.2)\nWithout using template (does not yet exist, will create based on this repository, which is a test-run)"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#upload-materials-3.1.3",
    "href": "evaluation/posts/2024_05_22/index.html#upload-materials-3.1.3",
    "title": "Day 1",
    "section": "12.11 - 12.16 Upload materials (3.1.3)",
    "text": "12.11 - 12.16 Upload materials (3.1.3)\nArticle:\n\nhttps://doi.org/10.1371%2Fjournal.pone.0237628\n\nSupplementary materials:\n\nhttps://doi.org/10.1371/journal.pone.0237628.s001\nhttps://doi.org/10.1371/journal.pone.0237628.s002\n\nCode - both code sources should be the same and pretty much same data, hence used Zenodo as that is the archived version:\n\nhttps://zenodo.org/records/3760626\nhttps://git.exeter.ac.uk/tmwm201/dialysis-service-delivery-covid19\n\nProtocol: Suggest what to record in logbook i.e. record the links. And that you record start time, do it, record end time, note down in logbook - unless that is too prescreptive."
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#choose-license-3.1.4",
    "href": "evaluation/posts/2024_05_22/index.html#choose-license-3.1.4",
    "title": "Day 1",
    "section": "12.18-12.19 Choose license (3.1.4)",
    "text": "12.18-12.19 Choose license (3.1.4)\nNo need to change from MIT, as that was used by Allen et al. 2020.\nProtocol: Say that default in template is MIT but may need to change. Makes sense to have this as a combined step with above perhaps? Although helpful to see seperate.\nTemplate: Set as STARS Project Team in default MIT license - is that correct?"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#display-on-website",
    "href": "evaluation/posts/2024_05_22/index.html#display-on-website",
    "title": "Day 1",
    "section": "Display on website",
    "text": "Display on website\nSet up article and supplementary to display on website in study_publciation.qmd.\nProtocol: Need to add creation of pages to display it within Quarto to logbook - when to do it, and when to time it. I naturally found I wanted to do it after upload. Publication in study_publication. Code in study_code. Although that does mean looking at the code before scoping? So actually, makes sense to do code later, when write up."
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#reading-article-3.2.1",
    "href": "evaluation/posts/2024_05_22/index.html#reading-article-3.2.1",
    "title": "Day 1",
    "section": "13.20-13.46 Reading article (3.2.1)",
    "text": "13.20-13.46 Reading article (3.2.1)\nRead article, making notes in study_summary.qmd\neasier to consolidate reading into a summary if it has a structure to it\nare the description of the sample part of scope? could do with some recommendation on this.\nneed seperate page for scope\nwhilst reading, find myself highlighting things for scope\nfor something like RCR, would it count as reproduction if we only focussed on part of the paper? worth perhaps noting that - although doesn’t change what we do now\nProtocol: This can be changed later. For now, when want to add images, added them into quarto_site alongside study_summary. If decide in scope, later move to reproduction/\ni made notes here as i read paper as I find that helps me concentrate better when reading, but that doesn’t have to be prescriptive?"
  },
  {
    "objectID": "evaluation/posts/2024_05_22/index.html#consolidating-notes-on-article-3.2.1",
    "href": "evaluation/posts/2024_05_22/index.html#consolidating-notes-on-article-3.2.1",
    "title": "Day 1",
    "section": "13.47- Consolidating notes on article (3.2.1)",
    "text": "13.47- Consolidating notes on article (3.2.1)\nMake rough notes whilst reading article, tidied these into a structured summary of model, to consolidate my understanding of model.\nDidn’t yet have a pre-defined structure for this. Figued simplest option is to use STRESS DES structure?"
  },
  {
    "objectID": "evaluation/badges.html",
    "href": "evaluation/badges.html",
    "title": "Badges",
    "section": "",
    "text": "This page evaluates the extent to which Monks et al. 2016 meets the criteria of badges related to reproducibility from various organisations and journals.\n\n\nCode\nimport numpy as np\nimport pandas as pd\n\ncriteria = {\n    'archive': 'Code is stored in a permanent archive that is publicly and openly accessible',\n    'id': 'It has a persistent identifier (e.g. DOI)',\n    'license': 'It has an open license',\n    'complete_open': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    'meta': 'Metadata describes data/code sufficiently to enable reproduction (e.g. package versions)',\n    'statement': 'Manuscript has data availability statement',\n    # DUPE with complete_open above (to reflect on)\n    'complete_review': 'Complete set of materials shared (as would be needed to fully reproduce article)',\n    # DUPE with meta above (to reflect on)\n    'describe_minimal': 'There is a minimal but sufficient description of artefacts',\n    'describe_careful': 'There is a more detailed, careful documentation of artefacts',\n    'artefacts_structure': 'Artefacts are well structured to facilitate reuse, adhering to norms and standards of research community',\n    'regenerated': 'Independent party regenerated results using the authors research artefacts',\n    'hour': 'Reproduced within approximately one hour (excluding compute time)',\n    # DUPE with artefacts_structure and meta/describe\n    'reproduce_organise': 'Requires data and scripts to be well-organised, clearly documented and with a README file with step-by-step instructions on how to reproduce results in the manuscript'\n}\n\nbadge_names = {\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'open_niso': 'NISO \"Open Research Objects\"',\n    'open_acm': 'ACM \"Artifacts Available\"',\n    'open_cos_data': 'COS \"Open Data\"',\n    'open_cos_materials': 'COS \"Open Materials\"',\n    'open_cos_code': 'COS \"Open Code\"',\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'open_ieee_code': 'IEEE \"Code Available\"',\n    'open_ieee_data': 'IEEE \"Datasets Available\"',\n    'open_springer': 'Springer Nature \"Badge for Open Data\"',\n    'review_acm_functional': 'ACM \"Artifacts Evaluated - Functional\"',\n    'review_acm_reusable': 'ACM \"Artifacts Evaluated - Reusable\"',\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'review_ieee_code': 'IEEE \"Code Reviewed\"',\n    'review_ieee_data': 'IEEE \"Datasets Reviewed\"',\n    'reproduce_niso': 'NISO \"Results Reproduced\"',\n    'reproduce_acm': 'ACM \"Results Reproduced\"',\n    # ISSUE: need to make seperate criteria for code and data (unless just do code?)\n    'reproduce_ieee_code': 'IEEE \"Code Reproducible\"',\n    'reproduce_ieee_data': 'IEEE \"Dataset Reproducible\"',\n    'reproduce_psy': 'Psychological Science \"Computational Reproducibility\"'\n}\n\nopen_cos = ['archive', 'id', 'license', 'complete_open', 'meta']\n\nbadges = {\n    'open_niso': ['archive', 'id', 'license', 'complete_open'],\n    'open_acm': ['archive', 'id'],\n    'open_cos_data': open_cos,\n    'open_cos_materials': open_cos,\n    'open_cos_code': open_cos,\n    'open_ieee_code': ['complete_open'],\n    # etc. etc.\n}\n\n\nTO DO: Change to full list of criteria\nTO DO: Change to full list of badges\nTO DO: Add a table (perhaps minimise-able) that summarises the criteria of each badge, so can see how/why did or did not meet each of the badges.\n\n\nCode\n# Example (not done for Monks et al. 2016 yet)\n# Based on the criteria dictionary above, populate with 1 and 0\neval = pd.Series({\n    'archive': 1,\n    'id': 1,\n    'license': 0,\n    'complete_open': 1,\n    'meta': 1,\n    'statement': 1\n    # etc. etc.\n})\n\n\n\n\nCode\n# Print compliance to each criteria\nfor key, value in eval.items(): \n    if value == 1:\n        icon = '✅'\n    else:\n        icon = '⬜'\n    print(f'{icon} {criteria[key]}')\n\n\n✅ Code is stored in a permanent archive that is publicly and openly accessible\n✅ It has a persistent identifier (e.g. DOI)\n⬜ It has an open license\n✅ Complete set of materials shared (as would be needed to fully reproduce article)\n✅ Metadata describes data/code sufficiently to enable reproduction (e.g. package versions)\n✅ Manuscript has data availability statement\n\n\n\n\nCode\n# Identify which badges would be awarded based on criteria\naward = {}\nfor badge in badges:\n    award[badge] = all([eval[key] == 1 for key in badges[badge]])\n\n# Print results\nfor key, value in award.items(): \n    if value:\n        icon = '✅'\n    else:\n        icon = '⬜'\n    print(f'{icon} {badge_names[key]}')\n\n\n⬜ NISO \"Open Research Objects\"\n✅ ACM \"Artifacts Available\"\n⬜ COS \"Open Data\"\n⬜ COS \"Open Materials\"\n⬜ COS \"Open Code\"\n✅ IEEE \"Code Available\""
  },
  {
    "objectID": "evaluation/reproduction_report.html",
    "href": "evaluation/reproduction_report.html",
    "title": "Computational reproducibility report",
    "section": "",
    "text": "Plain english summary"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html",
    "title": "Patient Transport Modelling",
    "section": "",
    "text": "This notebook provides an overview and instructions to run the patient transport model and explore results."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#aims-of-the-modelling",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#aims-of-the-modelling",
    "title": "Patient Transport Modelling",
    "section": "Aims of the modelling",
    "text": "Aims of the modelling\nThe model can be used to explore the impact of increasing transport vehicle (e.g. an ambulance) capacity on the total one-way travel time needed. We estimate two-way travel time via a simplification: doubling the one-way travel time.\nPlease note that:\n\nThe modelling is not intended to provide guidance on the number of vehicles needed.\n\nTravel time excludes vehicle turnaround time after each trip, duration of pickup and breaks rests for drivers.\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#the-vrp-package",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Transport_Model_Template.html#the-vrp-package",
    "title": "Patient Transport Modelling",
    "section": "The VRP package",
    "text": "The VRP package\nThe python VRP package provides functions and classes to:\n\nGenerate a simple weighted sample of a patient population spread over a geographic area.\nConstruct multiple short (but not necessarily optimal) routes for transport vehicles, with a given capacity, to travel to each patient from a ‘treatment facility’ and return.\nQuickly generate a large dataset of samples through parallel simulation.\n\n\nGeospatial and travel time data\nThe first step in parameterising a model is to load the input data files\n\nPatient count by postcode sector\nTravel times between each postcode sector\n\nThe data used in the analysis can be done access via functions in the module\nvrp.io\nNote the example here uses travel time. But travel distance could also be used.\n\nfrom vrp.io import (load_patient_postcode_count, \n                    load_travel_time)\n\n\ncost_matrix = load_travel_time()\nsector_counts = load_patient_postcode_count()\n\nThese functions each return a pandas.DataFrame\n\ntype(cost_matrix)\n\npandas.core.frame.DataFrame\n\n\n\ncost_matrix.shape\n\n(262, 262)\n\n\n\ntype(sector_counts)\n\npandas.core.frame.DataFrame\n\n\n\nsector_counts.head(3)\n\n\n\n\n\n\n\n\n\ncount\n\n\nsector\n\n\n\n\n\nL151\n1\n\n\nL91\n2\n\n\nL31\n1\n\n\n\n\n\n\n\n\n\n\nBuilt-in preprocessing\nTo convert a distribution of patient counts by postcodes to proportions use the following function\n\nfrom vrp.sim import create_postcode_distribution\n\n\npostcode_distribution = create_postcode_distribution(sector_counts)\n\n\ntype(postcode_distribution)\n\npandas.core.frame.DataFrame\n\n\n\npostcode_distribution.head(3)\n\n\n\n\n\n\n\n\n\ncount\nprob\n\n\nsector\n\n\n\n\n\n\nL151\n1\n0.001919\n\n\nL91\n2\n0.003839\n\n\nL31\n1\n0.001919\n\n\n\n\n\n\n\n\n\n\nRunning a transport experiment and exploring results\nThis can be done via six classes representing an simulated experiment, a scenario and a vehicle routing solvers.\nvrp.sim.TransportExperiment\nvrp.sim.Scenario\nvrp.sim.ILSWithConstructive\nvrp.constructive.SequentialClarkeWright\nvrp.sim.MultipleReplicationRunner\nvrp.sim.ScenarioManager\nTransportExperiment is a stochastic model. It generates a sample of the patient population to transport and then creates routes for patient transport services to use.\nScenario is a python dataclass. It is used to set the parameters for the simulation and passed to a TransportExperiment\nILSWithConstructive is a class that combines a simple constructive heuristic with Iterated Local Search\nSequentialClarkeWright is a constructive heuristic based for building transport routes based on the Clarke-Wright Savings algorithm.\nMultipleReplicationRunner allows a user to run multiple parallel replications of a simulation experiment.\nScenarioManager allows a user to run multiple parallel replications of multiple scenarios\n\nStep 1: create a scenario\nA Scenario accepts the following arguments\n\nn_patients: int, the number of patients to sample.\nwarehouse: str or int, the location of the depot/warehouse/facility where the vehicles start and end their trips.\nvehicle_capacities: list, e.g [2, 3, 4].\n\ncost_matrix: pandas.DataFrame, A travel distance or travel time matrix between all locations.\npostcode_distribution: pandas.DataFrame, the distribution of patients by postcode.\np_positive: float, the probability a sampled patient is positive\np_transport: float, the probability a sampled patient required transport\n\n\n#import the Scenario data class\nfrom vrp.sim import Scenario\n\n\nHOSP_LOCATION = 'L51'\nN_PATIENTS = 15\nCAPACITIES = [2, 3, 4]\nP_POS = 1.0\nP_TRAN = 1.0\n\n#sim parameters\nscenario_15 = Scenario(n_patients=N_PATIENTS,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n\n\nStep 2: create a Vehicle Routing Solver\n\n#import the Clark-Wright Savings euristic and ILS/Constructive wrapper classes\nfrom vrp.constructive import SequentialClarkeWright\nfrom vrp.sim import ILSWithConstructive\n\n\nN_ITER = 20\nsolver = ILSWithConstructive(constructive=SequentialClarkeWright(HOSP_LOCATION),\n                             warehouse=HOSP_LOCATION, \n                             iterations=N_ITER)\n\n\n\nStep 3: Create a transport experiment\n\n#import the TransportExperiment class\nfrom vrp.sim import TransportExperiment\n\n\nmodel = TransportExperiment(scenario=scenario_15, \n                            solver=solver)\n\n\n\nStep 3: Test run a single experiment\nThis should execute in &lt; 1 second.\n\n#set random seed to get a reproducible run\nSEED = 19\nnp.random.seed(SEED)\n\nresult = model.single_replication()\n\n\n#the result is a python dict with total travel time by capacity of vehicle\nresult\n\n{'capacity_1': 962,\n 'capacity_2': 630.0,\n 'capacity_3': 494.0,\n 'capacity_4': 463.0}\n\n\n\n\nStep 4: Execute multiple independent replications in parallel\nIt will take several seconds to run 10 replications. Depending on the population size, number of ILS iterations, and number of replications runtime can vary from seconds to hours.\n\nfrom vrp.sim import MultipleReplicationRunner\n\n\nrunner = MultipleReplicationRunner(model=model, random_state=SEED)\n\n\nN_REPS = 10\nresults = runner.execute(n_reps=N_REPS)\n\n\n#results is a list of dicts\ntype(results)\n\nlist\n\n\n\nresults[0]\n\n{'capacity_1': 974.0,\n 'capacity_2': 643.0,\n 'capacity_3': 528.0,\n 'capacity_4': 505.0}\n\n\n\n#convert results to a pandas DataFrame\ndf_results = pd.DataFrame(results)\n\n\ndf_results.head(3)\n\n\n\n\n\n\n\n\n\ncapacity_1\ncapacity_2\ncapacity_3\ncapacity_4\n\n\n\n\n0\n974.0\n643.0\n528.0\n505.0\n\n\n1\n1140.0\n707.0\n613.0\n492.0\n\n\n2\n712.0\n505.0\n411.0\n393.0\n\n\n\n\n\n\n\n\n\n#y-acis is in minutes in this example, but could be travel distance\ndf_results.boxplot(figsize=(12,5))\n\n\n\n\n\n\n\n\n\n\nStep 5: Analyse multiple scenarios\nFirst create multiple scenario objects\n\nHOSP_LOCATION = 'L51'\nCAPACITIES = [2, 3, 4]\nP_POS = 1.0\nP_TRAN = 1.0\n\n#scenario where 15 patients are positive on a day\nscenario_15 = Scenario(n_patients=15,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n#scenario where 25 patients are positive on a day\nscenario_25 = Scenario(n_patients=25,\n                       warehouse=HOSP_LOCATION,\n                       vehicle_capacities=CAPACITIES,\n                       cost_matrix = cost_matrix,\n                       postcode_distribution=postcode_distribution,\n                       p_positive=P_POS, \n                       p_transport=P_TRAN)\n\n#store these in a dict\nscenarios = {}\nscenarios['15_covid_positive'] = scenario_15\nscenarios['25_covid_positive'] = scenario_25\n\n\n#create a sce\nfrom vrp.sim import ScenarioManager\n\n\nSEED = 999\nmanager = ScenarioManager(scenarios, solver, random_state=SEED)\n\n\nscenario_results = manager.execute(N_REPS)\n\nRunning scenario: 15_covid_positive... done.\nRunning scenario: 25_covid_positive... done.\nAll experiments completed.\n\n\n\n#plot multiple scenarios in one figure\nfig, ax = plt.subplots(1, 2, figsize=(12,5), sharey=True)\nindex = 0\nfor scenario_name, result in scenario_results.items():\n    result.boxplot(ax=ax[index])\n    ax[index].set_title(scenario_name)\n    index += 1\n    \nax[0].set_ylabel('Travel Time (mins)');\n\n#uncomment to save to file...\n#fig.savefig('scenario_boxplots.png', dpi=300)\n\n\n\n\n\n\n\n\n\n#access one of the scenarios\nscenario_results['25_covid_positive']\n\n#uncomment to save results to file\n#scenario_results['25_covid_positive'].to_csv('single_scenario_result.csv')\n\n\n\n\n\n\n\n\n\ncapacity_1\ncapacity_2\ncapacity_3\ncapacity_4\n\n\n\n\n0\n1306.0\n834.0\n681.0\n586.0\n\n\n1\n1562.0\n976.0\n771.0\n706.0\n\n\n2\n1618.0\n1059.0\n868.0\n750.0\n\n\n3\n1896.0\n1175.0\n883.0\n799.0\n\n\n4\n1756.0\n1027.0\n827.0\n724.0\n\n\n5\n1250.0\n798.0\n618.0\n571.0\n\n\n6\n1732.0\n1095.0\n921.0\n854.0\n\n\n7\n1972.0\n1201.0\n966.0\n870.0\n\n\n8\n1514.0\n942.0\n720.0\n661.0\n\n\n9\n1150.0\n784.0\n681.0\n619.0\n\n\n\n\n\n\n\n\n\n### Doubling travel times\ntwo_way = scenario_results['25_covid_positive'] * 2\ntwo_way.boxplot(figsize=(12,5))"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/CONTRIBUTING.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/CONTRIBUTING.html",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "Michael Allen - m.allen@exeter.ac.uk\nThomas Monks - t.m.w.monks@exeter.ac.uk"
  },
  {
    "objectID": "quarto_site/study_code.html",
    "href": "quarto_site/study_code.html",
    "title": "Code",
    "section": "",
    "text": "insert the code as copied into repository."
  },
  {
    "objectID": "quarto_site/study_publication.html#supplementary-materials",
    "href": "quarto_site/study_publication.html#supplementary-materials",
    "title": "Publication",
    "section": "Supplementary materials",
    "text": "Supplementary materials"
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "Changelog\nAll notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning. Dates formatted as YYYY-MM-DD as per ISO standard."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nAllen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction code - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nReport - final report describing the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Reproducing Allen et al. 2020",
    "section": "",
    "text": "This book captures the reproduction of:\n\nAllen, M., Bhanji, A., Willemsen, J., Dudfield, S., Logan, S., & Monks, T. A simulation modelling toolkit for organising outpatient dialysis services during the COVID-19 pandemic. PLoS One 15, 8 (2020). https://doi.org/10.1371%2Fjournal.pone.0237628.\n\nUse the navigation bar above to view:\n\nOriginal study - the original study article and associated artefacts.\nReproduction code - code and documentation from reproduction of the model.\nEvaluation - describes model reproduction success and compares original study against guidelines for sharing research, criteria for journal reproducibility guidelines, and article reporting guidelines.\nLogbook - chronological entries detailing reproduction work.\nReport - final report describing the computational reproducibility assessment."
  },
  {
    "objectID": "index.html#project-team",
    "href": "index.html#project-team",
    "title": "Reproducing Allen et al. 2020",
    "section": "Project team",
    "text": "Project team\nConducting this reproduction:\n\nAmy Heather\n\nOther team members:\n\nThomas Monks\nAlison Harper\nNavonil Mustafee\nAndy Mayne"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Reproducing Allen et al. 2020",
    "section": "Citation",
    "text": "Citation\nAPA: Heather A. (2024). Reproducing Allen et al. 2020 URL: https://github.com/pythonhealthdatascience/stars-reproduce-allen-2020\nSee CITATION.cff and citation_bibtex.bib for alternative formats."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Reproducing Allen et al. 2020",
    "section": "License",
    "text": "License\nMIT License\nCopyright (c) 2024 STARS Project Team\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "quarto_site/study_summary.html",
    "href": "quarto_site/study_summary.html",
    "title": "Summary",
    "section": "",
    "text": "Type of model: Discrete event simulation (excluding sections of the paper relevant to another model - a Monte-Carlo vehicle routing model of patient transport)\nPurpose of model: Model service delivery in dialysis network during change in COVID-19 cases.\nDiscrete event simulation to model service delivery in dialysis network\nPart of the paper is also about a Monte-Carlo vehile routing model of patient transport (not in our scope).\nWessex - mixed urban/rural setting, renal dialysis services cares for 644 patients, nine centres\n75% of patients use patient transport services\nCOVID-positive patients treated seperately to COVID-negative.\nChange in inpatient and outpatient workload during pandemic at each deialysis unit in network. Estimate over three to six months. Estimate number of patients required to travel to different unit and change in travel time. Estimate vehicle total travel implications. (Some of this will be Monte Carlo).\nPatient location postcode. Travel time routine. Worst case time spread COVID Fergeson. Mortality rate, time patient COVID-positive before admission, and inpatient rate of stay were local parameters.\nModel:\n\nPython 3.8\nSimPy 3\nMatPlotLib\nSTRESS reporting guidelines\nDES on Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux\n\nDefined period (e.g. one year). Patients progress through phases of COVID (negative, positive, some with inpatient care, recovred, died). In each COVID state, model seeks to put them in appropriate unit and session, opening COVID-positive sessions in units that allow it. COVID-positive don’t mis with others.\nRun 30 times, show median and extremes.\n\n\n\nPatient pathway figure from Allen et al. 2020\n\n\nAll patients receive dialysis 3 times a week. Each patient starts on either Monday or Tuesday.\nHave proportion of patients either fixed or sampled from stochastic distribution for phases of COVID state and care.\nCOVID seperate from unifected and recoered.\n\n\n\nBaseline model parameters from Allen et al. 2020\n\n\nFor allocation to units, use search strategy: * COVID negative or recovered - look for place in current unit, if no space, find closest unit (by travel time) with available space * COVID positive - put in Queen Alexandara, and if full, make capacity in Basingstoke. If new COVID session required, more all COVID negative patients in that session as per neg rules. * COVID positive inpatient - all in Queen Alexandra (but allows search for unit with inpatients) * Unallocated - if can’t allocate to any units, attempt again next day\nOnce every week, attempts to reallocate patients back to starting unit or closest available. This is so cared more nearby and to compress COVID positive patients into few units and sessions.\nCOVID positive converted back to COVID negative when no longer needed.\nResults\nStates current median travel time from home to dialysis unit, and current capacity.\nFigures 2, 3, 4 show impact of COVID infecting 80% patients in next three months.\n\nUsing half of Queen Alexandra and then Basingstoke for excess for COVID positive copes without any patients being unallocated to session and no need to reduce dialysis frequency.\nReduces workflow in units not taking COVID positive patients.\nDisplaced patients typically need 20 extra minutes to get to temporary care place (sometimes 50 minutes)\n\n\n\n\nFigure 2\n\n\n\n\n\nFigure 3\n\n\n\n\n\nFigure 4\n\n\nDiscusion\nDialysis unit can cope with worst case spread. Requires reallocation of patients, will impact on ambulance and efficiency.\nLikely significant patient partessures, current capacity breached, consider moving dislaysi requipment during peak COVID positive.\nTransporting individually unsustainable.(Markov?)\nModel limitations - assumes can reallocate immediatley, assumes current capacity maintained (i.e. no staff shortage), not modelled timing, not included home dialysis."
  },
  {
    "objectID": "reproduction/scripts/example.html",
    "href": "reproduction/scripts/example.html",
    "title": "Example notebook (ipynb)",
    "section": "",
    "text": "This could be .ipynb or .Qmd. This example is .ipynb. Taken from HSMA DES Book.\n\nimport simpy\nimport random\nimport pandas as pd\n\n\n# Global parameter values\n# Don't make instance of this class, just access it directly\nclass g:\n    patient_inter = 5\n    mean_n_consult_time = 6\n    number_of_nurses = 1\n    sim_duration = 120\n    number_of_runs = 5\n\n\n# Entity (Patient) with two attributes: ID and time queueing\nclass Patient:\n    def __init__(self, p_id):\n        self.id = p_id\n        self.q_time_nurse = 0\n\n\nclass Model:\n    # Constructor to set up model for run\n    def __init__(self, run_number):\n        self.env = simpy.Environment()\n        self.patient_counter = 0\n        self.nurse = simpy.Resource(self.env, capacity=g.number_of_nurses)\n        self.run_number = run_number\n        # Blank dataframe for results\n        self.results_df = pd.DataFrame()\n        self.results_df[\"Patient ID\"] = [1]\n        self.results_df[\"Q Time Nurse\"] = [0.0]\n        self.results_df[\"Time with Nurse\"] = [0.0]\n        self.results_df.set_index(\"Patient ID\", inplace=True)\n        # Blank attribute to store mean queue time of run\n        self.mean_q_time_nurse = 0\n\n    # Generator function for patient arriving\n    def generator_patient_arrivals(self):\n        # Infinite loop does this indefinitely during simulation run\n        while True:\n            self.patient_counter += 1\n            # Create a new patient\n            p = Patient(self.patient_counter)\n            # Send through process\n            self.env.process(self.attend_clinic(p))\n            # Sample time to next patient (inter-arrival time)\n            sampled_inter = random.expovariate(1.0 / g.patient_inter)\n            # Freeze this instance of this function until time has elapsed\n            yield self.env.timeout(sampled_inter)\n\n    # Generator function for patient going through clinic\n    def attend_clinic(self, patient):\n        # Wait start time\n        start_q_nurse = self.env.now\n        # Request a nurse resource\n        with self.nurse.request() as req:\n            # Queue until resource available\n            yield req\n            # Wait end time\n            end_q_nurse = self.env.now\n            patient.q_time_nurse = end_q_nurse - start_q_nurse\n            # Sample time with nurse\n            sampled_nurse_act_time = random.expovariate(1.0 /\n                                                        g.mean_n_consult_time)\n            # Store queue time and time with nurse in results\n            self.results_df.at[patient.id, \"Q Time Nurse\"] = (\n                patient.q_time_nurse)\n            self.results_df.at[patient.id, \"Time with Nurse\"] = (\n                sampled_nurse_act_time)\n            # Freeze this instance of this function (i.e. for this entity) for the time spent with nurse\n            yield self.env.timeout(sampled_nurse_act_time)\n            # Sink\n\n\n    def calculate_run_results(self):\n        # Find mean queue time\n        self.mean_q_time_nurse = self.results_df[\"Q Time Nurse\"].mean()\n\n\n    def run(self):\n        # Start up DES entity generators that create new patients\n        self.env.process(self.generator_patient_arrivals())\n        # Run the model\n        self.env.run(until=g.sim_duration)\n        # Calculate results\n        self.calculate_run_results()\n        # Print results\n        print (f\"Run Number {self.run_number}\")\n        print (self.results_df)\n\n\nclass Trial:\n    # Set up dataframe to store results from each run\n    def  __init__(self):\n        self.df_trial_results = pd.DataFrame()\n        self.df_trial_results[\"Run Number\"] = [0]\n        self.df_trial_results[\"Mean Q Time Nurse\"] = [0.0]\n        self.df_trial_results.set_index(\"Run Number\", inplace=True)\n\n    # Print trial results\n    def print_trial_results(self):\n        print (\"Trial Results\")\n        print (self.df_trial_results)\n\n    def run_trial(self):\n        for run in range(g.number_of_runs):\n            # Conduct run of model\n            my_model = Model(run)\n            my_model.run()\n            # Store results from run\n            self.df_trial_results.loc[run] = [my_model.mean_q_time_nurse]\n        # Print trial results\n        self.print_trial_results()\n\n# To run the above, create instance of trial class and run it\nmy_trial = Trial()\nmy_trial.run_trial()\n\nRun Number 0\n            Q Time Nurse  Time with Nurse\nPatient ID                               \n1               0.000000         0.409188\n2               0.000000         8.100493\n3               5.742528         2.027577\n4               0.285292         8.021103\n5               2.169934         0.812972\n6               1.787660         4.975679\n7               4.152844         8.475809\n8               0.636725        11.118521\n9               9.933379        13.579424\n10             19.631816         2.318209\n11             15.678563         4.760156\n12             17.947855         2.919600\n13             18.492176         0.566682\n14             12.620286         1.183490\n15             12.140536         1.326338\n16             12.858259         7.448187\n17             18.428704         5.328174\n18             19.953129         3.616531\n19             18.001635         5.880564\n20             22.429778         0.267782\n21             22.320529         2.487885\n22              9.548502         9.597006\n23             14.396941         6.272699\n24             16.072207         3.328748\n25             18.122587        10.206102\nRun Number 1\n            Q Time Nurse  Time with Nurse\nPatient ID                               \n1               0.000000         2.516259\n2               1.115424         3.644607\n3               0.000000         7.944117\n4               0.000000         8.811074\n5               4.310967         0.425983\n6               3.417324         0.212787\n7               0.000000         4.535966\n8               3.986428         2.065685\n9               0.000000        16.135685\n10              9.562419         0.772438\n11              8.888352         3.674308\n12              3.275494         2.214535\n13              0.000000        22.009625\n14             16.755442         2.618881\n15             14.796738         7.545737\n16             21.098239         7.087591\n17             17.525011         6.807372\nRun Number 2\n            Q Time Nurse  Time with Nurse\nPatient ID                               \n1               0.000000         3.331999\n2               0.000000         2.926743\n3               0.000000        25.176285\n4               3.245599         0.461992\n5               0.000000         0.079364\n6               0.000000         2.698655\n7               1.053251         1.164030\n8               1.610119         0.155731\n9               0.919789        15.679076\n10              0.000000         2.977460\n11              0.000000         5.333376\n12              0.000000         0.655473\nRun Number 3\n            Q Time Nurse  Time with Nurse\nPatient ID                               \n1               0.000000         6.980844\n2               3.038776        11.509943\n3               0.000000         1.347718\n4               0.000000         0.179672\n5               0.000000         2.533136\n6               0.000000         4.348770\n7               1.146818        12.305038\n8               7.843208         3.427361\n9              10.488391        10.138762\n10             20.552358        21.661585\n11             25.784807         4.094876\n12             28.399336         3.926248\n13             22.634506        16.149078\nRun Number 4\n            Q Time Nurse  Time with Nurse\nPatient ID                               \n1               0.000000         0.949441\n2               0.000000         5.865261\n3               4.826353         6.488822\n4               8.417712         4.738231\n5               6.414321         3.498835\n6               0.000000        10.198860\n7               0.441545         4.262194\n8               4.699087         4.872532\n9               0.000000         3.793313\n10              0.000000         1.189360\n11              0.000000        26.569040\nTrial Results\n            Mean Q Time Nurse\nRun Number                   \n0                   11.734075\n1                    6.160696\n2                    0.569063\n3                    9.222169\n4                    2.254456"
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html",
    "title": "Dialysis capapcity model",
    "section": "",
    "text": "The dialysis model runs through a defined period (e.g. one year) and simulates the progression of patients through phases of COVID infection: negative, positive (with some requiring inpatient care) and recovered or died. The speed of progression of infection through the population may be varied (typically 3-12 months).\nAs patients change COVID state the model seeks to place them in the appropriate unit and session, opening up COVID-positive sessions in units that allow it. COVID-positive patients do not mix with any other patients. Opening up COVID-positive sessions causes other patients to be displaced from that session, and the model seeks to reallocate them either to the same unit or, if there is no space left, to the closest alternative unit.\nWhen allocating patients to units, the following search strategy is employed.\nPatients, in the model, may end up being cared for at a more distant unit than their starting unit. Once every week, the model seeks to reallocate patients back to their starting unit, or closest available unit if room in their starting unit is not available. This will also compress COVID-positive patients into as few units and sessions as possible."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#input-files",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#input-files",
    "title": "Dialysis capapcity model",
    "section": "Input files",
    "text": "Input files\n\nUnit capacity and use\nThe input file ./sim/units.csv allows definition and use of units:\n\nunit: the name used in outputs.\nsubunit: units may be broken down into two or more subunits. This may be done, for example, if only a part of the unit will be made available to COVID-19 positive patients.\nChairs: the number of dialysis chairs available in each session.\ninpatient: Set to 1 for hospitals that can accept COVID postive dialysis inpatients.\nAllow cov +: a value of 1 indicates that sessions for that unit, or subunit, may be made available to COVID positive patients.\nCov +ve order: The order in which units open up for COVID positive dialysis out patients.\nMon_1 thru Tues_3: Three sessions per day on Mon/Tues (which repeat on Wed/Thurs and Fri/Sat). A 1 indicates that the session is open for booking.\n\n\n\nPatients\nThe input file ./sim/units.csv contains information on patients:\n\nPatient ID: Any id of patient.\nPatient type: Not currently used in model.\nPostcode sector: Home postcode sector of patient.\nSite: Site patient currently attends.\nSubunit: Allocation of patient to subunit (if subunits use, you can simply assign them to any of them at the beginning of the model).\nSite postcode: Postcode of dialysis unit\nCOVID status: Can be set to positive if patients known to be positive at the start of the model run.\nfirst_day: Either Mon or Tues for patients having dialysis Mon/Wed/Fri or Tues/Thurs/Sat.\ncount*: set to 1 for all patients.\n\n\n\nTravel matrix\nThe input file ./sim/travel_matrix.csv contains travel times (minutes) from all patient postcode sectors to all dialysis units. We used Routino (routino.org) to obtain travel times."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#code-and-example",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/Capacity_Model_Template.html#code-and-example",
    "title": "Dialysis capapcity model",
    "section": "Code and example",
    "text": "Code and example\n\nimport sim_replicate as sim\nfrom sim.parameters import Scenario, Uniform, Normal\n\nScenarios are defined in dictionaries as below. Multiple sceanrios may be defined and all results are saved to the ./output folder.\nParameters in the dictionary are:\n\nrun_length: Model run in days.\ntotal_proportion_people_infected. The proportion of patients who may be infected in the model. We assume this will be limited by herd immunity (or a vaccine).\ntime_to_infection: The time from start of model run to the time patients are infected. For time to infection a normal distrubtion is used. The paramters applied are mean, standard deviation, and lower cut-off (use 0 to avoid negative values) in days. In scarios we describe as 3 months we assume that six standard deviations of the distrubution (3 either side of the mean) occur in 3 months, or 90 days, so a standard deviation of 90/6 (or 15) is used.\ntime_positive: The duration a patient is positive if they remain in outpatient dialysis. A uniform distribution is used.\nproportion_pos_requiring_inpatient: The poportion of infected patients who will require inpatient dialysis.\ntime_pos_before_inpatient: For patients who will receive inpatient care, this is the time spent as a COVID positive outpatient before being hospitalised. A uniform distribution is used.\ntime_inpatient: The length of stay as an inpatient. A uniform distribution is used.\nmortality: The average mortality of dialysis patients who become infected with COVID.\nrandom_positive_rate_at_start: The model allows a proportion of patients to be randomly infected at the start of the model run.\n\nDefine a sceanrio and the numebr of model runs below (the replicates will use all available CPU cores).\n\nnumber_of_replications = 30\nscenarios = {}\nscenarios['base_3_month'] = Scenario(\n    run_length=150,\n    total_proportion_people_infected = 0.8,\n    time_to_infection = Normal(60, 15, 0.0),\n    time_positive = Uniform(7, 14),\n    proportion_pos_requiring_inpatient= 0.6,\n    time_pos_before_inpatient = Uniform(3,7),\n    time_inpatient = Uniform(7.0, 14.0),\n    mortality = 0.15,\n    random_positive_rate_at_start = 0.0\n    )\n\nRun the scenario. Three sets of charts will be outputed for each scenario (and saved with sceanrio names in the ./output directory: * Numbers of patients in negative, positive outpatient, positive inpatient, recovered/died stages of COVID: * Number of patients displaced from their starting dialysis unit, and how much extra travel time there is to their unit of current care. * Numbers of patients (negative/recovered, positive outpatient, pisitive inpatient) at each dialysis unit.\n\nsim.run_replications(scenarios, number_of_replications)\n\nRunning 30 reps of base_3_month =&gt; Done."
  },
  {
    "objectID": "original_study/dialysis-service-delivery-covid19-v1.0/vrp/transport_charts.html",
    "href": "original_study/dialysis-service-delivery-covid19-v1.0/vrp/transport_charts.html",
    "title": "Transport model charts",
    "section": "",
    "text": "The code below produces the figures in the report illustrating the transport results.\n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\n\nFILE_1 = '20_positive_CW.csv'\nFILE_2 = '40_positive_CW.csv'\nFILE_3 = '60_positive_CW.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity to HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n#'P(positive) = {p_pos}. P(need transport)={p_transport}')\nax[0].set_ylabel('total driving time (mins)')\n#ax[0].set_xlabel('ambulance seating capacity')\n#ax[1].set_xlabel('ambulance seating capacity')\n#ax[2].set_xlabel('ambulance seating capacity')\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\nfig.savefig('output/prelim_model_tuned.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity to HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n#'P(positive) = {p_pos}. P(need transport)={p_transport}')\nax[0].set_ylabel('total driving time (mins)')\n#ax[0].set_xlabel('ambulance seating capacity')\n#ax[1].set_xlabel('ambulance seating capacity')\n#ax[2].set_xlabel('ambulance seating capacity')\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\nfig.savefig('output/prelim_model_ils.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nPATIENTS = 250\nP_POS_1 = 0.3\nP_TRANSPORT_1 = 0.75\nN_REPS = 1000\nSCALE = 2\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('40 COVID-19 Positive')\nax[2].set_title('60 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_outward_ILS.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '30_positive_ILS.csv'\nFILE_3 = '40_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 1\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\n#results = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('30 COVID-19 Positive')\nax[2].set_title('40 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_ILS_20_30_40.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '30_positive_ILS.csv'\nFILE_3 = '40_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 2\n\nfig, ax = plt.subplots(1, 3, sharey=True, sharex=False, figsize=(12,6))\n\nresults = pd.read_csv(f'output/{FILE_1}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[0],column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_2}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[1], column=['1', '2', '3', '4'])\n\nresults = pd.read_csv(f'output/{FILE_3}')\nresults.columns = ['0', '1', '2', '3', '4']\nresults = results * SCALE\nresults.boxplot(ax=ax[2], column=['1', '2', '3', '4'])\n\n#title = f'Covid-19 ambulance transport time by seating capacity TO and FROM HU ({N_REPS} model runs).'\n#fig.suptitle(title)\nfig.subplots_adjust(hspace=0.4)\n\nax[0].set_ylabel('total driving time (mins)')\n\nax[0].set_title('20 COVID-19 Positive')\nax[1].set_title('30 COVID-19 Positive')\nax[2].set_title('40 COVID-19 Positive')\n\n#ax[0].annotate('*Results compare proportion Covid19+ive and ambulance seating capacity (e.g. 2 = 2 seats.)\\n**Figures do not include ambulance clean-down/turnaround time.',\n#            xy=(65, 11), xycoords='figure pixels')\n\n\nfig.savefig('output/prelim_model_inward_outward_ILS_20_30_40.png', dpi=300, bbox_inches='tight')\n\n\n\n\n\n\n\n\n\nSummary statistics\n\nFILE_1 = '20_positive_ILS.csv'\nFILE_2 = '40_positive_ILS.csv'\nFILE_3 = '60_positive_ILS.csv'\n\nN_REPS = 1000\nSCALE = 2\n\nresults_20 = pd.read_csv(f'output/{FILE_1}')\nresults_20.columns = ['0', '1', '2', '3', '4']\nresults_20_double = results_20 * SCALE\n\n\n(results_20 / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n21.163067\n13.478783\n11.100733\n9.902833\n\n\nstd\n4.813657\n3.423492\n2.048313\n1.627923\n1.415795\n\n\nmin\n0.000000\n12.433333\n8.100000\n6.716667\n6.083333\n\n\n25%\n4.162500\n18.691667\n12.000000\n9.966667\n8.895833\n\n\n50%\n8.325000\n21.200000\n13.550000\n11.141667\n9.866667\n\n\n75%\n12.487500\n23.466667\n14.833333\n12.183333\n10.933333\n\n\nmax\n16.650000\n33.000000\n21.050000\n15.650000\n13.850000\n\n\n\n\n\n\n\n\n\n(results_20_double / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n42.326133\n26.957567\n22.201467\n19.805667\n\n\nstd\n9.627315\n6.846984\n4.096627\n3.255847\n2.831590\n\n\nmin\n0.000000\n24.866667\n16.200000\n13.433333\n12.166667\n\n\n25%\n8.325000\n37.383333\n24.000000\n19.933333\n17.791667\n\n\n50%\n16.650000\n42.400000\n27.100000\n22.283333\n19.733333\n\n\n75%\n24.975000\n46.933333\n29.666667\n24.366667\n21.866667\n\n\nmax\n33.300000\n66.000000\n42.100000\n31.300000\n27.700000\n\n\n\n\n\n\n\n\n\nresults_40 = pd.read_csv(f'output/{FILE_2}')\nresults_40.columns = ['0', '1', '2', '3', '4']\nresults_40_double = results_40 * SCALE\n(results_40 / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n40.191267\n24.244500\n19.077550\n16.572867\n\n\nstd\n4.813657\n4.685456\n2.658565\n2.002235\n1.701350\n\n\nmin\n0.000000\n24.500000\n14.983333\n11.716667\n10.616667\n\n\n25%\n4.162500\n36.900000\n22.383333\n17.662500\n15.416667\n\n\n50%\n8.325000\n40.100000\n24.258333\n19.066667\n16.550000\n\n\n75%\n12.487500\n43.333333\n26.066667\n20.416667\n17.716667\n\n\nmax\n16.650000\n55.033333\n32.150000\n24.733333\n21.433333\n\n\n\n\n\n\n\n\n\n(results_40_double / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n80.382533\n48.489000\n38.155100\n33.145733\n\n\nstd\n9.627315\n9.370911\n5.317131\n4.004470\n3.402700\n\n\nmin\n0.000000\n49.000000\n29.966667\n23.433333\n21.233333\n\n\n25%\n8.325000\n73.800000\n44.766667\n35.325000\n30.833333\n\n\n50%\n16.650000\n80.200000\n48.516667\n38.133333\n33.100000\n\n\n75%\n24.975000\n86.666667\n52.133333\n40.833333\n35.433333\n\n\nmax\n33.300000\n110.066667\n64.300000\n49.466667\n42.866667\n\n\n\n\n\n\n\n\n\n#iqr capacity 1\niqr_1 = (results_40_double / 60).describe().loc['75%']['1'] - (results_40_double / 60).describe().loc['25%']['1']\niqr_1\n\n12.866666666666674\n\n\n\niqr_1 = (results_40_double / 60).describe().loc['75%']['1'] - (results_40_double / 60).describe().loc['25%']['1']\niqr_2 = (results_40_double / 60).describe().loc['75%']['2'] - (results_40_double / 60).describe().loc['25%']['2']\niqr_3 = (results_40_double / 60).describe().loc['75%']['3'] - (results_40_double / 60).describe().loc['25%']['3']\niqr_4 = (results_40_double / 60).describe().loc['75%']['3'] - (results_40_double / 60).describe().loc['25%']['3']\n\n\nmdn_1 = (results_40_double / 60).describe().loc['50%']['1']\nmdn_2 = (results_40_double / 60).describe().loc['50%']['2']\nmdn_3 = (results_40_double / 60).describe().loc['50%']['3']\nmdn_4 = (results_40_double / 60).describe().loc['50%']['4']\n\n\n(mdn_1 - mdn_2) / mdn_1\n\n0.3950540315876975\n\n\n\n(mdn_1 - mdn_3) / mdn_1\n\n0.5245220282626767\n\n\n\n(mdn_1 - mdn_4) / mdn_1\n\n0.587281795511222\n\n\n\nresults_60 = pd.read_csv(f'output/{FILE_3}')\nresults_60.columns = ['0', '1', '2', '3', '4']\nresults_60_double = results_60 * SCALE\n\n\n(results_60 / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n8.325000\n56.972333\n33.508400\n25.832817\n22.076150\n\n\nstd\n4.813657\n5.562399\n3.053067\n2.263760\n1.883696\n\n\nmin\n0.000000\n40.033333\n24.100000\n19.166667\n16.483333\n\n\n25%\n4.162500\n53.100000\n31.433333\n24.300000\n20.733333\n\n\n50%\n8.325000\n56.800000\n33.491667\n25.825000\n22.066667\n\n\n75%\n12.487500\n60.766667\n35.650000\n27.450000\n23.437500\n\n\nmax\n16.650000\n76.633333\n44.066667\n34.116667\n28.183333\n\n\n\n\n\n\n\n\n\nmdn60_1 = (results_60_double / 60).describe().loc['50%']['1']\nmdn60_2 = (results_60_double / 60).describe().loc['50%']['2']\nmdn60_3 = (results_60_double / 60).describe().loc['50%']['3']\nmdn60_4 = (results_60_double / 60).describe().loc['50%']['4']\n\n\n(results_60_double / 60).describe()\n\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\ncount\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n1000.000000\n\n\nmean\n16.650000\n113.944667\n67.016800\n51.665633\n44.152300\n\n\nstd\n9.627315\n11.124798\n6.106134\n4.527521\n3.767392\n\n\nmin\n0.000000\n80.066667\n48.200000\n38.333333\n32.966667\n\n\n25%\n8.325000\n106.200000\n62.866667\n48.600000\n41.466667\n\n\n50%\n16.650000\n113.600000\n66.983333\n51.650000\n44.133333\n\n\n75%\n24.975000\n121.533333\n71.300000\n54.900000\n46.875000\n\n\nmax\n33.300000\n153.266667\n88.133333\n68.233333\n56.366667"
  },
  {
    "objectID": "evaluation/artefacts.html",
    "href": "evaluation/artefacts.html",
    "title": "Sharing research artefacts",
    "section": "",
    "text": "This page evaluates the extent to which Monks et al. 2016 meets the recommendations for the sharing of code and associated materials.\nFirst, it copies information from the best practice audit by Monks and Harper (2023). The items in this audit were based on ADD CITATIONS.\nSecondly, it assesses whether the article meets recommendations from the recently published STARS framework by Monks, Harper, and Mustafee (2024)."
  },
  {
    "objectID": "evaluation/artefacts.html#best-practice-audit-monks-and-harper-2023",
    "href": "evaluation/artefacts.html#best-practice-audit-monks-and-harper-2023",
    "title": "Sharing research artefacts",
    "section": "Best practice audit (Monks and Harper 2023)",
    "text": "Best practice audit (Monks and Harper 2023)\n\n\n\n\n\n\n\n\nItem\nDescription\nMet by study?\n\n\n\n\nDigital Object Identifier\nDoes the model have a DOI and promise of persistence? Can it be cited?\n\n\n\nOpen Researcher and Contributor ID\nIs the model linked to one or more of the authors via an ORCID?\n\n\n\nLicence\nDoes the repository have a recognised open license to control the use of code, liabilty and credit?\n\n\n\nReadme file\nIs there an obvious file that provides an overview of the repository/model and it purpose?\n\n\n\nLink to published paper\nDo models shared externally from journal articles contain a link to the published article?\n\n\n\nSteps to run code\nDoes the readme file or similar describe the steps required to execute the simulation model?\n\n\n\nFormal dependency management\nHas a formal tool, e.g. renv, conda, or poetry been used to manage software dependencies for the simulation model?\n\n\n\nInformal dependency management\nHas an informal list or description of software, or OS dependencies been provided?\n\n\n\nCode Testing\nIs there any evidence of tests that have been applied to the code to check that it functions correctly?\n\n\n\nLocal execution\nCan the simulation model and associated files be downloaded and in theory executed on a local machine\n\n\n\nRemote execution\nCan the simulation model be executed online using free or commercial infrastructure?"
  },
  {
    "objectID": "evaluation/artefacts.html#stars",
    "href": "evaluation/artefacts.html#stars",
    "title": "Sharing research artefacts",
    "section": "STARS",
    "text": "STARS\n\n\n\n\n\n\n\n\nComponent\nMet by study?\nEvidence/location\n\n\n\n\nEssential components\n\n\n\n\nOpen license\n✅ Fully\n\n\n\nDependency management\n🟡 Partially\n\n\n\nModel created using free and open-source software (FOSS)\n❌ Not met\n\n\n\nMinimum documentation\n❔ Unclear\n\n\n\nResearch artefact metadata: Open Researcher and Contributor ID (ORCID) and citation information\n\n\n\n\nRemote code repository\n\n\n\n\nOpen science archive\n\n\n\n\nOptional components\n\n\n\n\nEnhanced documentation\n\n\n\n\nDocumentation hosting\n\n\n\n\nOnline coding environment\n\n\n\n\nModel interface\n\n\n\n\nWeb app hosting"
  },
  {
    "objectID": "evaluation/reporting.html",
    "href": "evaluation/reporting.html",
    "title": "Reporting",
    "section": "",
    "text": "This page evaluates the extent to which Monks et al. 2016 meets the criteria from two discrete-event simulation study reporting guidelines:\nif we apply this later down the line, what about if its not discrete-event?"
  },
  {
    "objectID": "evaluation/reporting.html#stress-des",
    "href": "evaluation/reporting.html#stress-des",
    "title": "Reporting",
    "section": "STRESS-DES",
    "text": "STRESS-DES\nexample fill in, not actual\nTotal (out of 5):\n\n✅ Fully - 20% (n=1)\n🟡 Partially - 20% (n=1)\n❌ Not met - 20% (n=1)\n❔ Unclear - 40% (n=2)\n\n\n\n\n\n\n\n\n\n\nItem\nRecommendation\nMet by study?\nEvidence/location\n\n\n\n\nObjectives\n\n\n\n\n\n1.1 Purpose of the model\nExplain the background and objectives for the model\n✅ Fully\n\n\n\n1.2 Model outputs\nDefine all quantitative performance measures that are reported, using equations where necessary. Specify how and when they are calculated during the model run along with how any measures of error such as confidence intervals are calculated.\n🟡 Partially\n\n\n\n1.3 Experimentation aims\nIf the model has been used for experimentation, state the objectives that it was used to investigate.(A) Scenario based analysis – Provide a name and description for each scenario, providing a rationale for the choice of scenarios and ensure that item 2.3 (below) is completed.(B) Design of experiments – Provide details of the overall design of the experiments with reference to performance measures and their parameters (provide further details in data below).(C) Simulation Optimisation – (if appropriate) Provide full details of what is to be optimised, the parameters that were included and the algorithm(s) that was be used. Where possible provide a citation of the algorithm(s).\n❌ Not met\n\n\n\nLogic\n\n\n\n\n\n2.1 Base model overview diagram\nDescribe the base model using appropriate diagrams and description. This could include one or more process flow, activity cycle or equivalent diagrams sufficient to describe the model to readers. Avoid complicated diagrams in the main text. The goal is to describe the breadth and depth of the model with respect to the system being studied.\n❔ Unclear\n\n\n\n2.2 Base model logic\nGive details of the base model logic. Give additional model logic details sufficient to communicate to the reader how the model works.\n❔ Unclear\n\n\n\n2.3 Scenario logic\nGive details of the logical difference between the base case model and scenarios (if any). This could be incorporated as text or where differences are substantial could be incorporated in the same manner as 2.2.\n\n\n\n\n2.4 Algorithms\nProvide further detail on any algorithms in the model that (for example) mimic complex or manual processes in the real world (i.e. scheduling of arrivals/appointments/operations/maintenance, operation of a conveyor system, machine breakdowns, etc.). Sufficient detail should be included (or referred to in other published work) for the algorithms to be reproducible. Pseudo-code may be used to describe an algorithm.\n\n\n\n\n2.5.1 Components - entities\nGive details of all entities within the simulation including a description of their role in the model and a description of all their attributes.\n\n\n\n\n2.5.2 Components - activities\nDescribe the activities that entities engage in within the model. Provide details of entity routing into and out of the activity.\n\n\n\n\n2.5.3 Components - resources\nList all the resources included within the model and which activities make use of them.\n\n\n\n\n2.5.4 Components - queues\nGive details of the assumed queuing discipline used in the model (e.g. First in First Out, Last in First Out, prioritisation, etc.). Where one or more queues have a different discipline from the rest, provide a list of queues, indicating the queuing discipline used for each. If reneging, balking or jockeying occur, etc., provide details of the rules. Detail any delays or capacity constraints on the queues.\n\n\n\n\n2.5.5 Components - entry/exit points\nGive details of the model boundaries i.e. all arrival and exit points of entities. Detail the arrival mechanism (e.g. ‘thinning’ to mimic a non-homogenous Poisson process or balking)\n\n\n\n\nData\n\n\n\n\n\n3.1 Data sources\nList and detail all data sources. Sources may include:• Interviews with stakeholders,• Samples of routinely collected data,• Prospectively collected samples for the purpose of the simulation study,• Public domain data published in either academic or organisational literature. Provide, where possible, the link and DOI to the data or reference to published literature.All data source descriptions should include details of the sample size, sample date ranges and use within the study.\n\n\n\n\n3.2 Pre-processing\nProvide details of any data manipulation that has taken place before its use in the simulation, e.g. interpolation to account for missing data or the removal of outliers.\n\n\n\n\n3.3 Input parameters\nList all input variables in the model. Provide a description of their use and include parameter values. For stochastic inputs provide details of any continuous, discrete or empirical distributions used along with all associated parameters. Give details of all time dependent parameters and correlation.Clearly state:• Base case data• Data use in experimentation, where different from the base case.• Where optimisation or design of experiments has been used, state the range of values that parameters can take.Where theoretical distributions are used, state how these were selected and prioritised above other candidate distributions.\n\n\n\n\n3.4 Assumptions\nWhere data or knowledge of the real system is unavailable what assumptions are included in the model? This might include parameter values, distributions or routing logic within the model.\n\n\n\n\nExperimentation\n\n\n\n\n\n4.1 Initialisation\nReport if the system modelled is terminating or non-terminating. State if a warm-up period has been used, its length and the analysis method used to select it. For terminating systems state the stopping condition.State what if any initial model conditions have been included, e.g., pre-loaded queues and activities. Report whether initialisation of these variables is deterministic or stochastic.\n\n\n\n\n4.2 Run length\nDetail the run length of the simulation model and time units.\n\n\n\n\n4.3 Estimation approach\nState the method used to account for the stochasticity: For example, two common methods are multiple replications or batch means. Where multiple replications have been used, state the number of replications and for batch means, indicate the batch length and whether the batch means procedure is standard, spaced or overlapping. For both procedures provide a justification for the methods used and the number of replications/size of batches.\n\n\n\n\nImplementation\n\n\n\n\n\n5.1 Software or programming language\nState the operating system and version and build number.State the name, version and build number of commercial or open source DES software that the model is implemented in.State the name and version of general-purpose programming languages used (e.g. Python 3.5).Where frameworks and libraries have been used provide all details including version numbers.\n\n\n\n\n5.2 Random sampling\nState the algorithm used to generate random samples in the software/programming language used e.g. Mersenne Twister.If common random numbers are used, state how seeds (or random number streams) are distributed among sampling processes.\n\n\n\n\n5.3 Model execution\nState the event processing mechanism used e.g. three phase, event, activity, process interaction.Note that in some commercial software the event processing mechanism may not be published. In these cases authors should adhere to item 5.1 software recommendations.State all priority rules included if entities/activities compete for resources.If the model is parallel, distributed and/or use grid or cloud computing, etc., state and preferably reference the technology used. For parallel and distributed simulations the time management algorithms used. If the HLA is used then state the version of the standard, which run-time infrastructure (and version), and any supporting documents (FOMs, etc.)\n\n\n\n\n5.4 System specification\nState the model run time and specification of hardware used. This is particularly important for large scale models that require substantial computing power. For parallel, distributed and/or use grid or cloud computing, etc. state the details of all systems used in the implementation (processors, network, etc.)\n\n\n\n\nCode access\n\n\n\n\n\n6.1 Computer model sharing statement\nDescribe how someone could obtain the model described in the paper, the simulation software and any other associated software (or hardware) needed to reproduce the results. Provide, where possible, the link and DOIs to these."
  },
  {
    "objectID": "evaluation/reporting.html#ispor-sdm",
    "href": "evaluation/reporting.html#ispor-sdm",
    "title": "Reporting",
    "section": "ISPOR-SDM",
    "text": "ISPOR-SDM\nTotal (out of 4):\n\n✅ Fully - 25% (n=1)\n🟡 Partially - 25% (n=1)\n❌ Not met - 25% (n=1)\n❔ Unclear - 25% (n=1)\n\n\n\n\n\n\n\n\n\n\nItem\nAssessed if…\nMet by study?\nEvidence/location\n\n\n\n\nModel conceptualisation\n\n\n\n\n\n1 Is the focused health-related decision problem clarified?\n…the decision problem under investigation was defined. DES studies included different types of decision problems, eg, those listed in previously developed taxonomies.\n🟡 Partially\n\n\n\n2 Is the modeled healthcare setting/health condition clarified?\n…the physical context/scope (eg, a certain healthcare unit or a broader system) or disease spectrum simulated was described.\n❌ Not met\n\n\n\n3 Is the model structure described?\n…the model’s conceptual structure was described in the form of either graphical or text presentation.\n✅ Fully\n\n\n\n4 Is the time horizon given?\n…the time period covered by the simulation was reported.\n\n\n\n\n5 Are all simulated strategies/scenarios specified?\n…the comparators under test were described in terms of their components, corresponding variations, etc\n❔ Unclear\n\n\n\n6 Is the target population described?\n…the entities simulated and their main attributes were characterized.\n\n\n\n\nParamaterisation and uncertainty assessment\n\n\n\n\n\n7 Are data sources informing parameter estimations provided?\n…the sources of all data used to inform model inputs were reported.\n\n\n\n\n8 Are the parameters used to populate model frameworks specified?\n…all relevant parameters fed into model frameworks were disclosed.\n\n\n\n\n9 Are model uncertainties discussed?\n…the uncertainty surrounding parameter estimations and adopted statistical methods (eg, 95% confidence intervals or possibility distributions) were reported.\n\n\n\n\n10 Are sensitivity analyses performed and reported?\n…the robustness of model outputs to input uncertainties was examined, for example via deterministic (based on parameters’ plausible ranges) or probabilistic (based on a priori-defined probability distributions) sensitivity analyses, or both.\n\n\n\n\nValidation\n\n\n\n\n\n11 Is face validity evaluated and reported?\n…it was reported that the model was subjected to the examination on how well model designs correspond to the reality and intuitions. It was assumed that this type of validation should be conducted by external evaluators with no stake in the study.\n\n\n\n\n12 Is cross validation performed and reported\n…comparison across similar modeling studies which deal with the same decision problem was undertaken.\n\n\n\n\n13 Is external validation performed and reported?\n…the modeler(s) examined how well the model’s results match the empirical data of an actual event modeled.\n\n\n\n\n14 Is predictive validation performed or attempted?\n…the modeler(s) examined the consistency of a model’s predictions of a future event and the actual outcomes in the future. If this was not undertaken, it was assessed whether the reasons were discussed.\n\n\n\n\nGeneralisability and stakeholder involvement\n\n\n\n\n\n15 Is the model generalizability issue discussed?\n…the modeler(s) discussed the potential of the resulting model for being applicable to other settings/populations (single/multiple application).\n\n\n\n\n16 Are decision makers or other stakeholders involved in modeling?\n…the modeler(s) reported in which part throughout the modeling process decision makers and other stakeholders (eg, subject experts) were engaged.\n\n\n\n\n17 Is the source of funding stated?\n…the sponsorship of the study was indicated.\n\n\n\n\n18 Are model limitations discussed?\n…limitations of the assessed model, especially limitations of interest to decision makers, were discussed."
  },
  {
    "objectID": "evaluation/logbook.html",
    "href": "evaluation/logbook.html",
    "title": "Logbook",
    "section": "",
    "text": "These diary entries record daily progress in reproduction of the study, providing a transparent and detailed record of work.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDay 1\n\n\n\n\n\n\nsetup\n\n\n\n\n\n\n\n\n\nMay 22, 2024\n\n\nAmy Heather\n\n\n\n\n\n\nNo matching items"
  }
]
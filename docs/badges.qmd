---
title: "Badges"
format:
  html:
    code-fold: true
jupyter: python3
---

<!--
Template for evaluation of journal article against criteria of various reproducibility badges.

To use this template:
1. For each criteria in the Python cell, add a 0 if not met and 1 if it is met.
2. Run the script (i.e. preview the Quarto book) - you will see that the code outputs a formatted list of criteria met, as well as the badges met.

Although this script uses Python, it is applicable regardless of the language used by the study you are evaluating.
-->

This page evaluates the extent to which Monks et al. 2016 meets the criteria of badges related to reproducibility from various organisations and journals.

```{python}
import numpy as np
import pandas as pd

criteria = {
    'archive': 'Code is stored in a permanent archive that is publicly and openly accessible',
    'id': 'It has a persistent identifier (e.g. DOI)',
    'license': 'It has an open license',
    'complete_open': 'Complete set of materials shared (as would be needed to fully reproduce article)',
    'meta': 'Metadata describes data/code sufficiently to enable reproduction (e.g. package versions)',
    'statement': 'Manuscript has data availability statement',
    # DUPE with complete_open above (to reflect on)
    'complete_review': 'Complete set of materials shared (as would be needed to fully reproduce article)',
    # DUPE with meta above (to reflect on)
    'describe_minimal': 'There is a minimal but sufficient description of artefacts',
    'describe_careful': 'There is a more detailed, careful documentation of artefacts',
    'artefacts_structure': 'Artefacts are well structured to facilitate reuse, adhering to norms and standards of research community',
    'regenerated': 'Independent party regenerated results using the authors research artefacts',
    'hour': 'Reproduced within approximately one hour (excluding compute time)',
    # DUPE with artefacts_structure and meta/describe
    'reproduce_organise': 'Requires data and scripts to be well-organised, clearly documented and with a README file with step-by-step instructions on how to reproduce results in the manuscript'
}

badge_names = {
    # ISSUE: need to make seperate criteria for code and data (unless just do code?)
    'open_niso': 'NISO "Open Research Objects"',
    'open_acm': 'ACM "Artifacts Available"',
    'open_cos_data': 'COS "Open Data"',
    'open_cos_materials': 'COS "Open Materials"',
    'open_cos_code': 'COS "Open Code"',
    # ISSUE: need to make seperate criteria for code and data (unless just do code?)
    'open_ieee_code': 'IEEE "Code Available"',
    'open_ieee_data': 'IEEE "Datasets Available"',
    'open_springer': 'Springer Nature "Badge for Open Data"',
    'review_acm_functional': 'ACM "Artifacts Evaluated - Functional"',
    'review_acm_reusable': 'ACM "Artifacts Evaluated - Reusable"',
    # ISSUE: need to make seperate criteria for code and data (unless just do code?)
    'review_ieee_code': 'IEEE "Code Reviewed"',
    'review_ieee_data': 'IEEE "Datasets Reviewed"',
    'reproduce_niso': 'NISO "Results Reproduced"',
    'reproduce_acm': 'ACM "Results Reproduced"',
    # ISSUE: need to make seperate criteria for code and data (unless just do code?)
    'reproduce_ieee_code': 'IEEE "Code Reproducible"',
    'reproduce_ieee_data': 'IEEE "Dataset Reproducible"',
    'reproduce_psy': 'Psychological Science "Computational Reproducibility"'
}

open_cos = ['archive', 'id', 'license', 'complete_open', 'meta']

badges = {
    'open_niso': ['archive', 'id', 'license', 'complete_open'],
    'open_acm': ['archive', 'id'],
    'open_cos_data': open_cos,
    'open_cos_materials': open_cos,
    'open_cos_code': open_cos,
    'open_ieee_code': ['complete_open'],
    # etc. etc.
}
```

TO DO: Change to full list of criteria

TO DO: Change to full list of badges

TO DO: Add a table (perhaps minimise-able) that summarises the criteria of each badge, so can see how/why did or did not meet each of the badges.

```{python}
# Example (not done for Monks et al. 2016 yet)
# Based on the criteria dictionary above, populate with 1 and 0
eval = pd.Series({
    'archive': 1,
    'id': 1,
    'license': 0,
    'complete_open': 1,
    'meta': 1,
    'statement': 1
    # etc. etc.
})
```

```{python}
# Print compliance to each criteria
for key, value in eval.items(): 
    if value == 1:
        icon = '✅'
    else:
        icon = '⬜'
    print(f'{icon} {criteria[key]}')
```

```{python}
# Identify which badges would be awarded based on criteria
award = {}
for badge in badges:
    award[badge] = all([eval[key] == 1 for key in badges[badge]])

# Print results
for key, value in award.items(): 
    if value:
        icon = '✅'
    else:
        icon = '⬜'
    print(f'{icon} {badge_names[key]}')
```

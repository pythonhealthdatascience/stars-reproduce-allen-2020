---
title: "Day 2"
author: "Amy Heather"
date: "2024-05-23"
categories: [read]
---

::: {.callout-note}

## Total time elapsed

TBC

:::

## Work log

### 10.24-11.00 - Describe code/data

Looked over code and data from original study, taking notes below.

::: {.callout-note appearance="minimal" collapse=true}

## Notes from looking over their code and data

Code files in main folder:

* **Capacity_Model_Template.ipynb** - explain DES model, input files, code example importing `sim_replicate.py` and using functions from that
* **sim_replicate.py** - importing from sim/, single and multiple runs of model, and multiple runs of prescribed scenarios, and function to get audit results from multiple runs, and parameters
* **sim_single.py** - single run of model

Other files in main folder:

* **CONTRIBUTING.md** - lists Mike and Tom as the contributors
* **environment.yaml** - conda environment
* **.gitignore**
* **LICENSE** - MIT
* **README.md** - Instructs to use environment and then refer to `.ipynb` files
* **Transport_Model_Template.ipynb** - Monte Carlo Model
* **main_vrp.py** - importing from vrp/, but otherwise very similar to part of sim_replicate (single and multiple runs, and parameters). VRP = vehicle routing problem?

Other folders:

* **output/** - empty
* **patient_geography_data/** - patient data
* **sim/** - Discrete event
* **vrp/** - Monte Carlo

```bash
├── output
│   └── ...
├── patient_geography_data
│   └── ...
├── sim
│   └── ...
├── vrp
│   └── ...
├── .gitignore
├── CONTRIBUTING.md
├── Capacity_Model_Template.ipynb
├── LICENSE
├── README.md
├── Transport_Model_Template.ipynb
├── environment.yaml
├── main_vrp.py
├── sim_replicate.py
└── sim_single.py
```

More details on patient_geography_data/ folder:

* **patient_counts_no_home_or_IOW.csv** - ? counts per postcode
* **patients.csv** - table of patients with type, postcode, site, first day, and blank COVID status column
* **travel_matrix_distance_km.csv** - travel distance (km) between postcodes
* **travel_matrix_time_min.csv** - travel time (min) between postcodes

```bash
├── patient_geography_data
│   ├── patient_counts_no_home_or_IOW.csv
│   ├── patients.csv
│   ├── travel_matrix_distance_km.csv
│   └── travel_matrix_time_min.csv
```

More details on sim/ folder:

* **allocation.py** - methods to allocate patients to units and shifts
* **audit.py** - audit on patient and unit metrics
* **end_trial_analysis.py** - analysis after replicates, creates charts
* **helper_functions.py** - expands multi-index
* **__init__.py** - blank, to initalise as package
* **model.py** - model classes to hold patients, simulation model class
* **parameters.py** - classes for normal and uniform distributions, and class with parameters for scenario
* **patient.py** - patient class
* **patients.csv** - looks similar to patients.csv in main folder
* **travel_matrix.csv** - patient travel times to each of the units
* **units.csv** - information on each of the units
* **units.py** - unit information from CSV

```bash
├── sim
│   ├── allocation.py
│   ├── audit.py
│   ├── end_trial_analysis.py
│   ├── helper_functions.py
│   ├── __init__.py
│   ├── .ipynb_checkpoints
│   │   ├── end_trial_analysis-checkpoint.py
│   │   └── helper_functions-checkpoint.py
│   ├── model.py
│   ├── parameters.py
│   ├── patient.py
│   ├── patients.csv
│   ├── travel_matrix.csv
│   ├── units.csv
│   └── units.py
```

:::

### Untimed: Trying out WebPlotDigitizer

Tried using version 4, found it worked really well except:

* It couldn't differentiate confidence interval lines from the primary lines, which makes the resulting points hard to use.
* The points extracted from these charts don't necessarily align with the points obtained from the simulation (i.e. line chart draws line through the days but points are at specific locations and not completely continuous).

Hence, I'm going to suggest that I don't think it is worth trying to use this tool, and that a simpler and more standardised approach would be visual comparison of figures, or overlaying of the figures when possible.

### NA: Compile items in scope

All items are figures, so no actions required.

### 12.10-12.15 Search for code that produces item in scope

`Capacity_Model_Template.ipynb` creates figures incredibly similar to the article. Can spot a few slight differences likely due to different parameters. Some examples:
* Figure 2, slightly wider confidence intervals in the notebook
* Figure 4 number of displaced patients, different "bumps" in the line

### 12.15-12.16 Identify dependencies

From article:

* DES on Intel i9-7980XE CPU with 64GB RAM running Ubuntu 19.10 Linux
* Python 3.8

Within environment.yaml, can see packages and versions, to create a conda environment.

### 12.19-12.29 Create environment

Copied environment.yaml file into reproduction. Run the command `conda env create --name covid19 --file environment.yaml` from terminal within reproduction folder to create environment.

Found that:

* Received error CondaEnvException: Pip failed, for installing pip dependencies, Pip subprocess error: ImportError: libffi.so.7: cannot open shared object file: No such file or directory        
* Noticed it was including Spyder in the environment which is an IDE so removed that.

This was then successful, and built quickly (within 30s). A quick glance over the environment confirmed that it looked to have the correct python version and packages.

### 13.26- Reproduction

* Copied sim/ and sim_replicate.py into reproduction/.
* Copied code cells from Capacity_Model_Template.ipynb.
* Error no module named joblib - add this to environment.yaml. Code was archived 22 April 2020, paper was published 13 August 2020. Used date of code archive, looking at <https://pypi.org/project/joblib/#history>, can see the version closest to prior to that date is 0.14.1 (10 Dec 2019) (as the next is 0.15.0 which is 15 May 2020). Add it to environment.yaml then ran `conda env update --file environment.yaml --prune`. This fixed the error.
* FileNotFoundError: [Errno 2] No such file or directory: 'output/base_3_month_reps_30_patient_audit.csv'. Not resolved by adding output/ folder.

Protocol suggestion: On reflection, perhaps it would've better to copy over the whole code folder into reproduction/ and then modify there, rather than copying over stuff bit by bit?

Switched to doing that -

* Kept environment.yaml and example.ipynb, but otherwise copied everything over.
* Deleted irrelevant files
* Ran again and it worked fine, didn't get the FileNoteFoundError

Images look similar to their notebook from Zenodo but, as with those figures, slight differences to paper, likely due to parameters.

## Timings

```{python}
from datetime import datetime

# --------------------------------------------------------------
# Modify this section:

# Time in minutes that has been used prior to this day
used_to_date = 73

# List of times from today (as string tuples in list)
times = [
    ('10.24', '11.00'),
    ('12.10', '12.16'),
    ('12.19', '12.29')]
# --------------------------------------------------------------

FMT = '%H.%M'
total_min = 0
for t in times:
    # Convert to datetime object
    h0 = datetime.strptime(t[0], FMT)
    h1 = datetime.strptime(t[1], FMT)
    # Find difference in minutes and add to total
    total_min += (h1 - h0).total_seconds() / 60

# Time in hours and minutes
print(f'Time spent today: {int(total_min)//60}h {int(total_min)%60}m')

# Find time remaining
max = 40*60
remain_min = max - total_min - used_to_date
print(f'Time remaining: {int(remain_min//60)}h {int(remain_min%60)}m')

# Find proportion out of 40 hours
print(f'Used {round((total_min+used_to_date)/max*100,1)}% of 40 hours max')
```

## Suggested changes for protocol/template

✅ = Made the change.

Protocol: 

* Just suggestion not requirement to make notes about study, and make the notes within the logbook, as purpose is familiarising with study, and at this stage, may get details wrong! So rather than it be a seperate page where we're worried about getting it right, do it in logbook as still learning.
* There's a balance between trying to understand the code, and just trying to run the code. Reading through and making notes on files is more along the lines of understanding, but without a direct purpose. Do we like it or not? It feels like a necessity, but it also feels a little unclear? Although perhaps that is ok. It felt like well used time to me, but would suggest not making it as prespective as I'd suggested, and that you and read and take notes if you like
* Remove sugestion of WebPlotDigitizer etc., and instead suggest standardised approach of visually comparing the figures (with overlaying where possible done to support that - need to explore simplest way of doing that).
* To end of 3.2.3, suggest displaying those within the scope page also (that would be untimed though? although currently time writing out of scope above as that is just part of defining scope... so maybe just include for simplicity?)
* Modify 3.2.4 - as we describe the scope during 3.2.2
* RE: reproduction package, having the figures created within the notebooks if really handy when spotting what parts of the code create figures from article
* With regards to creating the environment, I think taking the simplest approach is appropriate - so using their environment file (or creating based on packages), and not worrying about operating system used. Could consider that with regards to troubleshooting though.
    * Don't worry about operating system
    * Keep suggestion about package list and versions using close to publication date <mark>but need to include instructions on HOW to find that out</mark>
    * Simplest might just be looking manually for each of the packages. Can't find a way to prevent it in Python. Knowing versions of the imported packages is as close as you get to if they provided a yaml file (as even with a yaml file, the dependencies they install alongside may be more recent). **Go with this**.
* For 3.4.2, this is the first time we might start using and modifying materials, so important to note that we should COPY over any environment stuff into our reproduction folder/, and not directly run scripts in original_study/, those should stay untouched.
* Turn 3.5.1 into step-by-step instructions (e.g. make notebook, copy over code, insert images from article, create images). Or perhaps just more bolding.
* For 3.5.1, need to shift emphasis onto the key things of (a) copying over stuff when running, and (b) taking very detailed notes in the logbook as go along of each copy, change, success, error. Super super detailed!
* For finding packages that were missing, base version date on Zenodo/code archive/github if possible/earlier than the paper - if later than the paper, then base on the paper - or just base on the paper.

Thoughts as reading through code:

* PEP8 of code (?)
* Commenting/docstrings (if not already) in code (?)
* Data not all stored in one place, mixing scripts and data
* README stating what folders mean (e.g. vrp, took me a little while to realise this stood for vehicle routing problem)
* Locations of parameters for simulation and finding them - convention is storing data seperately, but can be a little harder to spot where those parameters are
* Including an IDE within the dependencies (Spyder) created an issue, and also, am using own IDE. Or is that similar to when people require Jupyterlab?
* For reproducing stuff, it's helpful to know how long code takes to run?